{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "<span style=\"float: right; color: rgb(128, 128, 128); font-size:150%\" >  <strong> Final Project - Milestone 1</span>\n",
    "<span style=\"float: left; color: rgb(128, 128, 128); font-size:150%\"> <strong>  42186 Model-based machine learning (F20)</span>    \n",
    "    <br>  \n",
    "  \n",
    "    \n",
    "    \n",
    "  <span style=\"float: right; color: rgb(128, 128, 128)\" >  <strong> Students:</span>\n",
    "  <span style=\"float: left; color: rgb(128, 128, 128)\"> <strong>  Professors:</span>\n",
    "<div> \n",
    "      <br>  \n",
    "<div>\n",
    "  <span style=\"float: right\" > Guðlaug Erlendsdóttir, s185717</span> \n",
    "  <span style=\"float: left\"> Filipe Rodrigues</span>\n",
    "<div> \n",
    "    <br>\n",
    "  <span style=\"float: right\" > Matthías Karl Karlsson, s182306</span> \n",
    "  <span style=\"float: left\"> Francisco Camara Pereira</span>\n",
    "    <br>\n",
    "<div style=\"text-align: right\"> Steinn Orri Erlendsson, s153716</div>\n",
    "    \n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been cleaned in the main notebook. \n",
    "\n",
    "Here, we plan to get some results with the help of Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import nltk, re, pprint\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import collections\n",
    "import colorsys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import Image\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "import pystan\n",
    "import pystan_utils\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "#make margins smaller \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_df.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = df.short_desc\n",
    "\n",
    "data_lemmatized.dropna(inplace = True)\n",
    "\n",
    "data_lemmatized = [d.split() for d in data_lemmatized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation: Corpus and Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(2645 unique tokens: [\"'bonus',\", \"'christma',\", \"'cut',\", \"'except',\", \"'get',\"]...) from 600 documents (total 10400 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)], [(7, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 2), (37, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = dataset\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.1\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.1\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamulticore:running online LDA training, 10 topics, 10 passes over the supplied corpus of 600 documents, updating every 300 documents, evaluating every ~600 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamulticore:training LDA model using 3 processes\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.012*\"['omer',\" + 0.010*\"['art',\" + 0.009*\"'itchi',\" + 0.008*\"'join',\" + 0.008*\"'grade',\" + 0.008*\"'prove',\" + 0.008*\"'scratchi',\" + 0.006*\"'power',\" + 0.006*\"'father',\" + 0.006*\"'job',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.009*\"'stori',\" + 0.008*\"'princip',\" + 0.007*\"'race',\" + 0.006*\"'segment',\" + 0.006*\"'three',\" + 0.006*\"'attack',\" + 0.005*\"'first',\" + 0.005*\"'helper',\" + 0.005*\"'littl',\" + 0.005*\"'student',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.013*\"['fter',\" + 0.011*\"'grampa',\" + 0.009*\"'life',\" + 0.009*\"'choos',\" + 0.009*\"'quick',\" + 0.008*\"'good',\" + 0.008*\"'must',\" + 0.007*\"'form',\" + 0.006*\"'continu',\" + 0.006*\"'award',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.012*\"['fter',\" + 0.010*\"'team',\" + 0.008*\"['omer',\" + 0.007*\"'accident',\" + 0.006*\"'career',\" + 0.006*\"'hand',\" + 0.006*\"'princip',\" + 0.005*\"'chief',\" + 0.005*\"'job',\" + 0.005*\"'busi',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.016*\"['art',\" + 0.013*\"'power',\" + 0.013*\"'plant',\" + 0.011*\"'nuclear',\" + 0.010*\"['omer',\" + 0.007*\"'beat',\" + 0.007*\"'food',\" + 0.006*\"'father',\" + 0.006*\"'love',\" + 0.005*\"'must',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=7.908759, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:-11.033 per-word bound, 2094.9 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"['art',\" + 0.009*\"['omer',\" + 0.009*\"'power',\" + 0.008*\"'plant',\" + 0.006*\"'father',\" + 0.006*\"'nuclear',\" + 0.005*\"'love',\" + 0.005*\"'send',\" + 0.005*\"'keep',\" + 0.005*\"'friend',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.009*\"['omer',\" + 0.006*\"['art',\" + 0.006*\"'power',\" + 0.005*\"'famili',\" + 0.004*\"'decid',\" + 0.004*\"'father',\" + 0.004*\"'join',\" + 0.004*\"'itchi',\" + 0.004*\"'save',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.009*\"['fter',\" + 0.008*\"'open',\" + 0.006*\"'get',\" + 0.006*\"'success',\" + 0.006*\"'busi',\" + 0.005*\"'boy',\" + 0.005*\"'princip',\" + 0.005*\"'guy',\" + 0.005*\"'store',\" + 0.005*\"'lose',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.008*\"['fter',\" + 0.007*\"'friend',\" + 0.007*\"'bear',\" + 0.006*\"['omer',\" + 0.006*\"'team',\" + 0.005*\"'get',\" + 0.005*\"'bar',\" + 0.004*\"'buy',\" + 0.004*\"'selma',\" + 0.004*\"'choos',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.008*\"'save',\" + 0.008*\"['omer',\" + 0.006*\"'win',\" + 0.006*\"'christma',\" + 0.005*\"'job',\" + 0.005*\"'forc',\" + 0.005*\"'mart',\" + 0.005*\"'nelson',\" + 0.005*\"'game',\" + 0.005*\"'friend',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=2.065193, rho=0.500000\n",
      "INFO:gensim.models.ldamodel:-8.198 per-word bound, 293.6 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.009*\"['fter',\" + 0.007*\"['omer',\" + 0.007*\"'team',\" + 0.006*\"'friend',\" + 0.005*\"'accident',\" + 0.005*\"'bear',\" + 0.005*\"'job',\" + 0.005*\"'bar',\" + 0.004*\"'hand',\" + 0.004*\"'best',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"['art',\" + 0.011*\"'power',\" + 0.010*\"'plant',\" + 0.010*\"['omer',\" + 0.008*\"'nuclear',\" + 0.006*\"'father',\" + 0.005*\"'love',\" + 0.005*\"'food',\" + 0.005*\"'send',\" + 0.005*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.008*\"'maud',\" + 0.007*\"['art',\" + 0.006*\"'get',\" + 0.006*\"'visit',\" + 0.005*\"'park',\" + 0.005*\"'suspect',\" + 0.004*\"'pie',\" + 0.004*\"'promis',\" + 0.004*\"'open',\" + 0.004*\"'amus',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.016*\"['omer',\" + 0.007*\"'life',\" + 0.007*\"'littl',\" + 0.007*\"'grampa',\" + 0.007*\"'love',\" + 0.007*\"'drive',\" + 0.006*\"'mayor',\" + 0.005*\"'secret',\" + 0.005*\"['fter',\" + 0.004*\"'need',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"['fter',\" + 0.007*\"'show',\" + 0.006*\"'bowl',\" + 0.005*\"'buy',\" + 0.005*\"'friend',\" + 0.005*\"'result',\" + 0.004*\"'move',\" + 0.004*\"'stop',\" + 0.004*\"'spend',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.292205, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-8.526 per-word bound, 368.5 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"['art',\" + 0.010*\"['omer',\" + 0.009*\"'power',\" + 0.009*\"'plant',\" + 0.006*\"'father',\" + 0.006*\"'nuclear',\" + 0.006*\"'send',\" + 0.005*\"'littl',\" + 0.005*\"'love',\" + 0.005*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"'bulli',\" + 0.006*\"['fter',\" + 0.006*\"'nelson',\" + 0.006*\"'team',\" + 0.005*\"'invit',\" + 0.005*\"'life',\" + 0.005*\"'grampa',\" + 0.005*\"'star',\" + 0.004*\"'date',\" + 0.004*\"'frame',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.008*\"'friend',\" + 0.008*\"'stori',\" + 0.007*\"'key',\" + 0.007*\"'move',\" + 0.006*\"'life',\" + 0.005*\"'group',\" + 0.005*\"'father',\" + 0.005*\"'lost',\" + 0.005*\"'enjoy',\" + 0.005*\"'citi',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.013*\"['omer',\" + 0.006*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'move',\" + 0.005*\"'show',\" + 0.004*\"'bowl',\" + 0.004*\"'stop',\" + 0.004*\"'voic',\" + 0.004*\"'result',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.014*\"['omer',\" + 0.009*\"'drive',\" + 0.007*\"'littl',\" + 0.006*\"'love',\" + 0.006*\"'grampa',\" + 0.005*\"'life',\" + 0.005*\"'boy',\" + 0.005*\"'secret',\" + 0.004*\"'mother',\" + 0.004*\"'bar',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.362725, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-7.945 per-word bound, 246.5 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"['fter',\" + 0.006*\"'show',\" + 0.006*\"'bowl',\" + 0.005*\"'buy',\" + 0.005*\"'friend',\" + 0.005*\"'result',\" + 0.005*\"'move',\" + 0.004*\"'stop',\" + 0.004*\"'spend',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.009*\"'open',\" + 0.006*\"'busi',\" + 0.006*\"'get',\" + 0.006*\"'appear',\" + 0.005*\"'lose',\" + 0.005*\"'success',\" + 0.005*\"'boy',\" + 0.005*\"'power',\" + 0.005*\"'movi',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*\"['art',\" + 0.011*\"'power',\" + 0.011*\"'plant',\" + 0.010*\"['omer',\" + 0.008*\"'nuclear',\" + 0.006*\"'father',\" + 0.006*\"'send',\" + 0.005*\"'love',\" + 0.005*\"'keep',\" + 0.005*\"'must',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.016*\"['omer',\" + 0.008*\"'drive',\" + 0.007*\"'littl',\" + 0.007*\"'love',\" + 0.007*\"'grampa',\" + 0.007*\"'life',\" + 0.005*\"'secret',\" + 0.005*\"'mayor',\" + 0.004*\"['fter',\" + 0.004*\"'plant',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.009*\"['omer',\" + 0.007*\"['art',\" + 0.006*\"'power',\" + 0.006*\"'famili',\" + 0.005*\"'itchi',\" + 0.005*\"'father',\" + 0.005*\"'join',\" + 0.005*\"'prove',\" + 0.005*\"'scratchi',\" + 0.004*\"'grade',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.259952, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-8.228 per-word bound, 299.8 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'boy',\" + 0.007*\"'open',\" + 0.007*\"'shirt',\" + 0.007*\"'store',\" + 0.006*\"'get',\" + 0.006*\"'movi',\" + 0.006*\"'busi',\" + 0.006*\"'guy',\" + 0.006*\"'princip',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.008*\"'friend',\" + 0.008*\"'stori',\" + 0.007*\"'move',\" + 0.007*\"'key',\" + 0.006*\"'life',\" + 0.005*\"'group',\" + 0.005*\"'father',\" + 0.005*\"'citi',\" + 0.005*\"'lost',\" + 0.005*\"'krabappel',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.011*\"['art',\" + 0.010*\"['omer',\" + 0.009*\"'power',\" + 0.009*\"'plant',\" + 0.006*\"'father',\" + 0.006*\"'nuclear',\" + 0.006*\"'send',\" + 0.006*\"'littl',\" + 0.005*\"'helper',\" + 0.005*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'move',\" + 0.005*\"'bowl',\" + 0.004*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.014*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'get',\" + 0.007*\"'man',\" + 0.006*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'manag',\" + 0.005*\"'congressman',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.285285, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-7.871 per-word bound, 234.1 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.015*\"['omer',\" + 0.007*\"['fter',\" + 0.006*\"'bowl',\" + 0.006*\"'show',\" + 0.006*\"'friend',\" + 0.005*\"'buy',\" + 0.005*\"'result',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'spend',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.009*\"['fter',\" + 0.008*\"'bear',\" + 0.008*\"'bar',\" + 0.007*\"'friend',\" + 0.007*\"['omer',\" + 0.006*\"'team',\" + 0.005*\"'get',\" + 0.005*\"'job',\" + 0.005*\"'show',\" + 0.004*\"'accident',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.010*\"'save',\" + 0.009*\"['omer',\" + 0.007*\"'mart',\" + 0.007*\"'win',\" + 0.007*\"'christma',\" + 0.006*\"'job',\" + 0.006*\"'game',\" + 0.006*\"'cut',\" + 0.006*\"'kwik',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.011*\"'pie',\" + 0.007*\"'get',\" + 0.006*\"'promis',\" + 0.006*\"'maud',\" + 0.006*\"'visit',\" + 0.006*\"['art',\" + 0.005*\"'man',\" + 0.005*\"'snake',\" + 0.005*\"'park',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'open',\" + 0.006*\"'boy',\" + 0.006*\"'busi',\" + 0.006*\"'get',\" + 0.006*\"'appear',\" + 0.006*\"'lose',\" + 0.005*\"'shirt',\" + 0.005*\"'success',\" + 0.005*\"'movi',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.221512, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-8.136 per-word bound, 281.3 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.012*\"['art',\" + 0.010*\"['omer',\" + 0.010*\"'power',\" + 0.009*\"'plant',\" + 0.006*\"'littl',\" + 0.006*\"'father',\" + 0.006*\"'send',\" + 0.006*\"'nuclear',\" + 0.006*\"'santa',\" + 0.006*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.011*\"'bear',\" + 0.011*\"'bar',\" + 0.008*\"'friend',\" + 0.008*\"['fter',\" + 0.006*\"'get',\" + 0.006*\"'mitzvah',\" + 0.006*\"['omer',\" + 0.006*\"'show',\" + 0.005*\"'buy',\" + 0.005*\"'selma',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'boy',\" + 0.008*\"'shirt',\" + 0.007*\"'open',\" + 0.007*\"'store',\" + 0.006*\"'movi',\" + 0.006*\"'get',\" + 0.006*\"'guy',\" + 0.006*\"'busi',\" + 0.006*\"'princip',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'move',\" + 0.005*\"'bowl',\" + 0.005*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.008*\"['omer',\" + 0.006*\"'power',\" + 0.006*\"['art',\" + 0.006*\"'famili',\" + 0.005*\"'springfield',\" + 0.005*\"'lead',\" + 0.004*\"'music',\" + 0.004*\"'class',\" + 0.004*\"'save',\" + 0.004*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.229810, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-7.843 per-word bound, 229.7 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.010*\"'save',\" + 0.009*\"['omer',\" + 0.007*\"'mart',\" + 0.007*\"'win',\" + 0.007*\"'christma',\" + 0.006*\"'kwik',\" + 0.006*\"'job',\" + 0.006*\"'game',\" + 0.006*\"'cut',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'open',\" + 0.007*\"'boy',\" + 0.006*\"'get',\" + 0.006*\"'busi',\" + 0.006*\"'shirt',\" + 0.006*\"'lose',\" + 0.005*\"'appear',\" + 0.005*\"'princip',\" + 0.005*\"'movi',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*\"['art',\" + 0.011*\"'plant',\" + 0.011*\"'power',\" + 0.010*\"['omer',\" + 0.008*\"'nuclear',\" + 0.006*\"'father',\" + 0.006*\"'send',\" + 0.006*\"'keep',\" + 0.005*\"'must',\" + 0.005*\"'rais',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"'pie',\" + 0.007*\"'get',\" + 0.007*\"'promis',\" + 0.006*\"'maud',\" + 0.006*\"'visit',\" + 0.006*\"'man',\" + 0.006*\"['art',\" + 0.005*\"'snake',\" + 0.004*\"'park',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.007*\"['fter',\" + 0.007*\"'bulli',\" + 0.006*\"'grampa',\" + 0.006*\"'team',\" + 0.006*\"'nelson',\" + 0.006*\"'life',\" + 0.005*\"'date',\" + 0.004*\"'good',\" + 0.004*\"'invit',\" + 0.004*\"'star',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.186982, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-8.093 per-word bound, 273.1 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'boy',\" + 0.008*\"'shirt',\" + 0.007*\"'open',\" + 0.007*\"'store',\" + 0.007*\"'movi',\" + 0.006*\"'get',\" + 0.006*\"'guy',\" + 0.006*\"'princip',\" + 0.006*\"'busi',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'bowl',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.009*\"'friend',\" + 0.008*\"'stori',\" + 0.008*\"'move',\" + 0.007*\"'key',\" + 0.006*\"'life',\" + 0.006*\"'lost',\" + 0.006*\"'citi',\" + 0.006*\"'group',\" + 0.006*\"'krabappel',\" + 0.005*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.012*\"'bear',\" + 0.011*\"'bar',\" + 0.008*\"'friend',\" + 0.008*\"['fter',\" + 0.006*\"'get',\" + 0.006*\"'mitzvah',\" + 0.006*\"'show',\" + 0.006*\"['omer',\" + 0.005*\"'buy',\" + 0.005*\"'selma',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'manag',\" + 0.005*\"'congressman',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.190716, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-7.833 per-word bound, 228.0 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.009*\"['omer',\" + 0.008*\"['art',\" + 0.007*\"'power',\" + 0.006*\"'famili',\" + 0.005*\"'itchi',\" + 0.005*\"'father',\" + 0.005*\"'class',\" + 0.005*\"'join',\" + 0.005*\"'movi',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.012*\"'pie',\" + 0.007*\"'promis',\" + 0.007*\"'get',\" + 0.006*\"'visit',\" + 0.006*\"'maud',\" + 0.006*\"'man',\" + 0.005*\"['art',\" + 0.005*\"'snake',\" + 0.004*\"'park',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.010*\"'save',\" + 0.009*\"['omer',\" + 0.008*\"'mart',\" + 0.007*\"'win',\" + 0.007*\"'christma',\" + 0.007*\"'kwik',\" + 0.006*\"'job',\" + 0.006*\"'game',\" + 0.006*\"'cut',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"['omer',\" + 0.009*\"'drive',\" + 0.007*\"'grampa',\" + 0.007*\"'love',\" + 0.007*\"'life',\" + 0.007*\"'littl',\" + 0.005*\"'secret',\" + 0.005*\"'mayor',\" + 0.005*\"'mother',\" + 0.004*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'open',\" + 0.007*\"'boy',\" + 0.006*\"'shirt',\" + 0.006*\"'busi',\" + 0.006*\"'get',\" + 0.006*\"'princip',\" + 0.006*\"'appear',\" + 0.006*\"'part',\" + 0.006*\"'lose',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.160729, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-8.069 per-word bound, 268.6 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.008*\"['omer',\" + 0.006*\"'power',\" + 0.006*\"['art',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'springfield',\" + 0.005*\"'lead',\" + 0.005*\"'music',\" + 0.004*\"'father',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'boy',\" + 0.008*\"'shirt',\" + 0.007*\"'open',\" + 0.007*\"'store',\" + 0.007*\"'movi',\" + 0.006*\"'guy',\" + 0.006*\"'get',\" + 0.006*\"'princip',\" + 0.006*\"'busi',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.012*\"['art',\" + 0.010*\"['omer',\" + 0.010*\"'plant',\" + 0.010*\"'power',\" + 0.007*\"'littl',\" + 0.006*\"'send',\" + 0.006*\"'father',\" + 0.006*\"'nuclear',\" + 0.006*\"'helper',\" + 0.006*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'congressman',\" + 0.005*\"'manag',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.015*\"['omer',\" + 0.010*\"'drive',\" + 0.007*\"'love',\" + 0.007*\"'grampa',\" + 0.006*\"'littl',\" + 0.005*\"'boy',\" + 0.005*\"'mother',\" + 0.005*\"'life',\" + 0.005*\"'men',\" + 0.005*\"'secret',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.164157, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-7.830 per-word bound, 227.5 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.010*\"'bear',\" + 0.009*\"'bar',\" + 0.009*\"['fter',\" + 0.008*\"'friend',\" + 0.007*\"['omer',\" + 0.006*\"'team',\" + 0.005*\"'show',\" + 0.005*\"'get',\" + 0.005*\"'mitzvah',\" + 0.005*\"'job',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.015*\"['omer',\" + 0.007*\"['fter',\" + 0.006*\"'bowl',\" + 0.006*\"'friend',\" + 0.006*\"'buy',\" + 0.005*\"'show',\" + 0.005*\"'result',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'spend',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.009*\"['omer',\" + 0.008*\"['art',\" + 0.007*\"'power',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'father',\" + 0.005*\"'itchi',\" + 0.005*\"'join',\" + 0.005*\"'movi',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'open',\" + 0.007*\"'boy',\" + 0.006*\"'shirt',\" + 0.006*\"'get',\" + 0.006*\"'busi',\" + 0.006*\"'part',\" + 0.006*\"'appear',\" + 0.006*\"'princip',\" + 0.006*\"'movi',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.008*\"'bulli',\" + 0.007*\"['fter',\" + 0.007*\"'nelson',\" + 0.006*\"'grampa',\" + 0.006*\"'team',\" + 0.005*\"'life',\" + 0.005*\"'date',\" + 0.004*\"'frame',\" + 0.004*\"'good',\" + 0.004*\"'invit',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.143076, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-8.054 per-word bound, 265.7 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'bowl',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'congressman',\" + 0.005*\"'manag',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.012*\"['art',\" + 0.010*\"['omer',\" + 0.010*\"'plant',\" + 0.010*\"'power',\" + 0.007*\"'littl',\" + 0.007*\"'send',\" + 0.006*\"'nuclear',\" + 0.006*\"'father',\" + 0.006*\"'helper',\" + 0.006*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.009*\"'bulli',\" + 0.008*\"'nelson',\" + 0.006*\"['fter',\" + 0.006*\"'team',\" + 0.005*\"'date',\" + 0.005*\"'grampa',\" + 0.005*\"'invit',\" + 0.005*\"'sara',\" + 0.005*\"'star',\" + 0.005*\"'frame',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.008*\"['omer',\" + 0.007*\"['art',\" + 0.007*\"'power',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'springfield',\" + 0.005*\"'lead',\" + 0.005*\"'music',\" + 0.004*\"'father',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.146401, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-7.829 per-word bound, 227.4 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.009*\"'bulli',\" + 0.008*\"['fter',\" + 0.007*\"'nelson',\" + 0.006*\"'grampa',\" + 0.006*\"'team',\" + 0.005*\"'life',\" + 0.005*\"'date',\" + 0.004*\"'frame',\" + 0.004*\"'good',\" + 0.004*\"'invit',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*\"['art',\" + 0.012*\"'plant',\" + 0.011*\"'power',\" + 0.010*\"['omer',\" + 0.008*\"'nuclear',\" + 0.007*\"'send',\" + 0.006*\"'father',\" + 0.006*\"'keep',\" + 0.006*\"'littl',\" + 0.006*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"'pie',\" + 0.007*\"'promis',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'maud',\" + 0.006*\"'man',\" + 0.005*\"['art',\" + 0.005*\"'snake',\" + 0.004*\"'park',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.015*\"['omer',\" + 0.007*\"['fter',\" + 0.006*\"'bowl',\" + 0.006*\"'friend',\" + 0.006*\"'buy',\" + 0.005*\"'show',\" + 0.005*\"'result',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'spend',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"['omer',\" + 0.009*\"'drive',\" + 0.008*\"'grampa',\" + 0.008*\"'love',\" + 0.007*\"'life',\" + 0.006*\"'littl',\" + 0.005*\"'secret',\" + 0.005*\"'mayor',\" + 0.005*\"'mother',\" + 0.004*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.131547, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-8.043 per-word bound, 263.8 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'congressman',\" + 0.005*\"'manag',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.012*\"'save',\" + 0.008*\"['omer',\" + 0.007*\"'win',\" + 0.007*\"'mart',\" + 0.007*\"'problem',\" + 0.006*\"'christma',\" + 0.006*\"'real',\" + 0.006*\"'job',\" + 0.006*\"['arg',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.012*\"['art',\" + 0.011*\"'plant',\" + 0.010*\"['omer',\" + 0.010*\"'power',\" + 0.007*\"'littl',\" + 0.007*\"'send',\" + 0.006*\"'helper',\" + 0.006*\"'nuclear',\" + 0.006*\"'father',\" + 0.006*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'bowl',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.012*\"'bear',\" + 0.011*\"'bar',\" + 0.008*\"'friend',\" + 0.008*\"['fter',\" + 0.006*\"'get',\" + 0.006*\"'mitzvah',\" + 0.006*\"'show',\" + 0.006*\"['omer',\" + 0.005*\"'buy',\" + 0.005*\"'selma',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.134227, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-7.830 per-word bound, 227.5 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.008*\"'stori',\" + 0.007*\"'friend',\" + 0.006*\"'move',\" + 0.006*\"'lost',\" + 0.006*\"'citi',\" + 0.006*\"'key',\" + 0.005*\"'life',\" + 0.005*\"'father',\" + 0.005*\"'group',\" + 0.005*\"'krabappel',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.013*\"'pie',\" + 0.007*\"'promis',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'man',\" + 0.006*\"'maud',\" + 0.005*\"'snake',\" + 0.005*\"['art',\" + 0.004*\"'park',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*\"['omer',\" + 0.009*\"'drive',\" + 0.008*\"'grampa',\" + 0.008*\"'love',\" + 0.006*\"'life',\" + 0.006*\"'littl',\" + 0.005*\"'secret',\" + 0.005*\"'mayor',\" + 0.005*\"'mother',\" + 0.004*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.009*\"['omer',\" + 0.008*\"['art',\" + 0.007*\"'power',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'father',\" + 0.005*\"'itchi',\" + 0.005*\"'join',\" + 0.005*\"'movi',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.010*\"'bear',\" + 0.009*\"'bar',\" + 0.009*\"['fter',\" + 0.008*\"'friend',\" + 0.007*\"['omer',\" + 0.006*\"'team',\" + 0.005*\"'show',\" + 0.005*\"'get',\" + 0.005*\"'mitzvah',\" + 0.005*\"'job',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.123909, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-8.035 per-word bound, 262.3 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'bowl',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.010*\"'bulli',\" + 0.008*\"'nelson',\" + 0.006*\"['fter',\" + 0.006*\"'team',\" + 0.005*\"'date',\" + 0.005*\"'grampa',\" + 0.005*\"'invit',\" + 0.005*\"'sara',\" + 0.005*\"'star',\" + 0.005*\"'frame',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.012*\"['art',\" + 0.011*\"'plant',\" + 0.011*\"['omer',\" + 0.010*\"'power',\" + 0.007*\"'littl',\" + 0.007*\"'send',\" + 0.006*\"'helper',\" + 0.006*\"'nuclear',\" + 0.006*\"'father',\" + 0.006*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.012*\"'save',\" + 0.008*\"['omer',\" + 0.007*\"'win',\" + 0.007*\"'mart',\" + 0.007*\"'problem',\" + 0.006*\"'christma',\" + 0.006*\"'real',\" + 0.006*\"'job',\" + 0.006*\"['arg',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'congressman',\" + 0.005*\"'manag',\" + 0.004*\"'help',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic diff=0.125460, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-7.831 per-word bound, 227.7 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'open',\" + 0.007*\"'boy',\" + 0.006*\"'shirt',\" + 0.006*\"'part',\" + 0.006*\"'appear',\" + 0.006*\"'get',\" + 0.006*\"'busi',\" + 0.006*\"'princip',\" + 0.006*\"'guy',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.008*\"'stori',\" + 0.007*\"'friend',\" + 0.006*\"'move',\" + 0.006*\"'lost',\" + 0.006*\"'citi',\" + 0.006*\"'key',\" + 0.005*\"'life',\" + 0.005*\"'father',\" + 0.005*\"'group',\" + 0.005*\"'krabappel',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.009*\"['omer',\" + 0.008*\"['art',\" + 0.007*\"'power',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'father',\" + 0.005*\"'itchi',\" + 0.005*\"'join',\" + 0.005*\"'movi',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.011*\"'save',\" + 0.009*\"['omer',\" + 0.008*\"'mart',\" + 0.007*\"'win',\" + 0.007*\"'christma',\" + 0.007*\"'kwik',\" + 0.006*\"'job',\" + 0.006*\"'game',\" + 0.006*\"'cut',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*\"['art',\" + 0.013*\"'plant',\" + 0.011*\"'power',\" + 0.010*\"['omer',\" + 0.008*\"'nuclear',\" + 0.007*\"'send',\" + 0.006*\"'father',\" + 0.006*\"'keep',\" + 0.006*\"'littl',\" + 0.006*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.118311, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-8.029 per-word bound, 261.2 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.009*\"'friend',\" + 0.008*\"'stori',\" + 0.008*\"'move',\" + 0.007*\"'key',\" + 0.007*\"'citi',\" + 0.006*\"'life',\" + 0.006*\"'lost',\" + 0.006*\"'group',\" + 0.006*\"'krabappel',\" + 0.005*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.012*\"'bear',\" + 0.011*\"'bar',\" + 0.008*\"'friend',\" + 0.008*\"['fter',\" + 0.006*\"'get',\" + 0.006*\"'mitzvah',\" + 0.006*\"'show',\" + 0.006*\"['omer',\" + 0.005*\"'buy',\" + 0.005*\"'selma',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'congressman',\" + 0.005*\"'manag',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.012*\"'save',\" + 0.008*\"['omer',\" + 0.007*\"'win',\" + 0.007*\"'mart',\" + 0.007*\"'problem',\" + 0.006*\"'christma',\" + 0.006*\"'real',\" + 0.006*\"['arg',\" + 0.006*\"'job',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.008*\"['omer',\" + 0.007*\"'power',\" + 0.007*\"['art',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'springfield',\" + 0.005*\"'lead',\" + 0.005*\"'music',\" + 0.004*\"'father',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.118698, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-7.833 per-word bound, 228.0 perplexity estimate based on a held-out corpus of 100 documents with 1766 words\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.008*\"['omer',\" + 0.007*\"'power',\" + 0.007*\"['art',\" + 0.006*\"'famili',\" + 0.005*\"'class',\" + 0.005*\"'springfield',\" + 0.005*\"'lead',\" + 0.005*\"'music',\" + 0.004*\"'father',\" + 0.004*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.010*\"['fter',\" + 0.008*\"'boy',\" + 0.008*\"'shirt',\" + 0.007*\"'open',\" + 0.007*\"'store',\" + 0.007*\"'guy',\" + 0.006*\"'movi',\" + 0.006*\"'get',\" + 0.006*\"'princip',\" + 0.006*\"'busi',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.015*\"'pie',\" + 0.008*\"'promis',\" + 0.007*\"'man',\" + 0.007*\"'get',\" + 0.007*\"'visit',\" + 0.006*\"'snake',\" + 0.005*\"['art',\" + 0.005*\"'congressman',\" + 0.005*\"'manag',\" + 0.004*\"'help',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.012*\"'save',\" + 0.008*\"['omer',\" + 0.007*\"'win',\" + 0.007*\"'mart',\" + 0.007*\"'problem',\" + 0.006*\"'christma',\" + 0.006*\"'real',\" + 0.006*\"['arg',\" + 0.006*\"'job',\" + 0.006*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.015*\"['omer',\" + 0.010*\"'drive',\" + 0.007*\"'love',\" + 0.007*\"'grampa',\" + 0.006*\"'littl',\" + 0.005*\"'mother',\" + 0.005*\"'boy',\" + 0.005*\"'men',\" + 0.005*\"'life',\" + 0.005*\"'join',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.014*\"['omer',\" + 0.007*\"'friend',\" + 0.006*\"['fter',\" + 0.005*\"'buy',\" + 0.005*\"'voic',\" + 0.005*\"'bowl',\" + 0.005*\"'move',\" + 0.005*\"'stop',\" + 0.004*\"'result',\" + 0.004*\"'phone',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.009*\"'friend',\" + 0.008*\"'stori',\" + 0.008*\"'move',\" + 0.007*\"'key',\" + 0.007*\"'citi',\" + 0.006*\"'life',\" + 0.006*\"'lost',\" + 0.006*\"'group',\" + 0.006*\"'krabappel',\" + 0.005*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*\"['art',\" + 0.011*\"'plant',\" + 0.011*\"['omer',\" + 0.010*\"'power',\" + 0.007*\"'littl',\" + 0.007*\"'send',\" + 0.006*\"'helper',\" + 0.006*\"'nuclear',\" + 0.006*\"'father',\" + 0.006*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.010*\"'bulli',\" + 0.008*\"'nelson',\" + 0.006*\"['fter',\" + 0.006*\"'team',\" + 0.005*\"'date',\" + 0.005*\"'grampa',\" + 0.005*\"'invit',\" + 0.005*\"'sara',\" + 0.005*\"'star',\" + 0.005*\"'frame',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.012*\"'bear',\" + 0.011*\"'bar',\" + 0.008*\"'friend',\" + 0.008*\"['fter',\" + 0.006*\"'get',\" + 0.006*\"'mitzvah',\" + 0.006*\"'show',\" + 0.006*\"['omer',\" + 0.005*\"'buy',\" + 0.005*\"'selma',\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.008*\"[\\'omer\\',\" + 0.007*\"\\'power\\',\" + 0.007*\"[\\'art\\',\" + '\n",
      "  '0.006*\"\\'famili\\',\" + 0.005*\"\\'class\\',\" + 0.005*\"\\'springfield\\',\" + '\n",
      "  '0.005*\"\\'lead\\',\" + 0.005*\"\\'music\\',\" + 0.004*\"\\'father\\',\" + '\n",
      "  '0.004*\"\\'buy\\',\"'),\n",
      " (1,\n",
      "  '0.010*\"[\\'fter\\',\" + 0.008*\"\\'boy\\',\" + 0.008*\"\\'shirt\\',\" + '\n",
      "  '0.007*\"\\'open\\',\" + 0.007*\"\\'store\\',\" + 0.007*\"\\'guy\\',\" + '\n",
      "  '0.006*\"\\'movi\\',\" + 0.006*\"\\'get\\',\" + 0.006*\"\\'princip\\',\" + '\n",
      "  '0.006*\"\\'busi\\',\"'),\n",
      " (2,\n",
      "  '0.015*\"\\'pie\\',\" + 0.008*\"\\'promis\\',\" + 0.007*\"\\'man\\',\" + '\n",
      "  '0.007*\"\\'get\\',\" + 0.007*\"\\'visit\\',\" + 0.006*\"\\'snake\\',\" + '\n",
      "  '0.005*\"[\\'art\\',\" + 0.005*\"\\'congressman\\',\" + 0.005*\"\\'manag\\',\" + '\n",
      "  '0.004*\"\\'help\\',\"'),\n",
      " (3,\n",
      "  '0.012*\"\\'save\\',\" + 0.008*\"[\\'omer\\',\" + 0.007*\"\\'win\\',\" + '\n",
      "  '0.007*\"\\'mart\\',\" + 0.007*\"\\'problem\\',\" + 0.006*\"\\'christma\\',\" + '\n",
      "  '0.006*\"\\'real\\',\" + 0.006*\"[\\'arg\\',\" + 0.006*\"\\'job\\',\" + '\n",
      "  '0.006*\"\\'forc\\',\"'),\n",
      " (4,\n",
      "  '0.015*\"[\\'omer\\',\" + 0.010*\"\\'drive\\',\" + 0.007*\"\\'love\\',\" + '\n",
      "  '0.007*\"\\'grampa\\',\" + 0.006*\"\\'littl\\',\" + 0.005*\"\\'mother\\',\" + '\n",
      "  '0.005*\"\\'boy\\',\" + 0.005*\"\\'men\\',\" + 0.005*\"\\'life\\',\" + '\n",
      "  '0.005*\"\\'join\\',\"'),\n",
      " (5,\n",
      "  '0.014*\"[\\'omer\\',\" + 0.007*\"\\'friend\\',\" + 0.006*\"[\\'fter\\',\" + '\n",
      "  '0.005*\"\\'buy\\',\" + 0.005*\"\\'voic\\',\" + 0.005*\"\\'bowl\\',\" + '\n",
      "  '0.005*\"\\'move\\',\" + 0.005*\"\\'stop\\',\" + 0.004*\"\\'result\\',\" + '\n",
      "  '0.004*\"\\'phone\\',\"'),\n",
      " (6,\n",
      "  '0.009*\"\\'friend\\',\" + 0.008*\"\\'stori\\',\" + 0.008*\"\\'move\\',\" + '\n",
      "  '0.007*\"\\'key\\',\" + 0.007*\"\\'citi\\',\" + 0.006*\"\\'life\\',\" + '\n",
      "  '0.006*\"\\'lost\\',\" + 0.006*\"\\'group\\',\" + 0.006*\"\\'krabappel\\',\" + '\n",
      "  '0.005*\"\\'father\\',\"'),\n",
      " (7,\n",
      "  '0.013*\"[\\'art\\',\" + 0.011*\"\\'plant\\',\" + 0.011*\"[\\'omer\\',\" + '\n",
      "  '0.010*\"\\'power\\',\" + 0.007*\"\\'littl\\',\" + 0.007*\"\\'send\\',\" + '\n",
      "  '0.006*\"\\'helper\\',\" + 0.006*\"\\'nuclear\\',\" + 0.006*\"\\'father\\',\" + '\n",
      "  '0.006*\"\\'keep\\',\"'),\n",
      " (8,\n",
      "  '0.010*\"\\'bulli\\',\" + 0.008*\"\\'nelson\\',\" + 0.006*\"[\\'fter\\',\" + '\n",
      "  '0.006*\"\\'team\\',\" + 0.005*\"\\'date\\',\" + 0.005*\"\\'grampa\\',\" + '\n",
      "  '0.005*\"\\'invit\\',\" + 0.005*\"\\'sara\\',\" + 0.005*\"\\'star\\',\" + '\n",
      "  '0.005*\"\\'frame\\',\"'),\n",
      " (9,\n",
      "  '0.012*\"\\'bear\\',\" + 0.011*\"\\'bar\\',\" + 0.008*\"\\'friend\\',\" + '\n",
      "  '0.008*\"[\\'fter\\',\" + 0.006*\"\\'get\\',\" + 0.006*\"\\'mitzvah\\',\" + '\n",
      "  '0.006*\"\\'show\\',\" + 0.006*\"[\\'omer\\',\" + 0.005*\"\\'buy\\',\" + '\n",
      "  '0.005*\"\\'selma\\',\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Model Perplexity and Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:serializing accumulator to return to master...\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulator serialized\n",
      "INFO:gensim.topic_coherence.text_analysis:serializing accumulator to return to master...\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulator serialized\n",
      "INFO:gensim.topic_coherence.text_analysis:serializing accumulator to return to master...\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulator serialized\n",
      "INFO:gensim.topic_coherence.text_analysis:3 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 965 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.41072456375229416\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=K, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b,\n",
    "                                           per_word_topics=True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/540 [00:00<?, ?it/s]\u001b[AINFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "WARNING:gensim.models.ldamulticore:input corpus stream has no len(); counting documents\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mlencorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-b0c87f741414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;31m# get the coherence score for the given parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n\u001b[0;32m---> 44\u001b[0;31m                                                   k=k, a=a, b=b)\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0;31m# Save the model results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mmodel_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation_Set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-761ab2d9fb82>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(corpus, dictionary, k, a, b)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                            \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                            per_word_topics=True)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcoherence_model_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input corpus stream has no len(); counting documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mlencorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlencorpus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LdaMulticore.update() called with an empty corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamulticore:running online LDA training, 5 topics, 10 passes over the supplied corpus of 600 documents, updating every 300 documents, evaluating every ~600 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamulticore:training LDA model using 3 processes\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.004*\"'take',\" + 0.003*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'give',\" + 0.003*\"'springfield',\" + 0.003*\"'find',\" + 0.003*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'famili',\" + 0.004*\"'say',\" + 0.004*\"'springfield',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.003*\"'one',\" + 0.003*\"'back',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.004*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'springfield',\" + 0.004*\"'apu',\" + 0.004*\"'tell',\" + 0.003*\"'tri',\" + 0.003*\"'smither',\" + 0.003*\"'car',\" + 0.003*\"'fire',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.009*\"'famili',\" + 0.006*\"'get',\" + 0.004*\"'tell',\" + 0.004*\"'bob',\" + 0.003*\"'springfield',\" + 0.003*\"'littl',\" + 0.003*\"'hous',\" + 0.003*\"'back',\" + 0.003*\"'show',\" + 0.003*\"'tri',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.006*\"'get',\" + 0.005*\"'famili',\" + 0.005*\"'tell',\" + 0.005*\"'springfield',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'back',\" + 0.003*\"'school',\" + 0.003*\"'say',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=1.469543, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:-7.885 per-word bound, 236.4 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.007*\"'tell',\" + 0.004*\"'take',\" + 0.004*\"'famili',\" + 0.004*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'springfield',\" + 0.003*\"'say',\" + 0.003*\"'find',\" + 0.003*\"'give',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'say',\" + 0.004*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'springfield',\" + 0.004*\"'one',\" + 0.004*\"'make',\" + 0.004*\"'tri',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.004*\"'make',\" + 0.004*\"'tell',\" + 0.004*\"'springfield',\" + 0.004*\"'famili',\" + 0.004*\"'tri',\" + 0.003*\"'back',\" + 0.003*\"'apu',\" + 0.003*\"'fire',\" + 0.003*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.008*\"'famili',\" + 0.007*\"'get',\" + 0.004*\"'tell',\" + 0.004*\"'bob',\" + 0.004*\"'springfield',\" + 0.003*\"'back',\" + 0.003*\"'show',\" + 0.003*\"'make',\" + 0.003*\"'say',\" + 0.003*\"'car',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'famili',\" + 0.005*\"'springfield',\" + 0.004*\"'make',\" + 0.004*\"'back',\" + 0.004*\"'take',\" + 0.004*\"'say',\" + 0.003*\"'selma',\" + 0.003*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.322621, rho=0.500000\n",
      "INFO:gensim.models.ldamodel:-7.671 per-word bound, 203.8 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.009*\"'get',\" + 0.007*\"'tell',\" + 0.004*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'grampa',\" + 0.003*\"'find',\" + 0.003*\"'say',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'say',\" + 0.004*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'springfield',\" + 0.004*\"'tri',\" + 0.004*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.004*\"'springfield',\" + 0.004*\"'apu',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'tell',\" + 0.003*\"'tri',\" + 0.003*\"'smither',\" + 0.003*\"'fire',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.009*\"'famili',\" + 0.006*\"'get',\" + 0.006*\"'bob',\" + 0.004*\"'tell',\" + 0.003*\"'show',\" + 0.003*\"'springfield',\" + 0.003*\"'littl',\" + 0.003*\"'back',\" + 0.003*\"'howev',\" + 0.003*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'back',\" + 0.003*\"'say',\" + 0.003*\"'selma',\" + 0.003*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.141586, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-7.714 per-word bound, 210.0 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.007*\"'tell',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'back',\" + 0.003*\"'grampa',\" + 0.003*\"'find',\" + 0.003*\"'kid',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'say',\" + 0.005*\"'tell',\" + 0.004*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'one',\" + 0.004*\"'springfield',\" + 0.004*\"'tri',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.004*\"'make',\" + 0.004*\"'springfield',\" + 0.004*\"'tell',\" + 0.004*\"'apu',\" + 0.003*\"'tri',\" + 0.003*\"'famili',\" + 0.003*\"'back',\" + 0.003*\"'fire',\" + 0.003*\"'smither',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.009*\"'famili',\" + 0.007*\"'bob',\" + 0.006*\"'get',\" + 0.004*\"'tell',\" + 0.003*\"'show',\" + 0.003*\"'springfield',\" + 0.003*\"'back',\" + 0.003*\"'make',\" + 0.003*\"'car',\" + 0.003*\"'howev',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'famili',\" + 0.005*\"'springfield',\" + 0.004*\"'selma',\" + 0.004*\"'back',\" + 0.004*\"'say',\" + 0.004*\"'take',\" + 0.003*\"'make',\" + 0.003*\"'patti',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.153071, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-7.600 per-word bound, 194.0 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.004*\"'take',\" + 0.004*\"'grampa',\" + 0.004*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'back',\" + 0.003*\"'find',\" + 0.003*\"'kid',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'say',\" + 0.004*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'one',\" + 0.004*\"'springfield',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.005*\"'apu',\" + 0.004*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'make',\" + 0.004*\"'tell',\" + 0.004*\"'famili',\" + 0.003*\"'fire',\" + 0.003*\"'tri',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.009*\"'famili',\" + 0.008*\"'bob',\" + 0.006*\"'get',\" + 0.004*\"'show',\" + 0.004*\"'tell',\" + 0.003*\"'littl',\" + 0.003*\"'springfield',\" + 0.003*\"'back',\" + 0.003*\"'howev',\" + 0.003*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'selma',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.003*\"'patti',\" + 0.003*\"'say',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.125317, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-7.653 per-word bound, 201.3 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.004*\"'take',\" + 0.004*\"'grampa',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.003*\"'back',\" + 0.003*\"'kid',\" + 0.003*\"'find',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'say',\" + 0.005*\"'tell',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'one',\" + 0.004*\"'springfield',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.004*\"'apu',\" + 0.004*\"'springfield',\" + 0.004*\"'tell',\" + 0.004*\"'make',\" + 0.003*\"'fire',\" + 0.003*\"'tri',\" + 0.003*\"'back',\" + 0.003*\"'smither',\" + 0.003*\"'famili',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.009*\"'bob',\" + 0.009*\"'famili',\" + 0.006*\"'get',\" + 0.004*\"'tell',\" + 0.003*\"'show',\" + 0.003*\"'springfield',\" + 0.003*\"'back',\" + 0.003*\"'car',\" + 0.003*\"'make',\" + 0.003*\"'howev',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.005*\"'selma',\" + 0.004*\"'back',\" + 0.004*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'patti',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.127622, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-7.573 per-word bound, 190.4 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'grampa',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.003*\"'back',\" + 0.003*\"'find',\" + 0.003*\"'kid',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.007*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'say',\" + 0.005*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'one',\" + 0.004*\"'springfield',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.006*\"'apu',\" + 0.004*\"'smither',\" + 0.004*\"'springfield',\" + 0.004*\"'fire',\" + 0.004*\"'tell',\" + 0.003*\"'make',\" + 0.003*\"'famili',\" + 0.003*\"'tri',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.010*\"'bob',\" + 0.009*\"'famili',\" + 0.005*\"'get',\" + 0.004*\"'show',\" + 0.003*\"'tell',\" + 0.003*\"'littl',\" + 0.003*\"'springfield',\" + 0.003*\"'howev',\" + 0.003*\"'back',\" + 0.003*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.005*\"'selma',\" + 0.004*\"'patti',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.003*\"'say',\" + 0.003*\"'christma',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.111301, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-7.625 per-word bound, 197.4 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'grampa',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.003*\"'find',\" + 0.003*\"'kid',\" + 0.003*\"'back',\" + 0.003*\"'gil',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'say',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'one',\" + 0.004*\"'springfield',\" + 0.004*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.005*\"'apu',\" + 0.004*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'fire',\" + 0.004*\"'tell',\" + 0.003*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'famili',\" + 0.003*\"'tri',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.011*\"'bob',\" + 0.009*\"'famili',\" + 0.006*\"'get',\" + 0.004*\"'show',\" + 0.003*\"'tell',\" + 0.003*\"'springfield',\" + 0.003*\"'car',\" + 0.003*\"'littl',\" + 0.003*\"'howev',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'selma',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'patti',\" + 0.004*\"'back',\" + 0.004*\"'say',\" + 0.004*\"'take',\" + 0.003*\"'christma',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.108983, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-7.558 per-word bound, 188.5 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'grampa',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'famili',\" + 0.003*\"'find',\" + 0.003*\"'back',\" + 0.003*\"'kid',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'say',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'one',\" + 0.004*\"'back',\" + 0.004*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.006*\"'apu',\" + 0.005*\"'smither',\" + 0.004*\"'springfield',\" + 0.004*\"'fire',\" + 0.003*\"'tell',\" + 0.003*\"'famili',\" + 0.003*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'tri',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.012*\"'bob',\" + 0.009*\"'famili',\" + 0.005*\"'get',\" + 0.004*\"'show',\" + 0.003*\"'littl',\" + 0.003*\"'springfield',\" + 0.003*\"'tell',\" + 0.003*\"'howev',\" + 0.003*\"'abe',\" + 0.003*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'selma',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'patti',\" + 0.004*\"'back',\" + 0.004*\"'take',\" + 0.004*\"'christma',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.102448, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-7.608 per-word bound, 195.1 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.007*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'grampa',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'find',\" + 0.003*\"'kid',\" + 0.003*\"'gil',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'say',\" + 0.005*\"'make',\" + 0.005*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'one',\" + 0.004*\"'back',\" + 0.004*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'get',\" + 0.005*\"'apu',\" + 0.004*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'fire',\" + 0.003*\"'tell',\" + 0.003*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'famili',\" + 0.003*\"'sing',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.012*\"'bob',\" + 0.009*\"'famili',\" + 0.005*\"'get',\" + 0.004*\"'show',\" + 0.003*\"'tell',\" + 0.003*\"'springfield',\" + 0.003*\"'littl',\" + 0.003*\"'car',\" + 0.003*\"'howev',\" + 0.003*\"'sideshow',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'selma',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'patti',\" + 0.004*\"'back',\" + 0.004*\"'say',\" + 0.004*\"'take',\" + 0.003*\"'christma',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.097063, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-7.548 per-word bound, 187.2 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.007*\"'get',\" + 0.005*\"'grampa',\" + 0.005*\"'tell',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'famili',\" + 0.003*\"'find',\" + 0.003*\"'back',\" + 0.003*\"'springfield',\" + 0.003*\"'kid',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'say',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'apu',\" + 0.006*\"'get',\" + 0.005*\"'smither',\" + 0.005*\"'springfield',\" + 0.004*\"'fire',\" + 0.003*\"'tell',\" + 0.003*\"'famili',\" + 0.003*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'sing',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.013*\"'bob',\" + 0.009*\"'famili',\" + 0.005*\"'get',\" + 0.004*\"'show',\" + 0.004*\"'littl',\" + 0.003*\"'springfield',\" + 0.003*\"'abe',\" + 0.003*\"'tell',\" + 0.003*\"'santa',\" + 0.003*\"'howev',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'selma',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'patti',\" + 0.004*\"'back',\" + 0.004*\"'christma',\" + 0.004*\"'take',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.096229, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-7.593 per-word bound, 193.0 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.007*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'grampa',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'famili',\" + 0.004*\"'find',\" + 0.003*\"'gil',\" + 0.003*\"'kid',\" + 0.003*\"'back',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.005*\"'famili',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'back',\" + 0.004*\"'one',\" + 0.004*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.006*\"'get',\" + 0.006*\"'apu',\" + 0.004*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'fire',\" + 0.003*\"'make',\" + 0.003*\"'tell',\" + 0.003*\"'sing',\" + 0.003*\"'back',\" + 0.003*\"'famili',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.013*\"'bob',\" + 0.009*\"'famili',\" + 0.005*\"'get',\" + 0.003*\"'show',\" + 0.003*\"'tell',\" + 0.003*\"'springfield',\" + 0.003*\"'littl',\" + 0.003*\"'sideshow',\" + 0.003*\"'car',\" + 0.003*\"'howev',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'selma',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.004*\"'patti',\" + 0.004*\"'back',\" + 0.004*\"'say',\" + 0.003*\"'take',\" + 0.003*\"'christma',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.088799, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-7.541 per-word bound, 186.3 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.007*\"'get',\" + 0.006*\"'grampa',\" + 0.005*\"'tell',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'famili',\" + 0.003*\"'find',\" + 0.003*\"'back',\" + 0.003*\"'springfield',\" + 0.003*\"'buck',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'apu',\" + 0.006*\"'get',\" + 0.005*\"'smither',\" + 0.005*\"'springfield',\" + 0.004*\"'fire',\" + 0.003*\"'sing',\" + 0.003*\"'famili',\" + 0.003*\"'back',\" + 0.003*\"'plant',\" + 0.003*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.014*\"'bob',\" + 0.009*\"'famili',\" + 0.004*\"'get',\" + 0.004*\"'littl',\" + 0.004*\"'show',\" + 0.003*\"'abe',\" + 0.003*\"'springfield',\" + 0.003*\"'santa',\" + 0.003*\"'sideshow',\" + 0.003*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'selma',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.005*\"'patti',\" + 0.004*\"'christma',\" + 0.004*\"'back',\" + 0.003*\"'take',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.092542, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-7.581 per-word bound, 191.5 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.007*\"'get',\" + 0.005*\"'tell',\" + 0.005*\"'grampa',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.003*\"'find',\" + 0.003*\"'gil',\" + 0.003*\"'famili',\" + 0.003*\"'kid',\" + 0.003*\"'springfield',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'make',\" + 0.005*\"'famili',\" + 0.005*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.006*\"'apu',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'fire',\" + 0.003*\"'sing',\" + 0.003*\"'make',\" + 0.003*\"'back',\" + 0.003*\"'plant',\" + 0.003*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.014*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'get',\" + 0.003*\"'sideshow',\" + 0.003*\"'show',\" + 0.003*\"'littl',\" + 0.003*\"'springfield',\" + 0.003*\"'tell',\" + 0.003*\"'abe',\" + 0.003*\"'howev',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'selma',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.005*\"'patti',\" + 0.004*\"'back',\" + 0.003*\"'say',\" + 0.003*\"'christma',\" + 0.003*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.082086, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-7.535 per-word bound, 185.5 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.007*\"'get',\" + 0.006*\"'grampa',\" + 0.005*\"'tell',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'famili',\" + 0.003*\"'find',\" + 0.003*\"'buck',\" + 0.003*\"'springfield',\" + 0.003*\"'gil',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.008*\"'apu',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'smither',\" + 0.004*\"'fire',\" + 0.003*\"'sing',\" + 0.003*\"'plant',\" + 0.003*\"'back',\" + 0.003*\"'famili',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.015*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'get',\" + 0.004*\"'littl',\" + 0.004*\"'abe',\" + 0.003*\"'show',\" + 0.003*\"'sideshow',\" + 0.003*\"'springfield',\" + 0.003*\"'santa',\" + 0.003*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.006*\"'selma',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'patti',\" + 0.005*\"'famili',\" + 0.004*\"'christma',\" + 0.004*\"'back',\" + 0.003*\"'take',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.089364, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-7.571 per-word bound, 190.1 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.006*\"'get',\" + 0.005*\"'grampa',\" + 0.005*\"'tell',\" + 0.004*\"'gil',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.003*\"'find',\" + 0.003*\"'famili',\" + 0.003*\"'kid',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'apu',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.004*\"'fire',\" + 0.004*\"'smither',\" + 0.003*\"'sing',\" + 0.003*\"'plant',\" + 0.003*\"'back',\" + 0.003*\"'make',\" + 0.003*\"'littl',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.015*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'get',\" + 0.004*\"'sideshow',\" + 0.003*\"'littl',\" + 0.003*\"'abe',\" + 0.003*\"'show',\" + 0.003*\"'springfield',\" + 0.003*\"'tell',\" + 0.003*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'tell',\" + 0.007*\"'selma',\" + 0.006*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'patti',\" + 0.005*\"'famili',\" + 0.004*\"'back',\" + 0.004*\"'christma',\" + 0.003*\"'say',\" + 0.003*\"'love',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.076867, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-7.528 per-word bound, 184.6 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.006*\"'get',\" + 0.006*\"'grampa',\" + 0.005*\"'tell',\" + 0.003*\"'take',\" + 0.003*\"'make',\" + 0.003*\"'famili',\" + 0.003*\"'find',\" + 0.003*\"'buck',\" + 0.003*\"'gil',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.008*\"'apu',\" + 0.005*\"'get',\" + 0.005*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'fire',\" + 0.004*\"'sing',\" + 0.003*\"'plant',\" + 0.003*\"'back',\" + 0.002*\"'make',\" + 0.002*\"'famili',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.016*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'littl',\" + 0.004*\"'abe',\" + 0.004*\"'sideshow',\" + 0.004*\"'get',\" + 0.003*\"'santa',\" + 0.003*\"'springfield',\" + 0.003*\"'show',\" + 0.003*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'selma',\" + 0.007*\"'tell',\" + 0.005*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'patti',\" + 0.005*\"'famili',\" + 0.004*\"'christma',\" + 0.004*\"'back',\" + 0.003*\"'take',\" + 0.003*\"'love',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.086128, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-7.563 per-word bound, 189.1 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.006*\"'get',\" + 0.005*\"'grampa',\" + 0.005*\"'tell',\" + 0.004*\"'gil',\" + 0.003*\"'make',\" + 0.003*\"'take',\" + 0.003*\"'find',\" + 0.003*\"'famili',\" + 0.003*\"'buck',\" + 0.003*\"'kid',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.009*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.005*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.007*\"'apu',\" + 0.005*\"'get',\" + 0.005*\"'springfield',\" + 0.004*\"'fire',\" + 0.004*\"'smither',\" + 0.003*\"'sing',\" + 0.003*\"'plant',\" + 0.003*\"'back',\" + 0.003*\"'littl',\" + 0.003*\"'plan',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.017*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'sideshow',\" + 0.004*\"'littl',\" + 0.004*\"'abe',\" + 0.003*\"'get',\" + 0.003*\"'springfield',\" + 0.003*\"'walt',\" + 0.003*\"'show',\" + 0.003*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'selma',\" + 0.007*\"'tell',\" + 0.005*\"'get',\" + 0.005*\"'springfield',\" + 0.005*\"'patti',\" + 0.004*\"'famili',\" + 0.004*\"'christma',\" + 0.004*\"'back',\" + 0.003*\"'love',\" + 0.003*\"'say',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic diff=0.072747, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-7.523 per-word bound, 183.9 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.006*\"'grampa',\" + 0.006*\"'get',\" + 0.005*\"'tell',\" + 0.003*\"'take',\" + 0.003*\"'make',\" + 0.003*\"'find',\" + 0.003*\"'famili',\" + 0.003*\"'buck',\" + 0.003*\"'gil',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.009*\"'get',\" + 0.006*\"'tell',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.008*\"'apu',\" + 0.005*\"'get',\" + 0.005*\"'springfield',\" + 0.004*\"'smither',\" + 0.004*\"'fire',\" + 0.004*\"'sing',\" + 0.003*\"'plant',\" + 0.002*\"'plan',\" + 0.002*\"'back',\" + 0.002*\"'power',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.017*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'littl',\" + 0.004*\"'abe',\" + 0.004*\"'sideshow',\" + 0.003*\"'santa',\" + 0.003*\"'helper',\" + 0.003*\"'springfield',\" + 0.003*\"'show',\" + 0.003*\"'get',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'selma',\" + 0.006*\"'tell',\" + 0.005*\"'springfield',\" + 0.005*\"'get',\" + 0.005*\"'patti',\" + 0.004*\"'famili',\" + 0.004*\"'christma',\" + 0.003*\"'back',\" + 0.003*\"'love',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.083462, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-7.555 per-word bound, 188.1 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.010): 0.006*\"'get',\" + 0.006*\"'grampa',\" + 0.005*\"'tell',\" + 0.004*\"'gil',\" + 0.003*\"'take',\" + 0.003*\"'make',\" + 0.003*\"'find',\" + 0.003*\"'famili',\" + 0.003*\"'buck',\" + 0.002*\"'kid',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.009*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'say',\" + 0.005*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.008*\"'apu',\" + 0.005*\"'get',\" + 0.004*\"'springfield',\" + 0.004*\"'fire',\" + 0.004*\"'sing',\" + 0.003*\"'smither',\" + 0.003*\"'plant',\" + 0.003*\"'littl',\" + 0.003*\"'plan',\" + 0.002*\"'power',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.018*\"'bob',\" + 0.008*\"'famili',\" + 0.004*\"'sideshow',\" + 0.004*\"'littl',\" + 0.004*\"'abe',\" + 0.003*\"'walt',\" + 0.003*\"'santa',\" + 0.003*\"'helper',\" + 0.003*\"'get',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.007*\"'selma',\" + 0.006*\"'tell',\" + 0.005*\"'springfield',\" + 0.005*\"'get',\" + 0.005*\"'patti',\" + 0.004*\"'famili',\" + 0.004*\"'christma',\" + 0.004*\"'back',\" + 0.003*\"'love',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.069135, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-7.518 per-word bound, 183.2 perplexity estimate based on a held-out corpus of 100 documents with 16903 words\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=K, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the below vizualisation\n",
    "* Saliency: a measure of how much the term tells you about the topic.\n",
    "* Relevance: a weighted average of the probability of the word given the topic and the word given the topic normalized by the probability of the topic.\n",
    "* The size of the bubble measures the importance of the topics, relative to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el174848489109282368255138\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el174848489109282368255138_data = {\"mdsDat\": {\"x\": [-0.06975566561667654, -0.012543300570373728, 0.010828032164098951, 0.0318201771641271, 0.03965075685882434], \"y\": [-0.01701443417197524, 0.0199203280546864, 0.04145037050652625, -0.047626996396009834, 0.0032707320067724257], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [70.13884735107422, 9.616715431213379, 7.69367790222168, 6.759005546569824, 5.791751861572266]}, \"tinfo\": {\"Term\": [\"'bob',\", \"'famili',\", \"'get',\", \"'tell',\", \"'springfield',\", \"'apu',\", \"'selma',\", \"'grampa',\", \"'smither',\", \"'littl',\", \"'fire',\", \"'back',\", \"'patti',\", \"'show',\", \"'find',\", \"'make',\", \"'take',\", \"'kill',\", \"'love',\", \"'plant',\", \"'howev',\", \"'santa',\", \"'plan',\", \"'choos',\", \"'sing',\", \"'car',\", \"'see',\", \"'toni',\", \"'abe',\", \"'sideshow',\", \"'book',\", \"'kodo',\", \"'jimbo',\", \"'nelson',\", \"'bender',\", \"'robot',\", \"'kang',\", \"'frink',\", \"'comic',\", \"'zombi',\", \"'bulli',\", \"'ralph',\", \"'camp',\", \"'clone',\", \"'halloween',\", \"'teacher',\", \"'willi',\", \"'class',\", \"'statu',\", \"'itchi',\", \"'cartoon',\", \"'movi',\", \"'grime',\", \"'case',\", \"'god',\", \"'classroom',\", \"'hutz',\", \"'rachel',\", \"'scratchi',\", \"'action',\", \"'school',\", \"'use',\", \"'guy',\", \"'snake',\", \"'film',\", \"'tri',\", \"'one',\", \"'make',\", \"'princip',\", \"'say',\", \"'get',\", \"'like',\", \"'take',\", \"'turn',\", \"'later',\", \"'hair',\", \"'show',\", \"'back',\", \"'car',\", \"'tell',\", \"'drive',\", \"'time',\", \"'decid',\", \"'famili',\", \"'peopl',\", \"'life',\", \"'friend',\", \"'see',\", \"'hous',\", \"'chief',\", \"'find',\", \"'home',\", \"'springfield',\", \"'howev',\", \"'year',\", \"'live',\", \"'ask',\", \"'give',\", \"'isabel',\", \"'boston',\", \"'edison',\", \"'botz',\", \"'armin',\", \"'hugh',\", \"'eliza',\", \"'colonel',\", \"'michael',\", \"'duncan',\", \"'album',\", \"'homer',\", \"'virgil',\", \"'sara',\", \"'maya',\", \"'comet',\", \"'truffl',\", \"'dan',\", \"'ling',\", \"'hiram',\", \"'sylvia',\", \"'alberto',\", \"'frack',\", \"'calabres',\", \"'terranc',\", \"'tattoo',\", \"'kashmir',\", \"'lemon',\", \"'candac',\", \"'campaign',\", \"'selma',\", \"'christma',\", \"'patti',\", \"'ray',\", \"'marri',\", \"'smoke',\", \"'young',\", \"'wed',\", \"'tree',\", \"'toni',\", \"'tom',\", \"'american',\", \"'springfield',\", \"'tell',\", \"'love',\", \"'santa',\", \"'edna',\", \"'present',\", \"'date',\", \"'hole',\", \"'fat',\", \"'get',\", \"'famili',\", \"'back',\", \"'move',\", \"'choos',\", \"'year',\", \"'say',\", \"'ask',\", \"'learn',\", \"'take',\", \"'find',\", \"'see',\", \"'littl',\", \"'mother',\", \"'forc',\", \"'well',\", \"'buck',\", \"'lurleen',\", \"'monorail',\", \"'tabitha',\", \"'jessica',\", \"'lanley',\", \"'mozart',\", \"'essay',\", \"'arnold',\", \"'dwight',\", \"'gil',\", \"'ribwich',\", \"'henri',\", \"'colt',\", \"'becki',\", \"'racer',\", \"'salieri',\", \"'doorbel',\", \"'lab',\", \"'bea',\", \"'zander',\", \"'alcatraaz',\", \"'brandin',\", \"'spellymp',\", \"'goggl',\", \"'annika',\", \"'cobb',\", \"'poss',\", \"'ronaldo',\", \"'cooder',\", \"'isotop',\", \"'grampa',\", \"'egg',\", \"'georg',\", \"'kirk',\", \"'mona',\", \"'bear',\", \"'paint',\", \"'lou',\", \"'houten',\", \"'rememb',\", \"'van',\", \"'get',\", \"'tell',\", \"'group',\", \"'find',\", \"'martin',\", \"'kid',\", \"'take',\", \"'make',\", \"'parent',\", \"'famili',\", \"'place',\", \"'day',\", \"'hous',\", \"'springfield',\", \"'howev',\", \"'win',\", \"'say',\", \"'back',\", \"'friend',\", \"'tri',\", \"'bob',\", \"'walt',\", \"'elon',\", \"'bongo',\", \"'smoker',\", \"'donni',\", \"'cecil',\", \"'harper',\", \"'bashir',\", \"'tow',\", \"'mason',\", \"'knight',\", \"'iceland',\", \"'marshal',\", \"'darci',\", \"'greta',\", \"'julia',\", \"'movementarian',\", \"'chong',\", \"'pub',\", \"'simon',\", \"'karl',\", \"'plow',\", \"[]\", \"'venus',\", \"'cheech',\", \"'gaga',\", \"'myrna',\", \"'tenni',\", \"'mappl',\", \"'pie',\", \"'sideshow',\", \"'abe',\", \"'puppi',\", \"'grandpa',\", \"'helper',\", \"'leader',\", \"'pumpkin',\", \"'dog',\", \"'santa',\", \"'famili',\", \"'role',\", \"'littl',\", \"'kill',\", \"'state',\", \"'convinc',\", \"'hound',\", \"'show',\", \"'smither',\", \"'car',\", \"'howev',\", \"'springfield',\", \"'prison',\", \"'face',\", \"'choos',\", \"'tell',\", \"'get',\", \"'lenni',\", \"'explain',\", \"'plan',\", \"'good',\", \"'home',\", \"'back',\", \"'actual',\", \"'ultrahous',\", \"'wayn',\", \"'herb',\", \"'raymondo',\", \"'greas',\", \"'mitzvah',\", \"'golem',\", \"'peach',\", \"'gypsi',\", \"'montymort',\", \"'charli',\", \"'munchi',\", \"'sid',\", \"'brosnan',\", \"'vamp',\", \"'gabriel',\", \"'magician',\", \"'mindi',\", \"'woodrow',\", \"'albert',\", \"'whale',\", \"'dental',\", \"'leprechaun',\", \"'rita',\", \"'clyde',\", \"'bonni',\", \"'toot',\", \"'chloe',\", \"'crawford',\", \"'allison',\", \"'manjula',\", \"'arti',\", \"'seth',\", \"'penelop',\", \"'apu',\", \"'brother',\", \"'princess',\", \"'rod',\", \"'union',\", \"'sing',\", \"'fire',\", \"'abe',\", \"'smither',\", \"'kwik',\", \"'springfield',\", \"'helper',\", \"'two',\", \"'plant',\", \"'plan',\", \"'get',\", \"'song',\", \"'littl',\", \"'power',\", \"'town',\", \"'store',\", \"'carl',\", \"'bar',\", \"'love',\", \"'santa',\", \"'back',\", \"'make',\", \"'see',\", \"'show',\", \"'famili',\", \"'tell',\"], \"Freq\": [132.0, 551.0, 820.0, 584.0, 413.0, 125.0, 129.0, 149.0, 157.0, 189.0, 174.0, 399.0, 111.0, 293.0, 305.0, 452.0, 431.0, 152.0, 196.0, 178.0, 261.0, 116.0, 151.0, 198.0, 103.0, 211.0, 285.0, 114.0, 70.0, 62.0, 143.02854919433594, 48.52809524536133, 80.99877166748047, 173.6446533203125, 43.79232406616211, 70.50638580322266, 39.08713150024414, 72.19037628173828, 123.56990814208984, 37.99234390258789, 109.38236236572266, 90.86760711669922, 71.13988494873047, 26.452945709228516, 37.392005920410156, 80.24932098388672, 151.3427734375, 121.56761169433594, 39.79488754272461, 61.64823913574219, 35.70037078857422, 157.0027313232422, 25.431777954101562, 62.59800720214844, 72.49248504638672, 29.139101028442383, 27.47181510925293, 22.980426788330078, 59.484527587890625, 47.28639602661133, 291.5725402832031, 179.6630096435547, 93.57632446289062, 116.50658416748047, 121.47474670410156, 305.41607666015625, 273.1184387207031, 384.1543884277344, 156.15252685546875, 358.85272216796875, 665.2596435546875, 163.51914978027344, 351.43304443359375, 139.82635498046875, 135.0465850830078, 114.2898941040039, 241.80227661132812, 317.0411682128906, 178.24937438964844, 445.0090637207031, 188.31900024414062, 170.9710235595703, 161.70652770996094, 410.5553894042969, 191.9823455810547, 183.8134307861328, 175.6981201171875, 226.02359008789062, 191.5789794921875, 155.9036102294922, 229.12559509277344, 192.5170440673828, 286.76116943359375, 199.6188201904297, 172.1210174560547, 163.94398498535156, 168.72061157226562, 166.9293975830078, 19.839672088623047, 10.887845039367676, 7.671943664550781, 8.46590518951416, 7.1674346923828125, 7.141220569610596, 10.207032203674316, 7.8922319412231445, 18.53554916381836, 6.5975422859191895, 6.058838844299316, 5.981690883636475, 5.372836112976074, 5.329256534576416, 5.337643146514893, 5.107804298400879, 6.061928749084473, 4.685383319854736, 4.682549953460693, 4.682340621948242, 4.676913738250732, 4.676108360290527, 4.672863006591797, 4.657162189483643, 4.654605388641357, 4.874353408813477, 4.102568626403809, 5.1347479820251465, 3.981982946395874, 9.264058113098145, 76.0937271118164, 40.69475555419922, 53.24817657470703, 15.845599174499512, 29.804702758789062, 17.681224822998047, 18.113094329833984, 17.40868377685547, 25.193300247192383, 27.588665008544922, 10.039019584655762, 15.259427070617676, 55.29164123535156, 66.9207992553711, 35.06870651245117, 24.732580184936523, 16.24527359008789, 25.426483154296875, 21.272769927978516, 14.005138397216797, 25.22231674194336, 55.284461975097656, 45.18813705444336, 36.61609649658203, 20.47394561767578, 25.73568344116211, 26.613975524902344, 33.121768951416016, 24.978864669799805, 22.686368942260742, 29.627864837646484, 25.902803421020508, 24.963071823120117, 21.85962677001953, 19.88271713256836, 20.121938705444336, 19.600265502929688, 24.306785583496094, 16.499679565429688, 15.997453689575195, 8.772256851196289, 8.89579963684082, 9.8933687210083, 8.10556697845459, 8.374614715576172, 7.452556610107422, 7.970583915710449, 33.025390625, 6.855040073394775, 6.834879398345947, 6.512179851531982, 6.028202056884766, 5.642258167266846, 5.56361198425293, 5.628408432006836, 5.319875240325928, 5.155080795288086, 4.921440124511719, 5.892480850219727, 5.53944730758667, 4.309971332550049, 5.775373458862305, 4.300238132476807, 4.253222942352295, 4.25195837020874, 5.572115898132324, 4.225470542907715, 8.902060508728027, 46.360687255859375, 11.9139404296875, 11.405003547668457, 15.640114784240723, 14.88594913482666, 17.361263275146484, 19.782997131347656, 13.492734909057617, 11.517284393310547, 14.606545448303223, 13.413949966430664, 46.97718811035156, 40.21409225463867, 16.595043182373047, 26.698835372924805, 16.540159225463867, 20.78704071044922, 27.149070739746094, 27.01444435119629, 16.561290740966797, 24.593652725219727, 17.925579071044922, 17.60851287841797, 18.085594177246094, 20.375316619873047, 17.79146385192871, 16.047195434570312, 17.960229873657227, 16.929594039916992, 15.594109535217285, 16.408794403076172, 129.56570434570312, 24.548978805541992, 13.41377067565918, 8.69871997833252, 8.08751106262207, 8.061938285827637, 9.48353385925293, 7.971354007720947, 7.9621052742004395, 5.710867881774902, 5.666347503662109, 5.6648969650268555, 5.163435935974121, 5.1338934898376465, 5.556640625, 5.147263050079346, 4.542137145996094, 4.361854553222656, 3.991260528564453, 3.990244150161743, 9.733908653259277, 3.882086992263794, 4.1707048416137695, 3.5309009552001953, 3.4934499263763428, 3.402454137802124, 3.403027057647705, 3.4700541496276855, 3.062690496444702, 3.293530225753784, 16.141944885253906, 30.54920768737793, 27.2294864654541, 6.712187767028809, 20.58748435974121, 23.518911361694336, 6.962701797485352, 7.9873199462890625, 20.123489379882812, 24.047861099243164, 58.45314407348633, 12.277604103088379, 27.486709594726562, 19.55727195739746, 17.042728424072266, 18.059513092041016, 7.664231777191162, 22.1906681060791, 16.91842269897461, 18.50986099243164, 19.77682113647461, 22.537979125976562, 13.261119842529297, 14.122544288635254, 16.042573928833008, 21.022192001342773, 22.627893447875977, 15.022258758544922, 15.944490432739258, 14.720475196838379, 14.504371643066406, 14.223140716552734, 13.769484519958496, 13.486736297607422, 9.670351028442383, 8.130279541015625, 5.847033500671387, 5.904332160949707, 5.658423900604248, 5.380526542663574, 5.8352131843566895, 5.354518413543701, 5.22258996963501, 5.219762325286865, 6.519317626953125, 4.4881157875061035, 4.282203197479248, 4.410262584686279, 3.730815887451172, 3.999617099761963, 3.7028989791870117, 4.288626194000244, 3.9593935012817383, 3.681389331817627, 11.880130767822266, 3.635885238647461, 8.143306732177734, 3.552344560623169, 3.18060564994812, 3.180447578430176, 3.173536777496338, 3.1698660850524902, 3.1577646732330322, 3.2278482913970947, 11.429262161254883, 15.290462493896484, 4.47253942489624, 4.822352409362793, 47.27812194824219, 14.488632202148438, 7.3096795082092285, 14.538451194763184, 7.528998851776123, 22.903724670410156, 23.994855880737305, 14.564905166625977, 21.380834579467773, 10.96732234954834, 28.17992401123047, 13.855193138122559, 15.184491157531738, 18.111595153808594, 16.395753860473633, 30.402931213378906, 14.282710075378418, 16.440610885620117, 15.62075424194336, 13.240082740783691, 13.821296691894531, 13.129605293273926, 12.588171005249023, 13.818217277526855, 12.006926536560059, 15.331228256225586, 14.619174003601074, 13.355262756347656, 12.50247573852539, 12.933629035949707, 11.802681922912598], \"Total\": [132.0, 551.0, 820.0, 584.0, 413.0, 125.0, 129.0, 149.0, 157.0, 189.0, 174.0, 399.0, 111.0, 293.0, 305.0, 452.0, 431.0, 152.0, 196.0, 178.0, 261.0, 116.0, 151.0, 198.0, 103.0, 211.0, 285.0, 114.0, 70.0, 62.0, 148.32339477539062, 50.65983581542969, 84.57359313964844, 181.7013702392578, 45.95275115966797, 74.0519790649414, 41.19481658935547, 76.17864227294922, 130.8937530517578, 40.48643112182617, 116.64778900146484, 96.9576416015625, 76.34182739257812, 28.409507751464844, 40.25267028808594, 86.9468002319336, 164.0228729248047, 131.80796813964844, 43.16714859008789, 66.90779113769531, 38.823516845703125, 170.99923706054688, 27.712064743041992, 68.29460144042969, 79.22924041748047, 31.876562118530273, 30.085601806640625, 25.195812225341797, 65.24242401123047, 51.945396423339844, 321.47528076171875, 198.1927947998047, 102.8345718383789, 128.6983184814453, 134.2731475830078, 350.3648681640625, 314.1348571777344, 452.3142395019531, 177.3587188720703, 428.2432556152344, 820.5521240234375, 188.0403594970703, 431.0914611816406, 160.57957458496094, 155.0712432861328, 129.3885498046875, 293.1206970214844, 399.68756103515625, 211.34609985351562, 584.9688720703125, 224.99899291992188, 202.0544891357422, 190.24342346191406, 551.7239990234375, 231.336669921875, 221.6055145263672, 210.5192108154297, 285.49169921875, 234.52967834472656, 183.3472900390625, 305.6764221191406, 242.37860107421875, 413.14599609375, 261.4325256347656, 217.10877990722656, 198.01470947265625, 217.56309509277344, 211.0941619873047, 23.015960693359375, 13.246390342712402, 10.042743682861328, 11.232161521911621, 9.52504825592041, 9.523622512817383, 13.763559341430664, 10.763422966003418, 25.431188583374023, 9.059966087341309, 8.568476676940918, 8.468795776367188, 7.718324661254883, 7.71890926361084, 7.742264747619629, 7.486260414123535, 8.900291442871094, 7.027044296264648, 7.0257978439331055, 7.027326583862305, 7.03126335144043, 7.03123140335083, 7.033885478973389, 7.046943664550781, 7.044860363006592, 7.486520290374756, 6.463504314422607, 8.118331909179688, 6.344193935394287, 15.061165809631348, 129.46678161621094, 71.13433837890625, 111.49332427978516, 31.82868194580078, 75.0281753540039, 46.22226333618164, 48.85060119628906, 52.217430114746094, 94.94771575927734, 114.27947998046875, 23.380264282226562, 48.18906784057617, 413.14599609375, 584.9688720703125, 196.23370361328125, 116.17826843261719, 55.63338851928711, 127.98822784423828, 92.29639434814453, 45.285667419433594, 147.6840362548828, 820.5521240234375, 551.7239990234375, 399.68756103515625, 111.38511657714844, 198.2242889404297, 217.10877990722656, 428.2432556152344, 217.56309509277344, 166.37100219726562, 431.0914611816406, 305.6764221191406, 285.49169921875, 189.1342010498047, 125.54763793945312, 190.0866241455078, 168.22213745117188, 27.668323516845703, 18.969038009643555, 20.30177116394043, 11.165367126464844, 11.420221328735352, 12.764638900756836, 10.542152404785156, 10.909980773925781, 9.967584609985352, 10.671557426452637, 44.269126892089844, 9.256160736083984, 9.267796516418457, 9.088541984558105, 8.63486099243164, 8.087240219116211, 7.993585586547852, 8.100218772888184, 7.84716272354126, 7.62675666809082, 7.369822978973389, 8.911038398742676, 8.616777420043945, 6.707822322845459, 9.014358520507812, 6.7174906730651855, 6.654791355133057, 6.655000686645508, 8.794178009033203, 6.680210113525391, 14.156591415405273, 149.35794067382812, 25.79277229309082, 27.071287155151367, 44.18259811401367, 41.279335021972656, 52.63304138183594, 66.72540283203125, 39.890159606933594, 30.525192260742188, 57.69306564331055, 52.626216888427734, 820.5521240234375, 584.9688720703125, 87.64403533935547, 305.6764221191406, 98.21076202392578, 177.3422088623047, 431.0914611816406, 452.3142395019531, 117.28624725341797, 551.7239990234375, 180.7720947265625, 201.88638305664062, 234.52967834472656, 413.14599609375, 261.4325256347656, 167.38558959960938, 428.2432556152344, 399.68756103515625, 210.5192108154297, 350.3648681640625, 132.56082153320312, 28.086748123168945, 15.838743209838867, 11.125237464904785, 10.554752349853516, 10.588072776794434, 12.498822212219238, 10.684755325317383, 10.694005966186523, 8.220726013183594, 8.270606994628906, 8.27470874786377, 7.5981526374816895, 7.618510723114014, 8.278580665588379, 7.773134231567383, 7.037624835968018, 6.809920787811279, 6.412907600402832, 6.414852142333984, 15.688756942749023, 6.421270847320557, 6.980413436889648, 5.953369140625, 5.940438747406006, 5.823991775512695, 5.825811386108398, 5.963439464569092, 5.500080108642578, 5.938498020172119, 30.734525680541992, 62.98736572265625, 70.93265533447266, 14.106179237365723, 67.85271453857422, 90.03716278076172, 16.02022933959961, 19.8000431060791, 86.16471862792969, 116.17826843261719, 551.7239990234375, 41.19077682495117, 189.1342010498047, 152.21673583984375, 144.72337341308594, 170.2857666015625, 20.263643264770508, 293.1206970214844, 157.90939331054688, 211.34609985351562, 261.4325256347656, 413.14599609375, 91.0306396484375, 120.10273742675781, 198.2242889404297, 584.9688720703125, 820.5521240234375, 152.58522033691406, 201.95069885253906, 151.80194091796875, 169.27366638183594, 242.37860107421875, 399.68756103515625, 171.3875732421875, 12.381587982177734, 10.60317611694336, 8.340599060058594, 8.427289962768555, 8.249128341674805, 7.846682548522949, 8.510047912597656, 7.875920295715332, 7.867225646972656, 7.873385429382324, 9.930251121520996, 6.964338302612305, 6.741225719451904, 7.052231788635254, 6.190326690673828, 6.656167984008789, 6.221992492675781, 7.2063727378845215, 6.698984146118164, 6.24865198135376, 20.218812942504883, 6.192001819610596, 14.130517959594727, 6.199513912200928, 5.639106750488281, 5.639162063598633, 5.647007942199707, 5.652940273284912, 5.66555118560791, 5.793529510498047, 21.46835708618164, 29.95563507080078, 8.189556121826172, 9.089302062988281, 125.4014892578125, 34.15135192871094, 15.183130264282227, 37.37895965576172, 17.516263961791992, 103.36187744140625, 174.5669708251953, 70.93265533447266, 157.90939331054688, 51.91718292236328, 413.14599609375, 90.03716278076172, 110.31969451904297, 178.54534912109375, 151.80194091796875, 820.5521240234375, 112.3871078491211, 189.1342010498047, 167.70094299316406, 106.61122131347656, 140.146484375, 126.47160339355469, 118.35637664794922, 196.23370361328125, 116.17826843261719, 399.68756103515625, 452.3142395019531, 285.49169921875, 293.1206970214844, 551.7239990234375, 584.9688720703125], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.279300212860107, -7.360199928283691, -6.847899913787842, -6.085299968719482, -7.462900161743164, -6.986599922180176, -7.576499938964844, -6.9629998207092285, -6.42549991607666, -7.604899883270264, -6.547500133514404, -6.732900142669678, -6.977700233459473, -7.9670000076293945, -7.6209001541137695, -6.8572001457214355, -6.222799777984619, -6.44189977645874, -7.558599948883057, -7.1209001541137695, -7.667200088500977, -6.186100006103516, -8.00629997253418, -7.105599880218506, -6.958899974822998, -7.870299816131592, -7.929200172424316, -8.10770034790039, -7.156599998474121, -7.386099815368652, -5.566999912261963, -6.051300048828125, -6.70359992980957, -6.484399795532227, -6.442599773406982, -5.520699977874756, -5.632400035858154, -5.291299819946289, -6.191500186920166, -5.359399795532227, -4.742199897766113, -6.145400047302246, -5.380300045013428, -6.3018999099731445, -6.336699962615967, -6.503600120544434, -5.754199981689453, -5.48330020904541, -6.059199810028076, -5.144199848175049, -6.004199981689453, -6.100800037384033, -6.156599998474121, -5.224800109863281, -5.984899997711182, -6.02839994430542, -6.073599815368652, -5.821700096130371, -5.986999988555908, -6.1930999755859375, -5.80810022354126, -5.982100009918213, -5.583700180053711, -5.945899963378906, -6.094099998474121, -6.1427998542785645, -6.114099979400635, -6.124800205230713, -6.2677001953125, -6.867700099945068, -7.217800140380859, -7.11929988861084, -7.285799980163574, -7.2895002365112305, -6.932300090789795, -7.189499855041504, -6.335700035095215, -7.36870002746582, -7.453800201416016, -7.466700077056885, -7.573999881744385, -7.582099914550781, -7.580599784851074, -7.624599933624268, -7.4532999992370605, -7.710899829864502, -7.71150016784668, -7.711599826812744, -7.712699890136719, -7.712900161743164, -7.713600158691406, -7.7170000076293945, -7.71750020980835, -7.67140007019043, -7.843699932098389, -7.61929988861084, -7.873600006103516, -7.029200077056885, -4.923399925231934, -5.549300193786621, -5.280399799346924, -6.492499828338623, -5.8607001304626465, -6.382900238037109, -6.358699798583984, -6.398399829864502, -6.028800010681152, -5.938000202178955, -6.94890022277832, -6.530200004577637, -5.242700099945068, -5.051799774169922, -5.6981000900268555, -6.0472002029418945, -6.467599868774414, -6.019599914550781, -6.19789981842041, -6.615900039672852, -6.027599811553955, -5.2428998947143555, -5.444499969482422, -5.654900074005127, -6.236199855804443, -6.007500171661377, -5.973899841308594, -5.755199909210205, -6.037300109863281, -6.133600234985352, -5.866600036621094, -6.000999927520752, -6.038000106811523, -6.1707000732421875, -6.265500068664551, -6.253499984741211, -6.279799938201904, -5.8414998054504395, -6.228899955749512, -6.259799957275391, -6.8607001304626465, -6.846700191497803, -6.7403998374938965, -6.939700126647949, -6.907100200653076, -7.02370023727417, -6.956500053405762, -5.534999847412109, -7.1072998046875, -7.110199928283691, -7.158599853515625, -7.235799789428711, -7.302000045776367, -7.315999984741211, -7.3043999671936035, -7.360799789428711, -7.392300128936768, -7.438700199127197, -7.258600234985352, -7.320400238037109, -7.571300029754639, -7.27869987487793, -7.573599815368652, -7.58459997177124, -7.58489990234375, -7.314499855041504, -7.591100215911865, -6.8460001945495605, -5.195799827575684, -6.554500102996826, -6.598199844360352, -6.282400131225586, -6.3317999839782715, -6.177999973297119, -6.047399997711182, -6.430099964141846, -6.588399887084961, -6.350800037384033, -6.435999870300293, -5.182600021362305, -5.3379998207092285, -6.223199844360352, -5.747600078582764, -6.226500034332275, -5.997900009155273, -5.730899810791016, -5.735899925231934, -6.225200176239014, -5.829800128936768, -6.145999908447266, -6.163899898529053, -6.1371002197265625, -6.017899990081787, -6.153500080108643, -6.256700038909912, -6.144100189208984, -6.203199863433838, -6.285399913787842, -6.234399795532227, -4.03849983215332, -5.702099800109863, -6.30649995803833, -6.73960018157959, -6.812399864196777, -6.8155999183654785, -6.653200149536133, -6.826900005340576, -6.828000068664551, -7.160399913787842, -7.1682000160217285, -7.168399810791016, -7.261099815368652, -7.266900062561035, -7.187699794769287, -7.2642998695373535, -7.3892998695373535, -7.429800033569336, -7.518599987030029, -7.518899917602539, -6.627099990844727, -7.54640007019043, -7.474599838256836, -7.641200065612793, -7.651800155639648, -7.678199768066406, -7.678100109100342, -7.658599853515625, -7.783400058746338, -7.7108001708984375, -6.121300220489502, -5.483399868011475, -5.598400115966797, -6.998799800872803, -5.877999782562256, -5.744900226593018, -6.962200164794922, -6.824900150299072, -5.9008002281188965, -5.722700119018555, -4.834499835968018, -6.394999980926514, -5.589000225067139, -5.9293999671936035, -6.066999912261963, -6.009099960327148, -6.866199970245361, -5.803100109100342, -6.0742998123168945, -5.984399795532227, -5.9182000160217285, -5.787499904632568, -6.31790018081665, -6.255000114440918, -6.127500057220459, -5.8572001457214355, -5.7835001945495605, -6.19320011138916, -6.133600234985352, -6.213500022888184, -6.228300094604492, -6.247900009155273, -6.280300140380859, -6.301000118255615, -6.4791998863220215, -6.652699947357178, -6.982399940490723, -6.972599983215332, -7.015100002288818, -7.065499782562256, -6.984399795532227, -7.070400238037109, -7.095300197601318, -7.095799922943115, -6.873499870300293, -7.2469000816345215, -7.293799877166748, -7.264400005340576, -7.431700229644775, -7.362100124359131, -7.439199924468994, -7.292300224304199, -7.372200012207031, -7.445000171661377, -6.273399829864502, -7.457399845123291, -6.651100158691406, -7.4807000160217285, -7.59119987487793, -7.591300010681152, -7.593400001525879, -7.594600200653076, -7.598400115966797, -7.576499938964844, -6.312099933624268, -6.021100044250488, -7.25029993057251, -7.175000190734863, -4.892199993133545, -6.074900150299072, -6.759099960327148, -6.071499824523926, -6.729499816894531, -5.617000102996826, -5.570499897003174, -6.069699764251709, -5.685800075531006, -6.353400230407715, -5.4096999168396, -6.11959981918335, -6.0279998779296875, -5.8516998291015625, -5.951300144195557, -5.333799839019775, -6.089200019836426, -5.948500156402588, -5.99970006942749, -6.164999961853027, -6.122099876403809, -6.173399925231934, -6.2154998779296875, -6.122300148010254, -6.262800216674805, -6.018400192260742, -6.065999984741211, -6.156400203704834, -6.222400188446045, -6.188499927520752, -6.28000020980835], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3183000087738037, 0.3116999864578247, 0.31150001287460327, 0.3093000054359436, 0.30649998784065247, 0.30559998750686646, 0.30219998955726624, 0.30090001225471497, 0.2971000075340271, 0.29109999537467957, 0.2903999984264374, 0.2897999882698059, 0.2840999960899353, 0.2833000123500824, 0.2809999883174896, 0.2745000123977661, 0.2741999924182892, 0.27379998564720154, 0.2734000086784363, 0.2727999985218048, 0.27079999446868896, 0.26930001378059387, 0.2687999904155731, 0.26759999990463257, 0.26579999923706055, 0.26489999890327454, 0.2637999951839447, 0.26269999146461487, 0.2623000144958496, 0.260699987411499, 0.257099986076355, 0.2565000057220459, 0.26030001044273376, 0.25519999861717224, 0.25450000166893005, 0.21739999949932098, 0.21480000019073486, 0.19140000641345978, 0.227400004863739, 0.17790000140666962, 0.14489999413490295, 0.2150000035762787, 0.15039999783039093, 0.21629999577999115, 0.21639999747276306, 0.2305999994277954, 0.16220000386238098, 0.12300000339746475, 0.18440000712871552, 0.0812000036239624, 0.17669999599456787, 0.18770000338554382, 0.19220000505447388, 0.05920000001788139, 0.16820000112056732, 0.16769999265670776, 0.17389999330043793, 0.12110000103712082, 0.15240000188350677, 0.19249999523162842, 0.06639999896287918, 0.12439999729394913, -0.010499999858438969, 0.08489999920129776, 0.12250000238418579, 0.16590000689029694, 0.10040000081062317, 0.11999999731779099, 2.19320011138916, 2.1456000804901123, 2.0724000930786133, 2.0589001178741455, 2.057300090789795, 2.053800106048584, 2.0427000522613525, 2.031399965286255, 2.025399923324585, 2.0244998931884766, 1.9951000213623047, 1.99399995803833, 1.9794000387191772, 1.9711999893188477, 1.9697999954223633, 1.9594000577926636, 1.9575999975204468, 1.9363000392913818, 1.9358999729156494, 1.9357000589370728, 1.933899998664856, 1.9337999820709229, 1.9327000379562378, 1.9275000095367432, 1.9271999597549438, 1.912600040435791, 1.8870999813079834, 1.8835999965667725, 1.8759000301361084, 1.8557000160217285, 1.8101999759674072, 1.7832000255584717, 1.6026999950408936, 1.6441999673843384, 1.4184999465942383, 1.3806999921798706, 1.3494999408721924, 1.2431999444961548, 1.0148999691009521, 0.9204000234603882, 1.4962999820709229, 1.1916999816894531, 0.3305000066757202, 0.1736000031232834, 0.619700014591217, 0.794700026512146, 1.110700011253357, 0.7254999876022339, 0.8741000294685364, 1.1680999994277954, 0.5742999911308289, -0.35580000281333923, -0.16050000488758087, -0.048500001430511475, 0.6478000283241272, 0.3000999987125397, 0.24269999563694, -0.21780000627040863, 0.17720000445842743, 0.3492000102996826, -0.3359000086784363, -0.1264999955892563, -0.09510000050067902, 0.18389999866485596, 0.49880000948905945, 0.09600000083446503, 0.19189999997615814, 2.4351999759674072, 2.425299882888794, 2.3264999389648438, 2.323499917984009, 2.315000057220459, 2.309999942779541, 2.3018999099731445, 2.300299882888794, 2.2739999294281006, 2.272900104522705, 2.2718000411987305, 2.2644999027252197, 2.2602999210357666, 2.2314000129699707, 2.205399990081787, 2.2047998905181885, 2.202399969100952, 2.200700044631958, 2.176100015640259, 2.173099994659424, 2.1610000133514404, 2.15120005607605, 2.122999906539917, 2.1224000453948975, 2.1196000576019287, 2.1187000274658203, 2.1171000003814697, 2.11680006980896, 2.1085000038146973, 2.106800079345703, 2.1008999347686768, 1.3948999643325806, 1.7924000024795532, 1.7002999782562256, 1.5262999534606934, 1.544800043106079, 1.4557000398635864, 1.3489999771118164, 1.4808000326156616, 1.5901000499725342, 1.191100001335144, 1.1979000568389893, -0.2955000102519989, -0.11259999871253967, 0.900600016117096, 0.12690000236034393, 0.7833999991416931, 0.42100000381469727, -0.20020000636577606, -0.2531999945640564, 0.607200026512146, -0.545799970626831, 0.25380000472068787, 0.12540000677108765, 0.002300000051036477, -0.4447000026702881, -0.12269999831914902, 0.2199999988079071, -0.6068000197410583, -0.5968000292778015, -0.03790000081062317, -0.49639999866485596, 2.6714000701904297, 2.5597000122070312, 2.52810001373291, 2.4482998847961426, 2.427999973297119, 2.4217000007629395, 2.4182000160217285, 2.4012999534606934, 2.3993000984191895, 2.3299999237060547, 2.3160998821258545, 2.3153998851776123, 2.308000087738037, 2.2995998859405518, 2.295599937438965, 2.282099962234497, 2.2564001083374023, 2.248800039291382, 2.220099925994873, 2.2195000648498535, 2.2170000076293945, 2.1910998821258545, 2.17930006980896, 2.1719000339508057, 2.1633999347686768, 2.1568000316619873, 2.1566998958587646, 2.1528000831604004, 2.108799934387207, 2.10479998588562, 2.050299882888794, 1.9707000255584717, 1.736899971961975, 1.9515999555587769, 1.5016000270843506, 1.3518999814987183, 1.8609999418258667, 1.7864999771118164, 1.23989999294281, 1.1191999912261963, 0.4494999945163727, 1.4838999509811401, 0.765500009059906, 0.642300009727478, 0.5551999807357788, 0.4505000114440918, 1.722000002861023, 0.11339999735355377, 0.46070000529289246, 0.2590999901294708, 0.11259999871253967, -0.2143000066280365, 0.7678999900817871, 0.5536999702453613, 0.1800999939441681, -0.6316999793052673, -0.8964999914169312, 0.37610000371932983, 0.15539999306201935, 0.3610000014305115, 0.23720000684261322, -0.1412999927997589, -0.6739000082015991, 0.15209999680519104, 2.601599931716919, 2.583199977874756, 2.493499994277954, 2.4928998947143555, 2.4718000888824463, 2.471400022506714, 2.471400022506714, 2.462899923324585, 2.438999891281128, 2.437700033187866, 2.4279000759124756, 2.40939998626709, 2.3949999809265137, 2.379300117492676, 2.342400074005127, 2.339400053024292, 2.3297998905181885, 2.329699993133545, 2.3229000568389893, 2.319700002670288, 2.316999912261963, 2.3162999153137207, 2.297600030899048, 2.2918999195098877, 2.276099920272827, 2.2760000228881836, 2.2725000381469727, 2.27020001411438, 2.26419997215271, 2.2637999057769775, 2.2183001041412354, 2.1761999130249023, 2.243799924850464, 2.214900016784668, 1.8732999563217163, 1.9912999868392944, 2.117799997329712, 1.9043999910354614, 2.0044000148773193, 1.3417999744415283, 0.864300012588501, 1.2655999660491943, 0.8492000102996826, 1.2940000295639038, 0.16349999606609344, 0.9771999716758728, 0.8655999898910522, 0.5604000091552734, 0.623199999332428, -0.44670000672340393, 0.7857999801635742, 0.4059999883174896, 0.47519999742507935, 0.7627999782562256, 0.5322999954223633, 0.5835999846458435, 0.6078000068664551, 0.19539999961853027, 0.5791000127792358, -0.4120999872684479, -0.583299994468689, -0.21359999477863312, -0.3059000074863434, -0.9045000076293945, -1.0544999837875366]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 1, 2, 1, 2, 3, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 5, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 4], \"Freq\": [0.3383491039276123, 0.028195757418870926, 0.028195757418870926, 0.38064274191856384, 0.2114681899547577, 0.9047962427139282, 0.03850196674466133, 0.019250983372330666, 0.019250983372330666, 0.019250983372330666, 0.7643494606018066, 0.08752093464136124, 0.023338915780186653, 0.07585147023200989, 0.04084309935569763, 0.16003452241420746, 0.16003452241420746, 0.6401380896568298, 0.142222598195076, 0.7111129760742188, 0.11670685559511185, 0.7002411484718323, 0.22444073855876923, 0.11222036927938461, 0.6733222007751465, 0.17260634899139404, 0.17260634899139404, 0.5178190469741821, 0.4772866666316986, 0.3112739324569702, 0.14526116847991943, 0.020751595497131348, 0.041503190994262695, 0.14886511862277985, 0.14886511862277985, 0.5954604744911194, 0.5502327084541321, 0.055820707231760025, 0.007974387146532536, 0.007974387146532536, 0.37479618191719055, 0.10498634725809097, 0.734904408454895, 0.10498634725809097, 0.10032520443201065, 0.10032520443201065, 0.7022764682769775, 0.10014810413122177, 0.36720970273017883, 0.03338269889354706, 0.5007405281066895, 0.7767861485481262, 0.11490919440984726, 0.045963678508996964, 0.03677094355225563, 0.027578206732869148, 0.793119490146637, 0.09257230907678604, 0.04253322258591652, 0.035027358680963516, 0.037529315799474716, 0.7266190648078918, 0.10983776301145554, 0.01689811795949936, 0.03379623591899872, 0.10983776301145554, 0.09351032972335815, 0.09351032972335815, 0.7480826377868652, 0.1311173290014267, 0.1311173290014267, 0.6555866599082947, 0.6079831123352051, 0.03799894452095032, 0.3229910135269165, 0.01899947226047516, 0.01899947226047516, 0.11580962687730789, 0.11580962687730789, 0.6948577165603638, 0.9575052261352539, 0.02176148258149624, 0.02176148258149624, 0.02176148258149624, 0.007543706800788641, 0.007543706800788641, 0.007543706800788641, 0.9806818962097168, 0.007543706800788641, 0.08988571912050247, 0.08988571912050247, 0.08988571912050247, 0.8089715242385864, 0.17733131349086761, 0.17733131349086761, 0.5319939255714417, 0.9641095399856567, 0.013484049588441849, 0.006742024794220924, 0.013484049588441849, 0.006742024794220924, 0.075492262840271, 0.830414891242981, 0.075492262840271, 0.08903005719184875, 0.71224045753479, 0.08903005719184875, 0.11605266481637955, 0.11605266481637955, 0.6963160037994385, 0.11605266481637955, 0.14179907739162445, 0.14179907739162445, 0.14179907739162445, 0.5671963095664978, 0.26353275775909424, 0.1756885051727295, 0.029281416907906532, 0.08784425258636475, 0.40993985533714294, 0.07228482514619827, 0.036142412573099136, 0.8674179315567017, 0.9344369173049927, 0.017145631834864616, 0.017145631834864616, 0.017145631834864616, 0.017145631834864616, 0.14190548658370972, 0.7095274329185486, 0.9300275444984436, 0.013098979368805885, 0.013098979368805885, 0.02619795873761177, 0.013098979368805885, 0.199187770485878, 0.5975633263587952, 0.06639592349529266, 0.06639592349529266, 0.06639592349529266, 0.15762443840503693, 0.6304977536201477, 0.8422204256057739, 0.01892630197107792, 0.014194726012647152, 0.0898999348282814, 0.033121027052402496, 0.751156747341156, 0.023720739409327507, 0.03162765130400658, 0.09488295763731003, 0.10278987139463425, 0.9272730350494385, 0.02575758472084999, 0.02575758472084999, 0.02575758472084999, 0.02575758472084999, 0.9224740862846375, 0.029284890741109848, 0.029284890741109848, 0.014642445370554924, 0.014642445370554924, 0.08000753819942474, 0.08000753819942474, 0.08000753819942474, 0.7200678586959839, 0.08000753819942474, 0.10070239007472992, 0.10070239007472992, 0.10070239007472992, 0.7049167156219482, 0.1717035323381424, 0.1717035323381424, 0.5151106119155884, 0.8508443236351013, 0.02727065049111843, 0.02727065049111843, 0.06544956564903259, 0.02727065049111843, 0.17689909040927887, 0.17689909040927887, 0.5306972861289978, 0.15593551099300385, 0.15593551099300385, 0.6237420439720154, 0.7012258768081665, 0.13116455078125, 0.040358323603868484, 0.08071664720773697, 0.05044790357351303, 0.2530423402786255, 0.5763742327690125, 0.11246326565742493, 0.04217372462153435, 0.014057908207178116, 0.9255889654159546, 0.03793397545814514, 0.015173589810729027, 0.022760383784770966, 0.007586794905364513, 0.9097593426704407, 0.03137101233005524, 0.03137101233005524, 0.03137101233005524, 0.03137101233005524, 0.9151865839958191, 0.03519948199391365, 0.03519948199391365, 0.1773330569267273, 0.1773330569267273, 0.5319991707801819, 0.15026767551898956, 0.15026767551898956, 0.6010707020759583, 0.09290724992752075, 0.743257999420166, 0.09290724992752075, 0.09290724992752075, 0.11002864688634872, 0.11002864688634872, 0.7702005505561829, 0.13357804715633392, 0.667890191078186, 0.9473332166671753, 0.015279567800462246, 0.007639783900231123, 0.007639783900231123, 0.015279567800462246, 0.7046977877616882, 0.07634225487709045, 0.06459729373455048, 0.105704665184021, 0.04110737144947052, 0.14969588816165924, 0.14969588816165924, 0.598783552646637, 0.17650532722473145, 0.17650532722473145, 0.5295159816741943, 0.1423073410987854, 0.711536705493927, 0.1207936555147171, 0.1207936555147171, 0.7247619032859802, 0.6717488765716553, 0.22752784192562103, 0.04333863779902458, 0.02166931889951229, 0.04333863779902458, 0.7875716686248779, 0.07925249636173248, 0.0891590565443039, 0.01981312409043312, 0.02971968613564968, 0.8515406250953674, 0.04205138608813286, 0.05782065913081169, 0.02102569304406643, 0.03153854236006737, 0.16149866580963135, 0.16149866580963135, 0.16149866580963135, 0.6459946632385254, 0.47583281993865967, 0.0812397450208664, 0.11605678498744965, 0.2321135699748993, 0.10445110499858856, 0.09444589167833328, 0.09444589167833328, 0.7555671334266663, 0.12345345318317413, 0.12345345318317413, 0.7407207489013672, 0.8355593085289001, 0.053333573043346405, 0.04888910800218582, 0.031111249700188637, 0.026666786521673203, 0.11037568747997284, 0.7726297974586487, 0.09370703250169754, 0.09370703250169754, 0.7496562600135803, 0.09957437962293625, 0.79659503698349, 0.5931689739227295, 0.28759709000587463, 0.017974818125367165, 0.017974818125367165, 0.08987408876419067, 0.3101644217967987, 0.03877055272459984, 0.46524661779403687, 0.15508221089839935, 0.03877055272459984, 0.14531125128269196, 0.7265562415122986, 0.07265562564134598, 0.06313632428646088, 0.06313632428646088, 0.8207721710205078, 0.09165918827056885, 0.09165918827056885, 0.7332735061645508, 0.7229487299919128, 0.08913066238164902, 0.06932385265827179, 0.0792272537946701, 0.03961362689733505, 0.7909894585609436, 0.041631024330854416, 0.02497861534357071, 0.11656686663627625, 0.02497861534357071, 0.7449376583099365, 0.08156251907348633, 0.045312512665987015, 0.10512502491474152, 0.023562505841255188, 0.8125454783439636, 0.16928032040596008, 0.0067712124437093735, 0.0067712124437093735, 0.9011481404304504, 0.03723752871155739, 0.014895010739564896, 0.014895010739564896, 0.02979002147912979, 0.7491582036018372, 0.08505726605653763, 0.08832869678735733, 0.042528633028268814, 0.03598576411604881, 0.7275145053863525, 0.06301306933164597, 0.017185380682349205, 0.057284604758024216, 0.13748304545879364, 0.7733316421508789, 0.10521519184112549, 0.042086075991392136, 0.052607595920562744, 0.03156455606222153, 0.14216893911361694, 0.7108446955680847, 0.8360282182693481, 0.03325112164020538, 0.0760025680065155, 0.028500961139798164, 0.03325112164020538, 0.9451467990875244, 0.013127039186656475, 0.013127039186656475, 0.02625407837331295, 0.013127039186656475, 0.1502365916967392, 0.1502365916967392, 0.6009463667869568, 0.17164990305900574, 0.17164990305900574, 0.5149497389793396, 0.4063345789909363, 0.036939505487680435, 0.4063345789909363, 0.036939505487680435, 0.07387901097536087, 0.8104299306869507, 0.06702803820371628, 0.057278506457805634, 0.0280299074947834, 0.036560747772455215, 0.20330195128917694, 0.022589106112718582, 0.7454404830932617, 0.022589106112718582, 0.7911161184310913, 0.037897780537605286, 0.06632111221551895, 0.05684667080640793, 0.04737222567200661, 0.9087554216384888, 0.012621602974832058, 0.0378648079931736, 0.012621602974832058, 0.025243205949664116, 0.22186826169490814, 0.11093413084745407, 0.6656047701835632, 0.11750815063714981, 0.11750815063714981, 0.7050489187240601, 0.7857099175453186, 0.047260746359825134, 0.05907593294978142, 0.08861390501260757, 0.017722779884934425, 0.5557119846343994, 0.04017195105552673, 0.30798497796058655, 0.03347662836313248, 0.053562603890895844, 0.6189877390861511, 0.04421341046690941, 0.014737803488969803, 0.30949386954307556, 0.014737803488969803, 0.12122493237257004, 0.12122493237257004, 0.12122493237257004, 0.727349579334259, 0.12864823639392853, 0.12864823639392853, 0.6432411670684814, 0.9021341800689697, 0.03608536720275879, 0.03608536720275879, 0.5362601280212402, 0.17114683985710144, 0.19396641850471497, 0.03422936797142029, 0.057048946619033813, 0.9140895009040833, 0.019448712468147278, 0.038897424936294556, 0.009724356234073639, 0.029173068702220917, 0.1271096169948578, 0.1271096169948578, 0.1271096169948578, 0.6355480551719666, 0.881067156791687, 0.03864329680800438, 0.023185977712273598, 0.046371955424547195, 0.015457318164408207, 0.919193685054779, 0.02484307251870632, 0.02484307251870632, 0.02484307251870632, 0.02484307251870632, 0.09359128773212433, 0.09359128773212433, 0.7487303018569946, 0.39983490109443665, 0.13327829539775848, 0.05553262680768967, 0.26655659079551697, 0.15549135208129883, 0.10790051519870758, 0.10790051519870758, 0.7553036212921143, 0.11989546567201614, 0.11989546567201614, 0.7193728089332581, 0.14230161905288696, 0.7115081548690796, 0.6182971596717834, 0.3091485798358917, 0.022082041949033737, 0.022082041949033737, 0.022082041949033737, 0.7962749004364014, 0.08251553773880005, 0.05363509804010391, 0.057760875672101974, 0.012377330102026463, 0.11808054149150848, 0.7084832787513733, 0.11808054149150848, 0.4934946596622467, 0.0986989364027977, 0.04934946820139885, 0.3947957456111908, 0.04934946820139885, 0.8186597228050232, 0.046902380883693695, 0.07674934715032578, 0.046902380883693695, 0.012791558168828487, 0.4586375653743744, 0.09827947616577148, 0.39311790466308594, 0.03275982663035393, 0.03275982663035393, 0.7650157809257507, 0.07267649471759796, 0.06885141879320145, 0.07650157809257507, 0.01912539452314377, 0.10500206053256989, 0.7350144386291504, 0.10500206053256989, 0.8974392414093018, 0.0332384891808033, 0.0332384891808033, 0.1316109448671341, 0.1316109448671341, 0.6580547094345093, 0.043448109179735184, 0.8689622282981873, 0.043448109179735184, 0.043448109179735184, 0.21191541850566864, 0.07063847035169601, 0.6357462406158447, 0.07063847035169601, 0.9266484379768372, 0.014945942908525467, 0.014945942908525467, 0.0448378287255764, 0.014945942908525467, 0.08756397664546967, 0.08756397664546967, 0.7880758047103882, 0.9577457308769226, 0.01182402204722166, 0.01182402204722166, 0.01182402204722166, 0.01182402204722166, 0.14209339022636414, 0.14209339022636414, 0.14209339022636414, 0.7104669809341431, 0.946721076965332, 0.024274898692965508, 0.024274898692965508, 0.024274898692965508, 0.1557324081659317, 0.1557324081659317, 0.1557324081659317, 0.6229296326637268, 0.15471483767032623, 0.6188593506813049, 0.8007118105888367, 0.03947170823812485, 0.11841512471437454, 0.005638815462589264, 0.033832892775535583, 0.8474758267402649, 0.0065695797093212605, 0.0065695797093212605, 0.13139159977436066, 0.013139159418642521, 0.5658336281776428, 0.04526669159531593, 0.36213353276252747, 0.022633345797657967, 0.12085017561912537, 0.12085017561912537, 0.7251010537147522, 0.9672356843948364, 0.019739503040909767, 0.019739503040909767, 0.019739503040909767, 0.019739503040909767, 0.6548891663551331, 0.03852289170026779, 0.05778433755040169, 0.03852289170026779, 0.21187590062618256, 0.1274345964193344, 0.1274345964193344, 0.6371729969978333, 0.07834142446517944, 0.07834142446517944, 0.7834142446517944, 0.07834142446517944, 0.8705676198005676, 0.06448648869991302, 0.038691893219947815, 0.0064486488699913025, 0.019345946609973907, 0.24968431890010834, 0.062421079725027084, 0.18726323544979095, 0.4369475543498993, 0.062421079725027084, 0.7092581987380981, 0.13824523985385895, 0.0661172941327095, 0.0661172941327095, 0.024042651057243347, 0.12317801266908646, 0.6158900856971741, 0.12317801266908646, 0.7536771893501282, 0.052429717034101486, 0.026214858517050743, 0.09830571711063385, 0.07209086418151855, 0.2830752432346344, 0.0707688108086586, 0.0707688108086586, 0.0707688108086586, 0.5661504864692688, 0.8303042650222778, 0.07220037281513214, 0.040612708777189255, 0.03158766031265259, 0.02256261557340622, 0.8721532225608826, 0.06913409382104874, 0.021272029727697372, 0.02659003622829914, 0.015954021364450455, 0.14233258366584778, 0.7116629481315613, 0.6080338954925537, 0.11631952226161957, 0.042298007756471634, 0.14275577664375305, 0.08459601551294327, 0.828221321105957, 0.06060155853629112, 0.055551428347826004, 0.03030077926814556, 0.025250649079680443, 0.4763079583644867, 0.050137680023908615, 0.32589492201805115, 0.10027536004781723, 0.050137680023908615, 0.6318995952606201, 0.1783587634563446, 0.06624753773212433, 0.05605560913681984, 0.07134350389242172, 0.052717484533786774, 0.052717484533786774, 0.8434797525405884, 0.16072021424770355, 0.16072021424770355, 0.6428808569908142, 0.8489673137664795, 0.028741080313920975, 0.05969301238656044, 0.028741080313920975, 0.033162783831357956, 0.1863207370042801, 0.23290091753005981, 0.04658018425107002, 0.04658018425107002, 0.5123820304870605, 0.16839274764060974, 0.16839274764060974, 0.5051782727241516, 0.4531630873680115, 0.3998498022556305, 0.013328325934708118, 0.03998497873544693, 0.0932982861995697, 0.1312592476606369, 0.1312592476606369, 0.6562962532043457, 0.7738459706306458, 0.03054654970765114, 0.17309711873531342, 0.010182183235883713, 0.020364366471767426, 0.12091010808944702, 0.12091010808944702, 0.12091010808944702, 0.7254606485366821, 0.12916117906570435, 0.6458058953285217, 0.12916117906570435, 0.15728718042373657, 0.7471141219139099, 0.03932179510593414, 0.03932179510593414, 0.1387660652399063, 0.1387660652399063, 0.5550642609596252, 0.1274423897266388, 0.1274423897266388, 0.6372119784355164, 0.6056299209594727, 0.02422519586980343, 0.36337795853614807, 0.02422519586980343, 0.09851357340812683, 0.049256786704063416, 0.7881085872650146, 0.049256786704063416, 0.12701016664505005, 0.12701016664505005, 0.12701016664505005, 0.6350508332252502, 0.7248244881629944, 0.15930208563804626, 0.055755726993083954, 0.02389531210064888, 0.031860414892435074, 0.6553837656974792, 0.179557204246521, 0.0897786021232605, 0.0538671612739563, 0.0179557204246521, 0.14684458076953888, 0.14684458076953888, 0.5873783230781555, 0.9181327223777771, 0.02339191734790802, 0.02339191734790802, 0.005847979336977005, 0.02339191734790802, 0.09485729038715363, 0.09485729038715363, 0.758858323097229, 0.14358866214752197, 0.14358866214752197, 0.5743546485900879, 0.16768845915794373, 0.16768845915794373, 0.5030654072761536, 0.9576152563095093, 0.005503535736352205, 0.02201414294540882, 0.01100707147270441, 0.005503535736352205, 0.8690534830093384, 0.04138350114226341, 0.04456684738397598, 0.02228342369198799, 0.01910007745027542, 0.5395246744155884, 0.0749339833855629, 0.2997359335422516, 0.0599471852183342, 0.0299735926091671, 0.7247226238250732, 0.08526148647069931, 0.14494453370571136, 0.025578446686267853, 0.01705229841172695, 0.4394882023334503, 0.4753647744655609, 0.03587658703327179, 0.017938293516635895, 0.03587658703327179, 0.12696929275989532, 0.12696929275989532, 0.12696929275989532, 0.6348464488983154, 0.33005833625793457, 0.11001944541931152, 0.5500972270965576, 0.8299592137336731, 0.06916327029466629, 0.03025892935693264, 0.04754974693059921, 0.02161352150142193, 0.3904403746128082, 0.03253670036792755, 0.0650734007358551, 0.5205872058868408, 0.03253670036792755, 0.7080739140510559, 0.08850923925638199, 0.09957288950681686, 0.044254619628190994, 0.060850098729133606, 0.612640380859375, 0.10540049523115158, 0.07905036956071854, 0.09881296753883362, 0.10540049523115158, 0.7617112398147583, 0.08401226997375488, 0.00560081796720624, 0.04480654373764992, 0.10081472247838974, 0.1432579904794693, 0.1432579904794693, 0.5730319619178772, 0.1502629518508911, 0.1502629518508911, 0.6010518074035645, 0.8050044178962708, 0.06559295207262039, 0.011925991624593735, 0.029814979061484337, 0.09540793299674988, 0.7344425320625305, 0.19533047080039978, 0.03906609117984772, 0.02343965508043766, 0.015626437962055206, 0.2634502947330475, 0.19758771359920502, 0.4610379934310913, 0.8795733451843262, 0.06765948981046677, 0.011276581324636936, 0.01691487245261669, 0.01691487245261669, 0.8019278049468994, 0.010985312052071095, 0.03295593708753586, 0.14280906319618225, 0.010985312052071095, 0.15588824450969696, 0.15588824450969696, 0.6235529780387878, 0.45454445481300354, 0.05050494149327278, 0.05050494149327278, 0.40403953194618225, 0.07089091837406158, 0.07089091837406158, 0.07089091837406158, 0.4962364137172699, 0.35445457696914673, 0.12365157902240753, 0.12365157902240753, 0.7419094443321228, 0.9128500819206238, 0.03968913480639458, 0.03968913480639458, 0.03968913480639458, 0.9385541677474976, 0.030941346660256386, 0.010313781909644604, 0.010313781909644604, 0.010313781909644604, 0.3456002473831177, 0.5026912689208984, 0.1256728172302246, 0.03141820430755615, 0.11866211146116257, 0.11866211146116257, 0.11866211146116257, 0.7119726538658142, 0.5026600360870361, 0.12133173644542694, 0.25999659299850464, 0.08666552603244781, 0.034666210412979126, 0.10803615301847458, 0.10803615301847458, 0.7562530636787415, 0.16130296885967255, 0.16130296885967255, 0.16130296885967255, 0.6452118754386902, 0.9587860107421875, 0.0135040283203125, 0.0135040283203125, 0.0135040283203125, 0.027008056640625, 0.3745422661304474, 0.1070120707154274, 0.0802590548992157, 0.02675301767885685, 0.4012952744960785, 0.5098228454589844, 0.12138639390468597, 0.024277279153466225, 0.2913273572921753, 0.024277279153466225, 0.11371159553527832, 0.11371159553527832, 0.6822695732116699, 0.11371159553527832, 0.1251002997159958, 0.1251002997159958, 0.7506018280982971, 0.43037307262420654, 0.21518653631210327, 0.05164476856589317, 0.2065790742635727, 0.10328953713178635, 0.1295519769191742, 0.6477599143981934, 0.1295519769191742, 0.838308572769165, 0.07705900818109512, 0.042032185941934586, 0.023351214826107025, 0.021016092970967293, 0.9083124399185181, 0.046659886837005615, 0.01244263630360365, 0.0248852726072073, 0.009331976994872093, 0.9043195843696594, 0.015327449887990952, 0.015327449887990952, 0.061309799551963806, 0.015327449887990952, 0.7916167378425598, 0.08756822347640991, 0.035027287900447845, 0.03853001818060875, 0.04553547501564026, 0.3012355864048004, 0.587023138999939, 0.030895955860614777, 0.03861994668841362, 0.03861994668841362, 0.24421347677707672, 0.12210673838853836, 0.48842695355415344, 0.8255984783172607, 0.020469384267926216, 0.03752720355987549, 0.07505440711975098, 0.04435032978653908, 0.14834097027778625, 0.14834097027778625, 0.593363881111145, 0.39690500497817993, 0.015876200050115585, 0.06350480020046234, 0.49216219782829285, 0.047628600150346756, 0.12747982144355774, 0.1912197321653366, 0.6373991370201111, 0.4934120774269104, 0.11609696596860886, 0.10642221570014954, 0.06772322952747345, 0.2225191742181778, 0.7092674970626831, 0.01899823732674122, 0.03166372701525688, 0.10765667259693146, 0.13298764824867249, 0.389422744512558, 0.389422744512558, 0.10817298293113708, 0.10817298293113708, 0.09474404901266098, 0.09474404901266098, 0.09474404901266098, 0.7579523921012878, 0.9091027975082397, 0.007770109456032515, 0.007770109456032515, 0.007770109456032515, 0.07770109176635742, 0.5694603323936462, 0.16016072034835815, 0.11567162722349167, 0.017795635387301445, 0.12456944584846497, 0.14907968044281006, 0.14907968044281006, 0.5963187217712402, 0.6946696639060974, 0.13312485814094543, 0.04840903729200363, 0.05567039176821709, 0.06777264922857285, 0.6702442169189453, 0.11746547371149063, 0.05527787283062935, 0.11746547371149063, 0.04145840182900429, 0.9266305565834045, 0.04633152857422829, 0.023165764287114143, 0.023165764287114143, 0.8205699920654297, 0.021406173706054688, 0.03567695617675781, 0.021406173706054688, 0.09989547729492188, 0.14222195744514465, 0.7111097574234009, 0.08956266194581985, 0.08956266194581985, 0.8060639500617981, 0.8142123818397522, 0.06959079951047897, 0.06263171881437302, 0.02783632092177868, 0.023196933791041374, 0.13357339799404144, 0.6678670048713684, 0.13357339799404144, 0.9201028943061829, 0.02300257235765457, 0.011501286178827286, 0.02300257235765457, 0.02300257235765457, 0.7607242465019226, 0.11453600972890854, 0.068379707634449, 0.03589934483170509, 0.02051391266286373, 0.18181553483009338, 0.18181553483009338, 0.18181553483009338, 0.5454465746879578, 0.1419474482536316, 0.7097373008728027, 0.8463063836097717, 0.04949159920215607, 0.02969495952129364, 0.04949159920215607, 0.024745799601078033, 0.3849400579929352, 0.42771115899086, 0.042771115899086, 0.128313347697258, 0.042771115899086, 0.7437905669212341, 0.24501337110996246, 0.008750476874411106, 0.17708492279052734, 0.17708492279052734, 0.531254768371582, 0.12164375931024551, 0.12164375931024551, 0.7298625707626343, 0.5721724033355713, 0.15007801353931427, 0.13131825625896454, 0.02813962660729885, 0.12193838506937027, 0.6003304123878479, 0.2633028030395508, 0.031596336513757706, 0.07372478395700455, 0.02106422372162342, 0.870521068572998, 0.028541674837470055, 0.04566667973995209, 0.025687506422400475, 0.028541674837470055, 0.11235587298870087, 0.6741352081298828, 0.11235587298870087, 0.8718419075012207, 0.0373646542429924, 0.0373646542429924, 0.024909768253564835, 0.031137211248278618, 0.6707777976989746, 0.12690390646457672, 0.036258257925510406, 0.027193693444132805, 0.13596847653388977, 0.08076508343219757, 0.08076508343219757, 0.08076508343219757, 0.8076508641242981, 0.456718385219574, 0.05708979815244675, 0.05708979815244675, 0.456718385219574, 0.908206582069397, 0.02522796019911766, 0.020182369276881218, 0.010091184638440609, 0.040364738553762436, 0.1615423560142517, 0.1615423560142517, 0.6461694240570068, 0.6080619692802429, 0.07600774616003036, 0.24702516198158264, 0.01900193654000759, 0.057005807757377625, 0.16833773255348206, 0.16833773255348206, 0.5050132274627686, 0.12956179678440094, 0.6478089690208435, 0.12956179678440094, 0.035603977739810944, 0.035603977739810944, 0.035603977739810944, 0.8900994658470154, 0.09431136399507523, 0.09431136399507523, 0.7544909119606018, 0.4404659569263458, 0.3255617916584015, 0.15320554375648499, 0.038301385939121246, 0.05745207890868187, 0.7549541592597961, 0.1188904196023941, 0.029722604900598526, 0.07727877050638199, 0.017833562567830086, 0.29675331711769104, 0.04945888742804527, 0.04945888742804527, 0.04945888742804527, 0.5935066342353821, 0.920603334903717, 0.01219342090189457, 0.006096710450947285, 0.02438684180378914, 0.030483553186058998, 0.6810622215270996, 0.10156191140413284, 0.09558767825365067, 0.06571652740240097, 0.04779383912682533, 0.14927636086940765, 0.14927636086940765, 0.14927636086940765, 0.5971054434776306, 0.7922295928001404, 0.12436161935329437, 0.032241903245449066, 0.04605986177921295, 0.00921197235584259, 0.511764407157898, 0.3684704005718231, 0.020470576360821724, 0.04094115272164345, 0.04094115272164345, 0.13568846881389618, 0.13568846881389618, 0.6784423589706421, 0.9385860562324524, 0.024699633941054344, 0.024699633941054344, 0.024699633941054344, 0.1679721176624298, 0.1679721176624298, 0.6718884706497192], \"Term\": [\"'abe',\", \"'abe',\", \"'abe',\", \"'abe',\", \"'abe',\", \"'action',\", \"'action',\", \"'action',\", \"'action',\", \"'action',\", \"'actual',\", \"'actual',\", \"'actual',\", \"'actual',\", \"'actual',\", \"'albert',\", \"'albert',\", \"'albert',\", \"'alberto',\", \"'alberto',\", \"'album',\", \"'album',\", \"'alcatraaz',\", \"'alcatraaz',\", \"'alcatraaz',\", \"'allison',\", \"'allison',\", \"'allison',\", \"'american',\", \"'american',\", \"'american',\", \"'american',\", \"'american',\", \"'annika',\", \"'annika',\", \"'annika',\", \"'apu',\", \"'apu',\", \"'apu',\", \"'apu',\", \"'apu',\", \"'armin',\", \"'armin',\", \"'armin',\", \"'arnold',\", \"'arnold',\", \"'arnold',\", \"'arti',\", \"'arti',\", \"'arti',\", \"'arti',\", \"'ask',\", \"'ask',\", \"'ask',\", \"'ask',\", \"'ask',\", \"'back',\", \"'back',\", \"'back',\", \"'back',\", \"'back',\", \"'bar',\", \"'bar',\", \"'bar',\", \"'bar',\", \"'bar',\", \"'bashir',\", \"'bashir',\", \"'bashir',\", \"'bea',\", \"'bea',\", \"'bea',\", \"'bear',\", \"'bear',\", \"'bear',\", \"'bear',\", \"'bear',\", \"'becki',\", \"'becki',\", \"'becki',\", \"'bender',\", \"'bender',\", \"'bender',\", \"'bender',\", \"'bob',\", \"'bob',\", \"'bob',\", \"'bob',\", \"'bob',\", \"'bongo',\", \"'bongo',\", \"'bongo',\", \"'bongo',\", \"'bonni',\", \"'bonni',\", \"'bonni',\", \"'book',\", \"'book',\", \"'book',\", \"'book',\", \"'book',\", \"'boston',\", \"'boston',\", \"'boston',\", \"'botz',\", \"'botz',\", \"'botz',\", \"'brandin',\", \"'brandin',\", \"'brandin',\", \"'brandin',\", \"'brosnan',\", \"'brosnan',\", \"'brosnan',\", \"'brosnan',\", \"'brother',\", \"'brother',\", \"'brother',\", \"'brother',\", \"'brother',\", \"'buck',\", \"'buck',\", \"'buck',\", \"'bulli',\", \"'bulli',\", \"'bulli',\", \"'bulli',\", \"'bulli',\", \"'calabres',\", \"'calabres',\", \"'camp',\", \"'camp',\", \"'camp',\", \"'camp',\", \"'camp',\", \"'campaign',\", \"'campaign',\", \"'campaign',\", \"'campaign',\", \"'campaign',\", \"'candac',\", \"'candac',\", \"'car',\", \"'car',\", \"'car',\", \"'car',\", \"'car',\", \"'carl',\", \"'carl',\", \"'carl',\", \"'carl',\", \"'carl',\", \"'cartoon',\", \"'cartoon',\", \"'cartoon',\", \"'cartoon',\", \"'cartoon',\", \"'case',\", \"'case',\", \"'case',\", \"'case',\", \"'case',\", \"'cecil',\", \"'cecil',\", \"'cecil',\", \"'cecil',\", \"'cecil',\", \"'charli',\", \"'charli',\", \"'charli',\", \"'charli',\", \"'cheech',\", \"'cheech',\", \"'cheech',\", \"'chief',\", \"'chief',\", \"'chief',\", \"'chief',\", \"'chief',\", \"'chloe',\", \"'chloe',\", \"'chloe',\", \"'chong',\", \"'chong',\", \"'chong',\", \"'choos',\", \"'choos',\", \"'choos',\", \"'choos',\", \"'choos',\", \"'christma',\", \"'christma',\", \"'christma',\", \"'christma',\", \"'christma',\", \"'class',\", \"'class',\", \"'class',\", \"'class',\", \"'class',\", \"'classroom',\", \"'classroom',\", \"'classroom',\", \"'classroom',\", \"'classroom',\", \"'clone',\", \"'clone',\", \"'clone',\", \"'clyde',\", \"'clyde',\", \"'clyde',\", \"'cobb',\", \"'cobb',\", \"'cobb',\", \"'colonel',\", \"'colonel',\", \"'colonel',\", \"'colonel',\", \"'colt',\", \"'colt',\", \"'colt',\", \"'comet',\", \"'comet',\", \"'comic',\", \"'comic',\", \"'comic',\", \"'comic',\", \"'comic',\", \"'convinc',\", \"'convinc',\", \"'convinc',\", \"'convinc',\", \"'convinc',\", \"'cooder',\", \"'cooder',\", \"'cooder',\", \"'crawford',\", \"'crawford',\", \"'crawford',\", \"'dan',\", \"'dan',\", \"'darci',\", \"'darci',\", \"'darci',\", \"'date',\", \"'date',\", \"'date',\", \"'date',\", \"'date',\", \"'day',\", \"'day',\", \"'day',\", \"'day',\", \"'day',\", \"'decid',\", \"'decid',\", \"'decid',\", \"'decid',\", \"'decid',\", \"'dental',\", \"'dental',\", \"'dental',\", \"'dental',\", \"'dog',\", \"'dog',\", \"'dog',\", \"'dog',\", \"'dog',\", \"'donni',\", \"'donni',\", \"'donni',\", \"'doorbel',\", \"'doorbel',\", \"'doorbel',\", \"'drive',\", \"'drive',\", \"'drive',\", \"'drive',\", \"'drive',\", \"'duncan',\", \"'duncan',\", \"'dwight',\", \"'dwight',\", \"'dwight',\", \"'edison',\", \"'edison',\", \"'edna',\", \"'edna',\", \"'edna',\", \"'edna',\", \"'edna',\", \"'egg',\", \"'egg',\", \"'egg',\", \"'egg',\", \"'egg',\", \"'eliza',\", \"'eliza',\", \"'eliza',\", \"'elon',\", \"'elon',\", \"'elon',\", \"'essay',\", \"'essay',\", \"'essay',\", \"'explain',\", \"'explain',\", \"'explain',\", \"'explain',\", \"'explain',\", \"'face',\", \"'face',\", \"'face',\", \"'face',\", \"'face',\", \"'famili',\", \"'famili',\", \"'famili',\", \"'famili',\", \"'famili',\", \"'fat',\", \"'fat',\", \"'fat',\", \"'fat',\", \"'film',\", \"'film',\", \"'film',\", \"'film',\", \"'film',\", \"'find',\", \"'find',\", \"'find',\", \"'find',\", \"'find',\", \"'fire',\", \"'fire',\", \"'fire',\", \"'fire',\", \"'fire',\", \"'forc',\", \"'forc',\", \"'forc',\", \"'forc',\", \"'forc',\", \"'frack',\", \"'frack',\", \"'friend',\", \"'friend',\", \"'friend',\", \"'friend',\", \"'friend',\", \"'frink',\", \"'frink',\", \"'frink',\", \"'frink',\", \"'frink',\", \"'gabriel',\", \"'gabriel',\", \"'gabriel',\", \"'gaga',\", \"'gaga',\", \"'gaga',\", \"'georg',\", \"'georg',\", \"'georg',\", \"'georg',\", \"'georg',\", \"'get',\", \"'get',\", \"'get',\", \"'get',\", \"'get',\", \"'gil',\", \"'gil',\", \"'gil',\", \"'gil',\", \"'give',\", \"'give',\", \"'give',\", \"'give',\", \"'give',\", \"'god',\", \"'god',\", \"'god',\", \"'god',\", \"'god',\", \"'goggl',\", \"'goggl',\", \"'goggl',\", \"'golem',\", \"'golem',\", \"'golem',\", \"'good',\", \"'good',\", \"'good',\", \"'good',\", \"'good',\", \"'grampa',\", \"'grampa',\", \"'grampa',\", \"'grampa',\", \"'grampa',\", \"'grandpa',\", \"'grandpa',\", \"'grandpa',\", \"'grandpa',\", \"'grandpa',\", \"'greas',\", \"'greas',\", \"'greas',\", \"'greas',\", \"'greta',\", \"'greta',\", \"'greta',\", \"'grime',\", \"'grime',\", \"'grime',\", \"'group',\", \"'group',\", \"'group',\", \"'group',\", \"'group',\", \"'guy',\", \"'guy',\", \"'guy',\", \"'guy',\", \"'guy',\", \"'gypsi',\", \"'gypsi',\", \"'gypsi',\", \"'gypsi',\", \"'hair',\", \"'hair',\", \"'hair',\", \"'hair',\", \"'hair',\", \"'halloween',\", \"'halloween',\", \"'halloween',\", \"'halloween',\", \"'halloween',\", \"'harper',\", \"'harper',\", \"'harper',\", \"'helper',\", \"'helper',\", \"'helper',\", \"'helper',\", \"'helper',\", \"'henri',\", \"'henri',\", \"'henri',\", \"'herb',\", \"'herb',\", \"'herb',\", \"'hiram',\", \"'hiram',\", \"'hole',\", \"'hole',\", \"'hole',\", \"'hole',\", \"'hole',\", \"'home',\", \"'home',\", \"'home',\", \"'home',\", \"'home',\", \"'homer',\", \"'homer',\", \"'homer',\", \"'hound',\", \"'hound',\", \"'hound',\", \"'hound',\", \"'hound',\", \"'hous',\", \"'hous',\", \"'hous',\", \"'hous',\", \"'hous',\", \"'houten',\", \"'houten',\", \"'houten',\", \"'houten',\", \"'houten',\", \"'howev',\", \"'howev',\", \"'howev',\", \"'howev',\", \"'howev',\", \"'hugh',\", \"'hugh',\", \"'hugh',\", \"'hutz',\", \"'hutz',\", \"'hutz',\", \"'iceland',\", \"'iceland',\", \"'iceland',\", \"'isabel',\", \"'isabel',\", \"'isabel',\", \"'isabel',\", \"'isotop',\", \"'isotop',\", \"'isotop',\", \"'isotop',\", \"'itchi',\", \"'itchi',\", \"'itchi',\", \"'itchi',\", \"'itchi',\", \"'jessica',\", \"'jessica',\", \"'jessica',\", \"'jimbo',\", \"'jimbo',\", \"'jimbo',\", \"'jimbo',\", \"'jimbo',\", \"'julia',\", \"'julia',\", \"'julia',\", \"'julia',\", \"'kang',\", \"'kang',\", \"'kang',\", \"'kang',\", \"'karl',\", \"'karl',\", \"'karl',\", \"'karl',\", \"'kashmir',\", \"'kashmir',\", \"'kid',\", \"'kid',\", \"'kid',\", \"'kid',\", \"'kid',\", \"'kill',\", \"'kill',\", \"'kill',\", \"'kill',\", \"'kill',\", \"'kirk',\", \"'kirk',\", \"'kirk',\", \"'kirk',\", \"'knight',\", \"'knight',\", \"'knight',\", \"'kodo',\", \"'kodo',\", \"'kodo',\", \"'kodo',\", \"'kodo',\", \"'kwik',\", \"'kwik',\", \"'kwik',\", \"'kwik',\", \"'kwik',\", \"'lab',\", \"'lab',\", \"'lab',\", \"'lanley',\", \"'lanley',\", \"'lanley',\", \"'lanley',\", \"'later',\", \"'later',\", \"'later',\", \"'later',\", \"'later',\", \"'leader',\", \"'leader',\", \"'leader',\", \"'leader',\", \"'leader',\", \"'learn',\", \"'learn',\", \"'learn',\", \"'learn',\", \"'learn',\", \"'lemon',\", \"'lemon',\", \"'lemon',\", \"'lenni',\", \"'lenni',\", \"'lenni',\", \"'lenni',\", \"'lenni',\", \"'leprechaun',\", \"'leprechaun',\", \"'leprechaun',\", \"'leprechaun',\", \"'leprechaun',\", \"'life',\", \"'life',\", \"'life',\", \"'life',\", \"'life',\", \"'like',\", \"'like',\", \"'like',\", \"'like',\", \"'like',\", \"'ling',\", \"'ling',\", \"'littl',\", \"'littl',\", \"'littl',\", \"'littl',\", \"'littl',\", \"'live',\", \"'live',\", \"'live',\", \"'live',\", \"'live',\", \"'lou',\", \"'lou',\", \"'lou',\", \"'lou',\", \"'lou',\", \"'love',\", \"'love',\", \"'love',\", \"'love',\", \"'love',\", \"'lurleen',\", \"'lurleen',\", \"'lurleen',\", \"'magician',\", \"'magician',\", \"'magician',\", \"'make',\", \"'make',\", \"'make',\", \"'make',\", \"'make',\", \"'manjula',\", \"'manjula',\", \"'manjula',\", \"'manjula',\", \"'manjula',\", \"'mappl',\", \"'mappl',\", \"'mappl',\", \"'marri',\", \"'marri',\", \"'marri',\", \"'marri',\", \"'marri',\", \"'marshal',\", \"'marshal',\", \"'marshal',\", \"'martin',\", \"'martin',\", \"'martin',\", \"'martin',\", \"'martin',\", \"'mason',\", \"'mason',\", \"'mason',\", \"'mason',\", \"'maya',\", \"'maya',\", \"'maya',\", \"'michael',\", \"'michael',\", \"'michael',\", \"'michael',\", \"'mindi',\", \"'mindi',\", \"'mindi',\", \"'mitzvah',\", \"'mitzvah',\", \"'mitzvah',\", \"'mona',\", \"'mona',\", \"'mona',\", \"'mona',\", \"'monorail',\", \"'monorail',\", \"'monorail',\", \"'monorail',\", \"'montymort',\", \"'montymort',\", \"'montymort',\", \"'montymort',\", \"'mother',\", \"'mother',\", \"'mother',\", \"'mother',\", \"'mother',\", \"'move',\", \"'move',\", \"'move',\", \"'move',\", \"'move',\", \"'movementarian',\", \"'movementarian',\", \"'movementarian',\", \"'movi',\", \"'movi',\", \"'movi',\", \"'movi',\", \"'movi',\", \"'mozart',\", \"'mozart',\", \"'mozart',\", \"'munchi',\", \"'munchi',\", \"'munchi',\", \"'myrna',\", \"'myrna',\", \"'myrna',\", \"'nelson',\", \"'nelson',\", \"'nelson',\", \"'nelson',\", \"'nelson',\", \"'one',\", \"'one',\", \"'one',\", \"'one',\", \"'one',\", \"'paint',\", \"'paint',\", \"'paint',\", \"'paint',\", \"'paint',\", \"'parent',\", \"'parent',\", \"'parent',\", \"'parent',\", \"'parent',\", \"'patti',\", \"'patti',\", \"'patti',\", \"'patti',\", \"'patti',\", \"'peach',\", \"'peach',\", \"'peach',\", \"'peach',\", \"'penelop',\", \"'penelop',\", \"'penelop',\", \"'peopl',\", \"'peopl',\", \"'peopl',\", \"'peopl',\", \"'peopl',\", \"'pie',\", \"'pie',\", \"'pie',\", \"'pie',\", \"'pie',\", \"'place',\", \"'place',\", \"'place',\", \"'place',\", \"'place',\", \"'plan',\", \"'plan',\", \"'plan',\", \"'plan',\", \"'plan',\", \"'plant',\", \"'plant',\", \"'plant',\", \"'plant',\", \"'plant',\", \"'plow',\", \"'plow',\", \"'plow',\", \"'poss',\", \"'poss',\", \"'poss',\", \"'power',\", \"'power',\", \"'power',\", \"'power',\", \"'power',\", \"'present',\", \"'present',\", \"'present',\", \"'present',\", \"'present',\", \"'princess',\", \"'princess',\", \"'princess',\", \"'princip',\", \"'princip',\", \"'princip',\", \"'princip',\", \"'princip',\", \"'prison',\", \"'prison',\", \"'prison',\", \"'prison',\", \"'prison',\", \"'pub',\", \"'pub',\", \"'pub',\", \"'pumpkin',\", \"'pumpkin',\", \"'pumpkin',\", \"'pumpkin',\", \"'puppi',\", \"'puppi',\", \"'puppi',\", \"'puppi',\", \"'puppi',\", \"'racer',\", \"'racer',\", \"'racer',\", \"'rachel',\", \"'rachel',\", \"'rachel',\", \"'rachel',\", \"'ralph',\", \"'ralph',\", \"'ralph',\", \"'ralph',\", \"'ralph',\", \"'ray',\", \"'ray',\", \"'ray',\", \"'ray',\", \"'raymondo',\", \"'raymondo',\", \"'raymondo',\", \"'raymondo',\", \"'rememb',\", \"'rememb',\", \"'rememb',\", \"'rememb',\", \"'rememb',\", \"'ribwich',\", \"'ribwich',\", \"'ribwich',\", \"'rita',\", \"'rita',\", \"'rita',\", \"'rita',\", \"'robot',\", \"'robot',\", \"'robot',\", \"'robot',\", \"'robot',\", \"'rod',\", \"'rod',\", \"'rod',\", \"'rod',\", \"'rod',\", \"'role',\", \"'role',\", \"'role',\", \"'role',\", \"'role',\", \"'ronaldo',\", \"'ronaldo',\", \"'ronaldo',\", \"'ronaldo',\", \"'salieri',\", \"'salieri',\", \"'salieri',\", \"'santa',\", \"'santa',\", \"'santa',\", \"'santa',\", \"'santa',\", \"'sara',\", \"'sara',\", \"'sara',\", \"'say',\", \"'say',\", \"'say',\", \"'say',\", \"'say',\", \"'school',\", \"'school',\", \"'school',\", \"'school',\", \"'school',\", \"'scratchi',\", \"'scratchi',\", \"'scratchi',\", \"'scratchi',\", \"'scratchi',\", \"'see',\", \"'see',\", \"'see',\", \"'see',\", \"'see',\", \"'selma',\", \"'selma',\", \"'selma',\", \"'selma',\", \"'selma',\", \"'seth',\", \"'seth',\", \"'seth',\", \"'show',\", \"'show',\", \"'show',\", \"'show',\", \"'show',\", \"'sid',\", \"'sid',\", \"'sid',\", \"'sideshow',\", \"'sideshow',\", \"'sideshow',\", \"'sideshow',\", \"'sideshow',\", \"'simon',\", \"'simon',\", \"'simon',\", \"'sing',\", \"'sing',\", \"'sing',\", \"'sing',\", \"'sing',\", \"'smither',\", \"'smither',\", \"'smither',\", \"'smither',\", \"'smither',\", \"'smoke',\", \"'smoke',\", \"'smoke',\", \"'smoke',\", \"'smoker',\", \"'smoker',\", \"'smoker',\", \"'smoker',\", \"'snake',\", \"'snake',\", \"'snake',\", \"'snake',\", \"'snake',\", \"'song',\", \"'song',\", \"'song',\", \"'song',\", \"'song',\", \"'spellymp',\", \"'spellymp',\", \"'spellymp',\", \"'springfield',\", \"'springfield',\", \"'springfield',\", \"'springfield',\", \"'springfield',\", \"'state',\", \"'state',\", \"'state',\", \"'state',\", \"'state',\", \"'statu',\", \"'statu',\", \"'statu',\", \"'statu',\", \"'store',\", \"'store',\", \"'store',\", \"'store',\", \"'store',\", \"'sylvia',\", \"'sylvia',\", \"'tabitha',\", \"'tabitha',\", \"'tabitha',\", \"'take',\", \"'take',\", \"'take',\", \"'take',\", \"'take',\", \"'tattoo',\", \"'tattoo',\", \"'tattoo',\", \"'teacher',\", \"'teacher',\", \"'teacher',\", \"'teacher',\", \"'teacher',\", \"'tell',\", \"'tell',\", \"'tell',\", \"'tell',\", \"'tell',\", \"'tenni',\", \"'tenni',\", \"'tenni',\", \"'tenni',\", \"'terranc',\", \"'terranc',\", \"'time',\", \"'time',\", \"'time',\", \"'time',\", \"'time',\", \"'tom',\", \"'tom',\", \"'tom',\", \"'tom',\", \"'tom',\", \"'toni',\", \"'toni',\", \"'toni',\", \"'toot',\", \"'toot',\", \"'toot',\", \"'tow',\", \"'tow',\", \"'tow',\", \"'town',\", \"'town',\", \"'town',\", \"'town',\", \"'town',\", \"'tree',\", \"'tree',\", \"'tree',\", \"'tree',\", \"'tree',\", \"'tri',\", \"'tri',\", \"'tri',\", \"'tri',\", \"'tri',\", \"'truffl',\", \"'truffl',\", \"'truffl',\", \"'turn',\", \"'turn',\", \"'turn',\", \"'turn',\", \"'turn',\", \"'two',\", \"'two',\", \"'two',\", \"'two',\", \"'two',\", \"'ultrahous',\", \"'ultrahous',\", \"'ultrahous',\", \"'ultrahous',\", \"'union',\", \"'union',\", \"'union',\", \"'union',\", \"'use',\", \"'use',\", \"'use',\", \"'use',\", \"'use',\", \"'vamp',\", \"'vamp',\", \"'vamp',\", \"'van',\", \"'van',\", \"'van',\", \"'van',\", \"'van',\", \"'venus',\", \"'venus',\", \"'venus',\", \"'virgil',\", \"'virgil',\", \"'virgil',\", \"'walt',\", \"'walt',\", \"'walt',\", \"'walt',\", \"'wayn',\", \"'wayn',\", \"'wayn',\", \"'wed',\", \"'wed',\", \"'wed',\", \"'wed',\", \"'wed',\", \"'well',\", \"'well',\", \"'well',\", \"'well',\", \"'well',\", \"'whale',\", \"'whale',\", \"'whale',\", \"'whale',\", \"'whale',\", \"'willi',\", \"'willi',\", \"'willi',\", \"'willi',\", \"'willi',\", \"'win',\", \"'win',\", \"'win',\", \"'win',\", \"'win',\", \"'woodrow',\", \"'woodrow',\", \"'woodrow',\", \"'woodrow',\", \"'year',\", \"'year',\", \"'year',\", \"'year',\", \"'year',\", \"'young',\", \"'young',\", \"'young',\", \"'young',\", \"'young',\", \"'zander',\", \"'zander',\", \"'zander',\", \"'zombi',\", \"'zombi',\", \"'zombi',\", \"'zombi',\", \"[]\", \"[]\", \"[]\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 1, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el174848489109282368255138\", ldavis_el174848489109282368255138_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el174848489109282368255138\", ldavis_el174848489109282368255138_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el174848489109282368255138\", ldavis_el174848489109282368255138_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.069756 -0.017014       1        1  70.138847\n",
       "4     -0.012543  0.019920       2        1   9.616715\n",
       "0      0.010828  0.041450       3        1   7.693678\n",
       "3      0.031820 -0.047627       4        1   6.759006\n",
       "2      0.039651  0.003271       5        1   5.791752, topic_info=               Term        Freq       Total Category  logprob  loglift\n",
       "849          'bob',  132.000000  132.000000  Default  30.0000  30.0000\n",
       "127       'famili',  551.000000  551.000000  Default  29.0000  29.0000\n",
       "142          'get',  820.000000  820.000000  Default  28.0000  28.0000\n",
       "349         'tell',  584.000000  584.000000  Default  27.0000  27.0000\n",
       "328  'springfield',  413.000000  413.000000  Default  26.0000  26.0000\n",
       "..              ...         ...         ...      ...      ...      ...\n",
       "477         'make',   14.619174  452.314240   Topic5  -6.0660  -0.5833\n",
       "307          'see',   13.355263  285.491699   Topic5  -6.1564  -0.2136\n",
       "776         'show',   12.502476  293.120697   Topic5  -6.2224  -0.3059\n",
       "127       'famili',   12.933629  551.723999   Topic5  -6.1885  -0.9045\n",
       "349         'tell',   11.802682  584.968872   Topic5  -6.2800  -1.0545\n",
       "\n",
       "[356 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "0         1  0.338349    'abe',\n",
       "0         2  0.028196    'abe',\n",
       "0         3  0.028196    'abe',\n",
       "0         4  0.380643    'abe',\n",
       "0         5  0.211468    'abe',\n",
       "...     ...       ...       ...\n",
       "1791      3  0.024700  'zombi',\n",
       "1791      5  0.024700  'zombi',\n",
       "1411      1  0.167972        []\n",
       "1411      2  0.167972        []\n",
       "1411      4  0.671888        []\n",
       "\n",
       "[1129 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 1, 4, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one looks pretty decent, the bubbles are fairly big, non overlapping scattered throughout the chart. a bit clustered in the top right though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The same as we did here above, but now with the longer version of the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = df.desc\n",
    "\n",
    "data_lemmatized.dropna(inplace = True)\n",
    "\n",
    "data_lemmatized = [d.split() for d in data_lemmatized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation: Corpus and Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(5302 unique tokens: [\"'abe',\", \"'accident',\", \"'across',\", \"'act',\", \"'action',\"]...) from 600 documents (total 108774 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(41, 1), (62, 4), (116, 1), (142, 1), (185, 1), (197, 1), (202, 1), (214, 1), (263, 1), (300, 1), (305, 1), (313, 1), (562, 1), (685, 1), (826, 1), (1005, 1), (2633, 1)], [(59, 1), (143, 1), (197, 1), (241, 1), (301, 2), (340, 1), (421, 1), (428, 1), (466, 1), (478, 1), (509, 1), (524, 2), (967, 1), (1041, 1), (1220, 1), (2212, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = dataset\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.03333333333333333\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.03333333333333333\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamulticore:running online LDA training, 30 topics, 10 passes over the supplied corpus of 600 documents, updating every 300 documents, evaluating every ~600 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamulticore:training LDA model using 3 processes\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.033): 0.015*\"'public',\" + 0.010*\"'woman',\" + 0.010*\"'save',\" + 0.010*\"'face',\" + 0.010*\"'nuclear',\" + 0.010*\"'helper',\" + 0.010*\"'design',\" + 0.010*\"'father',\" + 0.010*\"'part',\" + 0.010*\"'car',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.016*\"'bulli',\" + 0.016*\"'beat',\" + 0.011*\"'win',\" + 0.011*\"'gang',\" + 0.011*\"'contest',\" + 0.011*\"'trip',\" + 0.011*\"'elementari',\" + 0.011*\"'test',\" + 0.011*\"'father',\" + 0.011*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.033): 0.017*\"'race',\" + 0.017*\"'local',\" + 0.016*\"'stori',\" + 0.011*\"'employe',\" + 0.011*\"'father',\" + 0.011*\"'plant',\" + 0.009*\"'choos',\" + 0.009*\"'tell',\" + 0.006*\"'thought',\" + 0.006*\"'nation',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.033): 0.012*\"'stampi',\" + 0.012*\"'eleph',\" + 0.012*\"'choos',\" + 0.012*\"'bear',\" + 0.008*\"'win',\" + 0.008*\"'nelson',\" + 0.007*\"'prize',\" + 0.007*\"'bulli',\" + 0.006*\"'privat',\" + 0.006*\"'dollar',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.033): 0.020*\"'christma',\" + 0.012*\"'mayor',\" + 0.012*\"'prove',\" + 0.012*\"'set',\" + 0.012*\"'keep',\" + 0.010*\"'dream',\" + 0.008*\"'job',\" + 0.008*\"'scratchi',\" + 0.008*\"'good',\" + 0.008*\"'plant',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=26.851440, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:-14.897 per-word bound, 30508.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.033): 0.013*\"'bear',\" + 0.010*\"'team',\" + 0.007*\"'bulli',\" + 0.007*\"'flame',\" + 0.007*\"'jebediah',\" + 0.007*\"'nelson',\" + 0.007*\"'group',\" + 0.006*\"'citi',\" + 0.005*\"'thing',\" + 0.005*\"'secret',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.033): 0.009*\"'boy',\" + 0.008*\"'bear',\" + 0.007*\"'bar',\" + 0.006*\"'math',\" + 0.006*\"'littl',\" + 0.006*\"'stori',\" + 0.006*\"'mitzvah',\" + 0.005*\"'helper',\" + 0.005*\"'elementari',\" + 0.005*\"'show',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.033): 0.008*\"'quick',\" + 0.006*\"'offer',\" + 0.006*\"'second',\" + 0.006*\"'choos',\" + 0.006*\"'camera',\" + 0.006*\"'new',\" + 0.006*\"'toni',\" + 0.006*\"'someth',\" + 0.006*\"'lose',\" + 0.006*\"'comic',\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.033): 0.014*\"'love',\" + 0.012*\"'grampa',\" + 0.010*\"'life',\" + 0.010*\"'movi',\" + 0.010*\"'stori',\" + 0.008*\"'parti',\" + 0.006*\"'flashback',\" + 0.006*\"'seri',\" + 0.006*\"'compani',\" + 0.006*\"'guy',\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.033): 0.009*\"'busi',\" + 0.008*\"'drive',\" + 0.007*\"'decid',\" + 0.007*\"'women',\" + 0.006*\"'bar',\" + 0.006*\"'hair',\" + 0.006*\"'charg',\" + 0.006*\"'men',\" + 0.006*\"'tavern',\" + 0.006*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=1.561351, rho=0.500000\n",
      "INFO:gensim.models.ldamodel:-9.158 per-word bound, 571.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.033): 0.009*\"'bear',\" + 0.008*\"'win',\" + 0.008*\"'choos',\" + 0.007*\"'stampi',\" + 0.007*\"'eleph',\" + 0.007*\"'form',\" + 0.006*\"'nelson',\" + 0.006*\"'actual',\" + 0.005*\"'teacher',\" + 0.005*\"'grow',\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.033): 0.015*\"'team',\" + 0.010*\"'flame',\" + 0.010*\"'jebediah',\" + 0.009*\"'bulli',\" + 0.009*\"'bear',\" + 0.008*\"'nelson',\" + 0.007*\"'follow',\" + 0.007*\"'day',\" + 0.007*\"'steal',\" + 0.006*\"'citi',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.012*\"'bulli',\" + 0.010*\"'beat',\" + 0.009*\"'win',\" + 0.008*\"'elementari',\" + 0.007*\"'gang',\" + 0.007*\"'contest',\" + 0.007*\"'trip',\" + 0.007*\"'test',\" + 0.007*\"'father',\" + 0.007*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.033): 0.010*\"'union',\" + 0.009*\"'buy',\" + 0.007*\"'last',\" + 0.007*\"'futur',\" + 0.007*\"'enlist',\" + 0.007*\"'best',\" + 0.007*\"'collect',\" + 0.007*\"'leader',\" + 0.005*\"['accident',\" + 0.005*\"'plant',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.033): 0.010*\"'fail',\" + 0.010*\"'hand',\" + 0.010*\"'apu',\" + 0.007*\"'celebr',\" + 0.007*\"'year',\" + 0.007*\"'anoth',\" + 0.007*\"'grade',\" + 0.007*\"'smither',\" + 0.007*\"'scene',\" + 0.007*\"'elementari',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.159691, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-9.517 per-word bound, 732.5 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.033): 0.010*\"'offer',\" + 0.009*\"'movi',\" + 0.009*\"'open',\" + 0.008*\"'front',\" + 0.008*\"'phone',\" + 0.008*\"'leari',\" + 0.007*\"'maud',\" + 0.006*\"'woman',\" + 0.006*\"'friend',\" + 0.006*\"'move',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.033): 0.012*\"'selma',\" + 0.011*\"'boy',\" + 0.009*\"'babi',\" + 0.008*\"'chief',\" + 0.008*\"'busi',\" + 0.007*\"'futur',\" + 0.007*\"'choos',\" + 0.007*\"'adopt',\" + 0.007*\"'marri',\" + 0.006*\"'annual',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.013*\"'chloe',\" + 0.011*\"'fli',\" + 0.011*\"'chalmer',\" + 0.010*\"'littl',\" + 0.009*\"'parti',\" + 0.008*\"'invit',\" + 0.008*\"'edna',\" + 0.008*\"'helper',\" + 0.008*\"'boy',\" + 0.008*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.033): 0.009*\"'bad',\" + 0.009*\"'club',\" + 0.009*\"'apu',\" + 0.008*\"'replac',\" + 0.008*\"'littl',\" + 0.007*\"'convinc',\" + 0.007*\"'bar',\" + 0.007*\"'set',\" + 0.007*\"'job',\" + 0.006*\"'kwik',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.033): 0.012*\"'bar',\" + 0.010*\"'mitzvah',\" + 0.008*\"'show',\" + 0.007*\"'bear',\" + 0.007*\"'littl',\" + 0.007*\"'boy',\" + 0.007*\"'stori',\" + 0.006*\"'actual',\" + 0.006*\"'dog',\" + 0.006*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.211237, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-8.739 per-word bound, 427.1 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #5 = documents up to #600/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.033): 0.012*\"'stori',\" + 0.009*\"'employe',\" + 0.009*\"'local',\" + 0.008*\"'race',\" + 0.007*\"'plant',\" + 0.007*\"'star',\" + 0.007*\"'rag',\" + 0.006*\"'fellow',\" + 0.006*\"'miss',\" + 0.006*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.033): 0.009*\"'local',\" + 0.008*\"'segment',\" + 0.007*\"'art',\" + 0.006*\"'father',\" + 0.006*\"'friend',\" + 0.006*\"'attack',\" + 0.006*\"'willi',\" + 0.006*\"'convinc',\" + 0.006*\"'teacher',\" + 0.006*\"'win',\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.033): 0.020*\"'power',\" + 0.016*\"'nuclear',\" + 0.014*\"'plant',\" + 0.009*\"'friend',\" + 0.006*\"'luann',\" + 0.006*\"'attract',\" + 0.006*\"'job',\" + 0.006*\"'activ',\" + 0.005*\"'smither',\" + 0.005*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.033): 0.009*\"'appear',\" + 0.008*\"'voic',\" + 0.007*\"'open',\" + 0.006*\"'bob',\" + 0.006*\"'music',\" + 0.006*\"'last',\" + 0.006*\"'guest',\" + 0.006*\"'featur',\" + 0.006*\"'hell',\" + 0.006*\"'terror',\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.033): 0.007*\"'find',\" + 0.007*\"'bad',\" + 0.006*\"'move',\" + 0.006*\"'father',\" + 0.005*\"'ralph',\" + 0.005*\"'learn',\" + 0.005*\"'star',\" + 0.005*\"'dream',\" + 0.005*\"'everi',\" + 0.005*\"'island',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.164497, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-9.053 per-word bound, 531.3 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.033): 0.028*\"'pie',\" + 0.013*\"'man',\" + 0.010*\"'children',\" + 0.009*\"'promis',\" + 0.008*\"'better',\" + 0.008*\"'ride',\" + 0.008*\"'team',\" + 0.008*\"'competit',\" + 0.007*\"'face',\" + 0.006*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.033): 0.008*\"'buy',\" + 0.007*\"'union',\" + 0.007*\"'littl',\" + 0.007*\"'talk',\" + 0.007*\"'bed',\" + 0.007*\"'mattress',\" + 0.007*\"'promot',\" + 0.007*\"'photo',\" + 0.007*\"'win',\" + 0.006*\"'keep',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.033): 0.010*\"'star',\" + 0.010*\"'rag',\" + 0.009*\"'stori',\" + 0.009*\"'employe',\" + 0.008*\"'famili',\" + 0.008*\"'parodi',\" + 0.008*\"'friend',\" + 0.007*\"'fellow',\" + 0.007*\"'miss',\" + 0.006*\"'plant',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.033): 0.009*\"'grampa',\" + 0.008*\"'write',\" + 0.008*\"'convinc',\" + 0.007*\"'stori',\" + 0.006*\"'life',\" + 0.006*\"'high',\" + 0.006*\"'take',\" + 0.006*\"'arti',\" + 0.006*\"'bashir',\" + 0.005*\"'show',\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.033): 0.016*\"'power',\" + 0.013*\"'nuclear',\" + 0.011*\"'plant',\" + 0.010*\"'friend',\" + 0.008*\"'activ',\" + 0.008*\"'santa',\" + 0.006*\"'interest',\" + 0.006*\"'train',\" + 0.006*\"'christma',\" + 0.006*\"'luann',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.184136, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-8.539 per-word bound, 371.9 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.011*\"'bulli',\" + 0.009*\"'beat',\" + 0.008*\"'win',\" + 0.008*\"'elementari',\" + 0.007*\"'friend',\" + 0.007*\"'result',\" + 0.007*\"'stay',\" + 0.006*\"'gang',\" + 0.006*\"'contest',\" + 0.006*\"'trip',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.033): 0.012*\"'bar',\" + 0.010*\"'mitzvah',\" + 0.008*\"'littl',\" + 0.008*\"'show',\" + 0.007*\"'helper',\" + 0.006*\"'stori',\" + 0.006*\"'dog',\" + 0.006*\"'replac',\" + 0.006*\"'teach',\" + 0.006*\"'actual',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.033): 0.009*\"'quick',\" + 0.009*\"'sara',\" + 0.008*\"'someth',\" + 0.008*\"'offer',\" + 0.007*\"'date',\" + 0.006*\"'lose',\" + 0.006*\"'new',\" + 0.006*\"'beer',\" + 0.006*\"'choos',\" + 0.005*\"'enter',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.033): 0.009*\"'local',\" + 0.009*\"'segment',\" + 0.007*\"'art',\" + 0.007*\"'father',\" + 0.007*\"'willi',\" + 0.007*\"'attack',\" + 0.007*\"'convinc',\" + 0.006*\"'friend',\" + 0.006*\"'teacher',\" + 0.006*\"'game',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.033): 0.022*\"'pie',\" + 0.010*\"'man',\" + 0.010*\"'team',\" + 0.009*\"'children',\" + 0.009*\"'better',\" + 0.007*\"'competit',\" + 0.007*\"'promis',\" + 0.007*\"'new',\" + 0.007*\"'bowl',\" + 0.006*\"'littl',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.154374, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-8.843 per-word bound, 459.3 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.015*\"'chloe',\" + 0.012*\"'fli',\" + 0.011*\"'chalmer',\" + 0.010*\"'littl',\" + 0.009*\"'parti',\" + 0.009*\"'invit',\" + 0.009*\"'edna',\" + 0.008*\"'helper',\" + 0.008*\"'boy',\" + 0.007*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.033): 0.013*\"'save',\" + 0.009*\"'christma',\" + 0.008*\"'life',\" + 0.008*\"'stay',\" + 0.007*\"'mayor',\" + 0.007*\"'church',\" + 0.007*\"'well',\" + 0.007*\"'show',\" + 0.007*\"'univers',\" + 0.007*\"'insist',\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.033): 0.012*\"'busi',\" + 0.010*\"'drive',\" + 0.010*\"'women',\" + 0.009*\"'bar',\" + 0.009*\"'soon',\" + 0.009*\"'tavern',\" + 0.008*\"'men',\" + 0.007*\"'steal',\" + 0.007*\"'decid',\" + 0.006*\"'drink',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.033): 0.012*\"'dream',\" + 0.010*\"'christma',\" + 0.008*\"'friend',\" + 0.008*\"'creat',\" + 0.007*\"'good',\" + 0.007*\"'prompt',\" + 0.006*\"'set',\" + 0.006*\"'keep',\" + 0.006*\"'mayor',\" + 0.006*\"'prove',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.033): 0.009*\"'grampa',\" + 0.009*\"'write',\" + 0.008*\"'convinc',\" + 0.006*\"'stori',\" + 0.006*\"'life',\" + 0.006*\"'high',\" + 0.006*\"'take',\" + 0.006*\"'arti',\" + 0.006*\"'bashir',\" + 0.005*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.158126, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-8.442 per-word bound, 347.8 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.033): 0.013*\"'key',\" + 0.010*\"'assist',\" + 0.009*\"'live',\" + 0.008*\"'popular',\" + 0.007*\"'trip',\" + 0.007*\"'keep',\" + 0.007*\"'spend',\" + 0.007*\"'convent',\" + 0.006*\"'free',\" + 0.006*\"'perform',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.011*\"'bulli',\" + 0.009*\"'beat',\" + 0.008*\"'win',\" + 0.008*\"'elementari',\" + 0.007*\"'friend',\" + 0.007*\"'result',\" + 0.007*\"'stay',\" + 0.006*\"'gang',\" + 0.006*\"'contest',\" + 0.006*\"'trip',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #3 (0.033): 0.009*\"'bob',\" + 0.008*\"'appear',\" + 0.008*\"'voic',\" + 0.007*\"'live',\" + 0.007*\"'music',\" + 0.007*\"'last',\" + 0.006*\"'scene',\" + 0.006*\"'lesson',\" + 0.006*\"'shock',\" + 0.006*\"'open',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.033): 0.010*\"'fail',\" + 0.010*\"'hand',\" + 0.010*\"'apu',\" + 0.006*\"'celebr',\" + 0.006*\"'year',\" + 0.006*\"'anoth',\" + 0.006*\"'grade',\" + 0.006*\"'smither',\" + 0.006*\"'scene',\" + 0.006*\"'elementari',\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.033): 0.016*\"'princip',\" + 0.014*\"'job',\" + 0.011*\"'smither',\" + 0.009*\"'fire',\" + 0.008*\"'drive',\" + 0.008*\"'save',\" + 0.007*\"'clown',\" + 0.007*\"'casino',\" + 0.007*\"'open',\" + 0.007*\"'adopt',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.135852, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-8.741 per-word bound, 428.0 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.033): 0.017*\"'selma',\" + 0.013*\"'boy',\" + 0.011*\"'babi',\" + 0.009*\"'marri',\" + 0.009*\"'chief',\" + 0.008*\"'busi',\" + 0.008*\"'adopt',\" + 0.007*\"'futur',\" + 0.007*\"'choos',\" + 0.006*\"'annual',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.033): 0.030*\"'pie',\" + 0.014*\"'man',\" + 0.011*\"'children',\" + 0.009*\"'promis',\" + 0.008*\"'competit',\" + 0.008*\"'team',\" + 0.008*\"'better',\" + 0.007*\"'ride',\" + 0.007*\"'face',\" + 0.006*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.033): 0.013*\"'princip',\" + 0.010*\"'job',\" + 0.009*\"'drive',\" + 0.009*\"'save',\" + 0.008*\"'fire',\" + 0.007*\"'smither',\" + 0.007*\"'littl',\" + 0.007*\"'helper',\" + 0.007*\"'santa',\" + 0.007*\"'relationship',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.033): 0.013*\"'save',\" + 0.009*\"'christma',\" + 0.008*\"'life',\" + 0.007*\"'mayor',\" + 0.007*\"'church',\" + 0.007*\"'show',\" + 0.007*\"'stay',\" + 0.007*\"'well',\" + 0.007*\"'univers',\" + 0.007*\"'insist',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.033): 0.009*\"'bob',\" + 0.008*\"'lesson',\" + 0.007*\"'music',\" + 0.007*\"'last',\" + 0.007*\"'shock',\" + 0.007*\"'scene',\" + 0.007*\"'voic',\" + 0.006*\"'live',\" + 0.006*\"'appear',\" + 0.006*\"'littl',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.133144, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-8.396 per-word bound, 336.9 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #3 = documents up to #400/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #4 = documents up to #500/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #5 = documents up to #600/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.033): 0.014*\"'apu',\" + 0.014*\"'mart',\" + 0.012*\"'bad',\" + 0.011*\"'club',\" + 0.010*\"'kwik',\" + 0.010*\"'job',\" + 0.009*\"'bar',\" + 0.009*\"'convinc',\" + 0.008*\"'littl',\" + 0.007*\"'replac',\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.033): 0.014*\"'key',\" + 0.010*\"'assist',\" + 0.008*\"'keep',\" + 0.008*\"'spend',\" + 0.008*\"'popular',\" + 0.007*\"'trip',\" + 0.006*\"'convent',\" + 0.006*\"'move',\" + 0.006*\"'cemeteri',\" + 0.006*\"'live',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.033): 0.010*\"'stori',\" + 0.009*\"'employe',\" + 0.008*\"'race',\" + 0.008*\"'star',\" + 0.008*\"'rag',\" + 0.007*\"'plant',\" + 0.006*\"'move',\" + 0.006*\"'fellow',\" + 0.006*\"'lenni',\" + 0.006*\"'compani',\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.033): 0.012*\"'busi',\" + 0.010*\"'steal',\" + 0.010*\"'tavern',\" + 0.008*\"'soon',\" + 0.008*\"'women',\" + 0.008*\"'hair',\" + 0.008*\"'drive',\" + 0.008*\"'bar',\" + 0.007*\"'men',\" + 0.007*\"'thank',\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.033): 0.017*\"'princip',\" + 0.013*\"'job',\" + 0.012*\"'drive',\" + 0.011*\"'fire',\" + 0.008*\"'save',\" + 0.008*\"'littl',\" + 0.008*\"'helper',\" + 0.008*\"'santa',\" + 0.008*\"'relationship',\" + 0.007*\"'licens',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.088773, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-8.769 per-word bound, 436.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.033): 0.013*\"'busi',\" + 0.011*\"'drive',\" + 0.010*\"'tavern',\" + 0.010*\"'women',\" + 0.009*\"'bar',\" + 0.009*\"'soon',\" + 0.008*\"'men',\" + 0.008*\"'steal',\" + 0.007*\"'drink',\" + 0.006*\"'hair',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.033): 0.009*\"'game',\" + 0.009*\"'father',\" + 0.008*\"'convinc',\" + 0.007*\"'willi',\" + 0.007*\"'bulli',\" + 0.007*\"'littl',\" + 0.007*\"'voic',\" + 0.007*\"'carl',\" + 0.007*\"'local',\" + 0.006*\"'segment',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.033): 0.015*\"'bar',\" + 0.012*\"'mitzvah',\" + 0.010*\"'show',\" + 0.008*\"'littl',\" + 0.007*\"'actual',\" + 0.007*\"'dog',\" + 0.007*\"'stori',\" + 0.007*\"'helper',\" + 0.007*\"'jewish',\" + 0.007*\"'replac',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.033): 0.013*\"'spi',\" + 0.013*\"'glass',\" + 0.012*\"'secret',\" + 0.009*\"'gift',\" + 0.009*\"'form',\" + 0.009*\"'counselor',\" + 0.007*\"'nelson',\" + 0.007*\"'earli',\" + 0.007*\"'band',\" + 0.007*\"'parodi',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.033): 0.010*\"'clip',\" + 0.010*\"'team',\" + 0.008*\"'romant',\" + 0.007*\"'bowl',\" + 0.007*\"'laney',\" + 0.007*\"'fear',\" + 0.007*\"'strangl',\" + 0.007*\"'popular',\" + 0.007*\"'face',\" + 0.006*\"'around',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.093066, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-8.350 per-word bound, 326.4 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.017*\"'littl',\" + 0.012*\"'helper',\" + 0.010*\"'chalmer',\" + 0.009*\"'chloe',\" + 0.009*\"'santa',\" + 0.009*\"'snake',\" + 0.009*\"'fli',\" + 0.008*\"'forc',\" + 0.008*\"'save',\" + 0.007*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.033): 0.011*\"'write',\" + 0.011*\"'grampa',\" + 0.010*\"'convinc',\" + 0.009*\"'stori',\" + 0.009*\"'life',\" + 0.008*\"'high',\" + 0.006*\"'role',\" + 0.006*\"'tale',\" + 0.006*\"'tall',\" + 0.006*\"'form',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.033): 0.014*\"'clip',\" + 0.010*\"'bowl',\" + 0.009*\"'romant',\" + 0.008*\"'around',\" + 0.007*\"'quick',\" + 0.007*\"'team',\" + 0.007*\"'ball',\" + 0.007*\"'show',\" + 0.006*\"'fashion',\" + 0.006*\"'red',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.033): 0.013*\"'selma',\" + 0.011*\"'boy',\" + 0.009*\"'marri',\" + 0.008*\"'babi',\" + 0.007*\"'futur',\" + 0.007*\"'choos',\" + 0.007*\"'chief',\" + 0.006*\"'hous',\" + 0.006*\"'busi',\" + 0.006*\"'scratchi',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.033): 0.009*\"'local',\" + 0.009*\"'segment',\" + 0.008*\"'father',\" + 0.007*\"'convinc',\" + 0.007*\"'art',\" + 0.007*\"'attack',\" + 0.007*\"'willi',\" + 0.006*\"'friend',\" + 0.006*\"'game',\" + 0.006*\"'film',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.095774, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-8.632 per-word bound, 396.8 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.033): 0.013*\"'princip',\" + 0.010*\"'job',\" + 0.010*\"'save',\" + 0.009*\"'drive',\" + 0.008*\"'smither',\" + 0.008*\"'fire',\" + 0.007*\"'invit',\" + 0.007*\"'littl',\" + 0.007*\"'helper',\" + 0.007*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.033): 0.013*\"'dream',\" + 0.011*\"'christma',\" + 0.008*\"'creat',\" + 0.008*\"'friend',\" + 0.007*\"'prove',\" + 0.007*\"'good',\" + 0.007*\"'prompt',\" + 0.007*\"'thing',\" + 0.006*\"'keep',\" + 0.006*\"'set',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.033): 0.016*\"'selma',\" + 0.013*\"'boy',\" + 0.011*\"'marri',\" + 0.010*\"'babi',\" + 0.009*\"'chief',\" + 0.008*\"'busi',\" + 0.007*\"'adopt',\" + 0.007*\"'futur',\" + 0.007*\"'choos',\" + 0.006*\"'annual',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.033): 0.028*\"'pie',\" + 0.013*\"'man',\" + 0.011*\"'children',\" + 0.009*\"'team',\" + 0.009*\"'promis',\" + 0.008*\"'better',\" + 0.008*\"'competit',\" + 0.007*\"'ride',\" + 0.007*\"'face',\" + 0.006*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.033): 0.015*\"'love',\" + 0.013*\"'grampa',\" + 0.013*\"'stori',\" + 0.011*\"'movi',\" + 0.010*\"'life',\" + 0.008*\"'guy',\" + 0.007*\"'parti',\" + 0.007*\"'seri',\" + 0.007*\"'comic',\" + 0.007*\"'compani',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.100833, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-8.357 per-word bound, 327.9 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.011*\"'bulli',\" + 0.009*\"'beat',\" + 0.008*\"'elementari',\" + 0.008*\"'win',\" + 0.007*\"'friend',\" + 0.007*\"'result',\" + 0.007*\"'stay',\" + 0.006*\"'gang',\" + 0.006*\"'contest',\" + 0.006*\"'trip',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.017*\"'littl',\" + 0.012*\"'helper',\" + 0.010*\"'chloe',\" + 0.010*\"'chalmer',\" + 0.009*\"'santa',\" + 0.009*\"'snake',\" + 0.009*\"'fli',\" + 0.008*\"'forc',\" + 0.008*\"'save',\" + 0.007*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.033): 0.010*\"'life',\" + 0.010*\"'mayor',\" + 0.010*\"'show',\" + 0.010*\"'save',\" + 0.010*\"'church',\" + 0.008*\"'christma',\" + 0.007*\"'quimbi',\" + 0.007*\"'behind',\" + 0.007*\"'accident',\" + 0.007*\"'predict',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.033): 0.014*\"'learn',\" + 0.011*\"'littl',\" + 0.010*\"'seem',\" + 0.008*\"'problem',\" + 0.008*\"'none',\" + 0.008*\"'spend',\" + 0.008*\"'week',\" + 0.006*\"'perfect',\" + 0.006*\"'yet',\" + 0.006*\"'anoth',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.033): 0.011*\"'write',\" + 0.010*\"'grampa',\" + 0.010*\"'convinc',\" + 0.009*\"'stori',\" + 0.008*\"'life',\" + 0.008*\"'high',\" + 0.006*\"'role',\" + 0.006*\"'tale',\" + 0.006*\"'tall',\" + 0.006*\"'form',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.084960, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-8.626 per-word bound, 395.1 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.033): 0.020*\"'power',\" + 0.019*\"'nuclear',\" + 0.018*\"'plant',\" + 0.010*\"'friend',\" + 0.008*\"'activ',\" + 0.008*\"'santa',\" + 0.007*\"'luann',\" + 0.007*\"'convent',\" + 0.006*\"'hire',\" + 0.006*\"'bedroom',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.033): 0.008*\"'fail',\" + 0.008*\"'hand',\" + 0.008*\"'apu',\" + 0.007*\"'diari',\" + 0.006*\"'fortun',\" + 0.005*\"'celebr',\" + 0.005*\"'year',\" + 0.005*\"'elementari',\" + 0.005*\"'anoth',\" + 0.005*\"'blame',\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.033): 0.013*\"'princip',\" + 0.010*\"'job',\" + 0.009*\"'save',\" + 0.009*\"'drive',\" + 0.008*\"'fire',\" + 0.008*\"'smither',\" + 0.007*\"'invit',\" + 0.007*\"'littl',\" + 0.007*\"'helper',\" + 0.007*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.033): 0.013*\"'sara',\" + 0.009*\"'date',\" + 0.008*\"'offer',\" + 0.007*\"'someth',\" + 0.007*\"'new',\" + 0.007*\"'quick',\" + 0.006*\"'past',\" + 0.006*\"'camera',\" + 0.006*\"'comic',\" + 0.006*\"'toni',\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.033): 0.010*\"'apart',\" + 0.010*\"'gay',\" + 0.009*\"'break',\" + 0.009*\"'princip',\" + 0.009*\"'enjoy',\" + 0.008*\"'move',\" + 0.008*\"'calm',\" + 0.007*\"'teach',\" + 0.007*\"'gradi',\" + 0.007*\"'good',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.086579, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-8.360 per-word bound, 328.5 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.033): 0.009*\"'enjoy',\" + 0.008*\"'princip',\" + 0.008*\"'itchi',\" + 0.008*\"'apart',\" + 0.008*\"'move',\" + 0.007*\"'gay',\" + 0.007*\"'break',\" + 0.006*\"'good',\" + 0.006*\"'life',\" + 0.006*\"'sideshow',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.017*\"'littl',\" + 0.012*\"'helper',\" + 0.011*\"'chloe',\" + 0.010*\"'chalmer',\" + 0.009*\"'santa',\" + 0.009*\"'snake',\" + 0.009*\"'fli',\" + 0.008*\"'forc',\" + 0.008*\"'save',\" + 0.007*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.033): 0.015*\"'selma',\" + 0.011*\"'boy',\" + 0.010*\"'marri',\" + 0.008*\"'babi',\" + 0.007*\"'futur',\" + 0.007*\"'choos',\" + 0.007*\"'chief',\" + 0.006*\"'busi',\" + 0.006*\"'adopt',\" + 0.006*\"'hous',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.033): 0.010*\"'fail',\" + 0.010*\"'hand',\" + 0.010*\"'apu',\" + 0.007*\"'celebr',\" + 0.007*\"'year',\" + 0.007*\"'elementari',\" + 0.006*\"'anoth',\" + 0.006*\"'blame',\" + 0.006*\"'smither',\" + 0.006*\"'scene',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.033): 0.011*\"'secret',\" + 0.010*\"'spi',\" + 0.010*\"'glass',\" + 0.009*\"'gift',\" + 0.008*\"'form',\" + 0.008*\"'counselor',\" + 0.007*\"'bear',\" + 0.007*\"'choos',\" + 0.007*\"'stampi',\" + 0.007*\"'eleph',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.076502, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-8.619 per-word bound, 393.1 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.014*\"'chloe',\" + 0.012*\"'littl',\" + 0.012*\"'fli',\" + 0.011*\"'edna',\" + 0.011*\"'chalmer',\" + 0.009*\"'invit',\" + 0.009*\"'parti',\" + 0.009*\"'helper',\" + 0.008*\"'boy',\" + 0.008*\"'save',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.009*\"'bulli',\" + 0.008*\"'friend',\" + 0.008*\"'result',\" + 0.008*\"'stay',\" + 0.007*\"'elementari',\" + 0.007*\"'win',\" + 0.006*\"'beat',\" + 0.006*\"'apart',\" + 0.006*\"'sign',\" + 0.006*\"'person',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.033): 0.008*\"'fail',\" + 0.008*\"'hand',\" + 0.008*\"'apu',\" + 0.007*\"'diari',\" + 0.006*\"'fortun',\" + 0.005*\"'celebr',\" + 0.005*\"'year',\" + 0.005*\"'elementari',\" + 0.005*\"'anoth',\" + 0.005*\"'blame',\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.033): 0.032*\"'bear',\" + 0.017*\"'bulli',\" + 0.017*\"'nelson',\" + 0.012*\"'friend',\" + 0.010*\"'group',\" + 0.009*\"'grampa',\" + 0.008*\"'leader',\" + 0.008*\"'thing',\" + 0.008*\"'attack',\" + 0.008*\"'make',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #1 (0.033): 0.015*\"'snake',\" + 0.008*\"'join',\" + 0.008*\"'music',\" + 0.007*\"'local',\" + 0.006*\"'make',\" + 0.006*\"'girl',\" + 0.006*\"'anyth',\" + 0.006*\"'post',\" + 0.006*\"'left',\" + 0.006*\"'love',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.077224, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-8.361 per-word bound, 328.8 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.033): 0.009*\"'enjoy',\" + 0.008*\"'princip',\" + 0.008*\"'itchi',\" + 0.008*\"'apart',\" + 0.008*\"'move',\" + 0.008*\"'gay',\" + 0.007*\"'break',\" + 0.006*\"'good',\" + 0.006*\"'life',\" + 0.006*\"'sideshow',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.017*\"'littl',\" + 0.012*\"'helper',\" + 0.011*\"'chloe',\" + 0.010*\"'chalmer',\" + 0.009*\"'fli',\" + 0.009*\"'santa',\" + 0.009*\"'snake',\" + 0.009*\"'edna',\" + 0.009*\"'save',\" + 0.008*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.033): 0.008*\"'find',\" + 0.007*\"'bad',\" + 0.006*\"'move',\" + 0.006*\"'learn',\" + 0.005*\"'ralph',\" + 0.005*\"'father',\" + 0.005*\"'star',\" + 0.005*\"'everi',\" + 0.005*\"'island',\" + 0.005*\"'group',\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.033): 0.014*\"'shirt',\" + 0.010*\"'nuclear',\" + 0.009*\"'food',\" + 0.009*\"'decid',\" + 0.009*\"'take',\" + 0.009*\"'get',\" + 0.009*\"'busi',\" + 0.009*\"'lose',\" + 0.009*\"'goos',\" + 0.007*\"'child',\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.033): 0.014*\"'busi',\" + 0.010*\"'steal',\" + 0.010*\"'tavern',\" + 0.009*\"'drive',\" + 0.008*\"'bar',\" + 0.008*\"'men',\" + 0.008*\"'hair',\" + 0.008*\"'women',\" + 0.008*\"'soon',\" + 0.007*\"'drink',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070526, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-8.611 per-word bound, 391.1 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.009*\"'bulli',\" + 0.008*\"'result',\" + 0.008*\"'friend',\" + 0.008*\"'stay',\" + 0.007*\"'elementari',\" + 0.007*\"'win',\" + 0.007*\"'beat',\" + 0.006*\"'apart',\" + 0.006*\"'sign',\" + 0.006*\"'person',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.033): 0.017*\"'bar',\" + 0.014*\"'mitzvah',\" + 0.011*\"'show',\" + 0.008*\"'littl',\" + 0.008*\"'actual',\" + 0.008*\"'jewish',\" + 0.007*\"'dog',\" + 0.007*\"'stori',\" + 0.007*\"'replac',\" + 0.007*\"'helper',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.033): 0.014*\"'chloe',\" + 0.013*\"'edna',\" + 0.013*\"'littl',\" + 0.012*\"'fli',\" + 0.011*\"'chalmer',\" + 0.009*\"'invit',\" + 0.009*\"'parti',\" + 0.009*\"'helper',\" + 0.008*\"'save',\" + 0.008*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.033): 0.014*\"'must',\" + 0.010*\"'lost',\" + 0.009*\"'love',\" + 0.008*\"'cut',\" + 0.008*\"'wayn',\" + 0.008*\"'father',\" + 0.008*\"'princ',\" + 0.008*\"'protect',\" + 0.008*\"'chosen',\" + 0.008*\"'relat']\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.033): 0.015*\"'snake',\" + 0.008*\"'music',\" + 0.008*\"'join',\" + 0.007*\"'local',\" + 0.006*\"'make',\" + 0.006*\"'girl',\" + 0.006*\"'anyth',\" + 0.006*\"'post',\" + 0.006*\"'left',\" + 0.006*\"'love',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.070805, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-8.363 per-word bound, 329.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=K, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #18 (0.033): 0.013*\"'busi',\" + 0.011*\"'drive',\" + 0.010*\"'tavern',\" + 0.010*\"'steal',\" + 0.010*\"'women',\" + 0.009*\"'soon',\" + 0.009*\"'men',\" + 0.009*\"'bar',\" + 0.007*\"'drink',\" + 0.007*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.033): 0.030*\"'pie',\" + 0.014*\"'man',\" + 0.011*\"'children',\" + 0.009*\"'promis',\" + 0.009*\"'team',\" + 0.008*\"'competit',\" + 0.008*\"'better',\" + 0.007*\"'ride',\" + 0.007*\"'face',\" + 0.007*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.033): 0.010*\"'grampa',\" + 0.009*\"'write',\" + 0.008*\"'convinc',\" + 0.007*\"'stori',\" + 0.007*\"'life',\" + 0.007*\"'high',\" + 0.006*\"'take',\" + 0.006*\"'bashir',\" + 0.006*\"'arti',\" + 0.005*\"'forc',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.033): 0.014*\"'dream',\" + 0.011*\"'christma',\" + 0.008*\"'creat',\" + 0.008*\"'friend',\" + 0.008*\"'prove',\" + 0.007*\"'good',\" + 0.007*\"'prompt',\" + 0.007*\"'thing',\" + 0.006*\"'keep',\" + 0.006*\"'set',\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.033): 0.010*\"'team',\" + 0.010*\"'clip',\" + 0.008*\"'romant',\" + 0.007*\"'bowl',\" + 0.007*\"'laney',\" + 0.007*\"'fear',\" + 0.007*\"'strangl',\" + 0.007*\"'popular',\" + 0.007*\"'face',\" + 0.007*\"'relationship',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.033): 0.013*\"'save',\" + 0.009*\"'christma',\" + 0.008*\"'life',\" + 0.008*\"'mayor',\" + 0.008*\"'show',\" + 0.008*\"'church',\" + 0.007*\"'univers',\" + 0.007*\"'stay',\" + 0.007*\"'well',\" + 0.007*\"'insist',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.033): 0.009*\"'bob',\" + 0.008*\"'lesson',\" + 0.007*\"'music',\" + 0.007*\"'last',\" + 0.007*\"'shock',\" + 0.007*\"'scene',\" + 0.007*\"'live',\" + 0.007*\"'voic',\" + 0.006*\"'appear',\" + 0.005*\"'trap',\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.033): 0.010*\"'apart',\" + 0.010*\"'gay',\" + 0.009*\"'break',\" + 0.009*\"'princip',\" + 0.009*\"'enjoy',\" + 0.008*\"'move',\" + 0.008*\"'calm',\" + 0.007*\"'teach',\" + 0.007*\"'gradi',\" + 0.007*\"'good',\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.033): 0.015*\"'love',\" + 0.013*\"'stori',\" + 0.013*\"'grampa',\" + 0.011*\"'movi',\" + 0.010*\"'life',\" + 0.009*\"'guy',\" + 0.007*\"'parti',\" + 0.007*\"'comic',\" + 0.007*\"'compani',\" + 0.007*\"'seri',\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.033): 0.014*\"'princip',\" + 0.010*\"'job',\" + 0.009*\"'save',\" + 0.009*\"'drive',\" + 0.008*\"'fire',\" + 0.008*\"'smither',\" + 0.007*\"'invit',\" + 0.007*\"'littl',\" + 0.007*\"'helper',\" + 0.007*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.033): 0.009*\"'bulli',\" + 0.008*\"'result',\" + 0.008*\"'friend',\" + 0.008*\"'stay',\" + 0.007*\"'elementari',\" + 0.007*\"'win',\" + 0.007*\"'beat',\" + 0.006*\"'apart',\" + 0.006*\"'sign',\" + 0.006*\"'person',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.033): 0.014*\"'sara',\" + 0.009*\"'date',\" + 0.008*\"'offer',\" + 0.007*\"'someth',\" + 0.007*\"'new',\" + 0.007*\"'past',\" + 0.006*\"'quick',\" + 0.006*\"'camera',\" + 0.006*\"'comic',\" + 0.006*\"'toni',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.033): 0.014*\"'must',\" + 0.010*\"'lost',\" + 0.009*\"'love',\" + 0.008*\"'cut',\" + 0.008*\"'wayn',\" + 0.008*\"'father',\" + 0.008*\"'princ',\" + 0.008*\"'protect',\" + 0.008*\"'chosen',\" + 0.008*\"'relat']\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.033): 0.023*\"'plant',\" + 0.022*\"'power',\" + 0.020*\"'nuclear',\" + 0.010*\"'friend',\" + 0.008*\"'activ',\" + 0.008*\"'santa',\" + 0.007*\"'luann',\" + 0.007*\"'convent',\" + 0.006*\"'hire',\" + 0.006*\"'bedroom',\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.033): 0.008*\"'find',\" + 0.007*\"'bad',\" + 0.006*\"'move',\" + 0.006*\"'learn',\" + 0.006*\"'group',\" + 0.006*\"'congressman',\" + 0.006*\"'get',\" + 0.005*\"'father',\" + 0.005*\"'star',\" + 0.005*\"'ralph',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.033): 0.015*\"'snake',\" + 0.008*\"'music',\" + 0.008*\"'join',\" + 0.007*\"'local',\" + 0.006*\"'make',\" + 0.006*\"'girl',\" + 0.006*\"'anyth',\" + 0.006*\"'post',\" + 0.006*\"'left',\" + 0.006*\"'love',\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.033): 0.011*\"'movi',\" + 0.010*\"'offer',\" + 0.009*\"'woman',\" + 0.009*\"'open',\" + 0.009*\"'maud',\" + 0.009*\"'front',\" + 0.008*\"'phone',\" + 0.008*\"'leari',\" + 0.007*\"'present',\" + 0.007*\"'film',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.033): 0.010*\"'father',\" + 0.009*\"'game',\" + 0.008*\"'convinc',\" + 0.008*\"'willi',\" + 0.007*\"'bulli',\" + 0.007*\"'littl',\" + 0.007*\"'voic',\" + 0.007*\"'carl',\" + 0.007*\"'local',\" + 0.007*\"'ice',\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.033): 0.009*\"'photo',\" + 0.008*\"'buy',\" + 0.008*\"'union',\" + 0.007*\"'promot',\" + 0.007*\"'win',\" + 0.007*\"'keep',\" + 0.007*\"'date',\" + 0.007*\"'littl',\" + 0.007*\"'talk',\" + 0.007*\"'mattress',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.033): 0.017*\"'selma',\" + 0.013*\"'boy',\" + 0.012*\"'marri',\" + 0.010*\"'babi',\" + 0.008*\"'chief',\" + 0.008*\"'busi',\" + 0.008*\"'adopt',\" + 0.007*\"'futur',\" + 0.007*\"'choos',\" + 0.005*\"'happen',\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(18,\n",
      "  '0.013*\"\\'busi\\',\" + 0.011*\"\\'drive\\',\" + 0.010*\"\\'tavern\\',\" + '\n",
      "  '0.010*\"\\'steal\\',\" + 0.010*\"\\'women\\',\" + 0.009*\"\\'soon\\',\" + '\n",
      "  '0.009*\"\\'men\\',\" + 0.009*\"\\'bar\\',\" + 0.007*\"\\'drink\\',\" + '\n",
      "  '0.007*\"\\'boy\\',\"'),\n",
      " (8,\n",
      "  '0.030*\"\\'pie\\',\" + 0.014*\"\\'man\\',\" + 0.011*\"\\'children\\',\" + '\n",
      "  '0.009*\"\\'promis\\',\" + 0.009*\"\\'team\\',\" + 0.008*\"\\'competit\\',\" + '\n",
      "  '0.008*\"\\'better\\',\" + 0.007*\"\\'ride\\',\" + 0.007*\"\\'face\\',\" + '\n",
      "  '0.007*\"\\'buy\\',\"'),\n",
      " (29,\n",
      "  '0.010*\"\\'grampa\\',\" + 0.009*\"\\'write\\',\" + 0.008*\"\\'convinc\\',\" + '\n",
      "  '0.007*\"\\'stori\\',\" + 0.007*\"\\'life\\',\" + 0.007*\"\\'high\\',\" + '\n",
      "  '0.006*\"\\'take\\',\" + 0.006*\"\\'bashir\\',\" + 0.006*\"\\'arti\\',\" + '\n",
      "  '0.005*\"\\'forc\\',\"'),\n",
      " (13,\n",
      "  '0.014*\"\\'dream\\',\" + 0.011*\"\\'christma\\',\" + 0.008*\"\\'creat\\',\" + '\n",
      "  '0.008*\"\\'friend\\',\" + 0.008*\"\\'prove\\',\" + 0.007*\"\\'good\\',\" + '\n",
      "  '0.007*\"\\'prompt\\',\" + 0.007*\"\\'thing\\',\" + 0.006*\"\\'keep\\',\" + '\n",
      "  '0.006*\"\\'set\\',\"'),\n",
      " (0,\n",
      "  '0.010*\"\\'team\\',\" + 0.010*\"\\'clip\\',\" + 0.008*\"\\'romant\\',\" + '\n",
      "  '0.007*\"\\'bowl\\',\" + 0.007*\"\\'laney\\',\" + 0.007*\"\\'fear\\',\" + '\n",
      "  '0.007*\"\\'strangl\\',\" + 0.007*\"\\'popular\\',\" + 0.007*\"\\'face\\',\" + '\n",
      "  '0.007*\"\\'relationship\\',\"'),\n",
      " (4,\n",
      "  '0.013*\"\\'save\\',\" + 0.009*\"\\'christma\\',\" + 0.008*\"\\'life\\',\" + '\n",
      "  '0.008*\"\\'mayor\\',\" + 0.008*\"\\'show\\',\" + 0.008*\"\\'church\\',\" + '\n",
      "  '0.007*\"\\'univers\\',\" + 0.007*\"\\'stay\\',\" + 0.007*\"\\'well\\',\" + '\n",
      "  '0.007*\"\\'insist\\',\"'),\n",
      " (3,\n",
      "  '0.009*\"\\'bob\\',\" + 0.008*\"\\'lesson\\',\" + 0.007*\"\\'music\\',\" + '\n",
      "  '0.007*\"\\'last\\',\" + 0.007*\"\\'shock\\',\" + 0.007*\"\\'scene\\',\" + '\n",
      "  '0.007*\"\\'live\\',\" + 0.007*\"\\'voic\\',\" + 0.006*\"\\'appear\\',\" + '\n",
      "  '0.005*\"\\'trap\\',\"'),\n",
      " (21,\n",
      "  '0.010*\"\\'apart\\',\" + 0.010*\"\\'gay\\',\" + 0.009*\"\\'break\\',\" + '\n",
      "  '0.009*\"\\'princip\\',\" + 0.009*\"\\'enjoy\\',\" + 0.008*\"\\'move\\',\" + '\n",
      "  '0.008*\"\\'calm\\',\" + 0.007*\"\\'teach\\',\" + 0.007*\"\\'gradi\\',\" + '\n",
      "  '0.007*\"\\'good\\',\"'),\n",
      " (22,\n",
      "  '0.015*\"\\'love\\',\" + 0.013*\"\\'stori\\',\" + 0.013*\"\\'grampa\\',\" + '\n",
      "  '0.011*\"\\'movi\\',\" + 0.010*\"\\'life\\',\" + 0.009*\"\\'guy\\',\" + '\n",
      "  '0.007*\"\\'parti\\',\" + 0.007*\"\\'comic\\',\" + 0.007*\"\\'compani\\',\" + '\n",
      "  '0.007*\"\\'seri\\',\"'),\n",
      " (10,\n",
      "  '0.014*\"\\'princip\\',\" + 0.010*\"\\'job\\',\" + 0.009*\"\\'save\\',\" + '\n",
      "  '0.009*\"\\'drive\\',\" + 0.008*\"\\'fire\\',\" + 0.008*\"\\'smither\\',\" + '\n",
      "  '0.007*\"\\'invit\\',\" + 0.007*\"\\'littl\\',\" + 0.007*\"\\'helper\\',\" + '\n",
      "  '0.007*\"\\'santa\\',\"'),\n",
      " (9,\n",
      "  '0.009*\"\\'bulli\\',\" + 0.008*\"\\'result\\',\" + 0.008*\"\\'friend\\',\" + '\n",
      "  '0.008*\"\\'stay\\',\" + 0.007*\"\\'elementari\\',\" + 0.007*\"\\'win\\',\" + '\n",
      "  '0.007*\"\\'beat\\',\" + 0.006*\"\\'apart\\',\" + 0.006*\"\\'sign\\',\" + '\n",
      "  '0.006*\"\\'person\\',\"'),\n",
      " (23,\n",
      "  '0.014*\"\\'sara\\',\" + 0.009*\"\\'date\\',\" + 0.008*\"\\'offer\\',\" + '\n",
      "  '0.007*\"\\'someth\\',\" + 0.007*\"\\'new\\',\" + 0.007*\"\\'past\\',\" + '\n",
      "  '0.006*\"\\'quick\\',\" + 0.006*\"\\'camera\\',\" + 0.006*\"\\'comic\\',\" + '\n",
      "  '0.006*\"\\'toni\\',\"'),\n",
      " (5,\n",
      "  '0.014*\"\\'must\\',\" + 0.010*\"\\'lost\\',\" + 0.009*\"\\'love\\',\" + '\n",
      "  '0.008*\"\\'cut\\',\" + 0.008*\"\\'wayn\\',\" + 0.008*\"\\'father\\',\" + '\n",
      "  '0.008*\"\\'princ\\',\" + 0.008*\"\\'protect\\',\" + 0.008*\"\\'chosen\\',\" + '\n",
      "  '0.008*\"\\'relat\\']\"'),\n",
      " (16,\n",
      "  '0.023*\"\\'plant\\',\" + 0.022*\"\\'power\\',\" + 0.020*\"\\'nuclear\\',\" + '\n",
      "  '0.010*\"\\'friend\\',\" + 0.008*\"\\'activ\\',\" + 0.008*\"\\'santa\\',\" + '\n",
      "  '0.007*\"\\'luann\\',\" + 0.007*\"\\'convent\\',\" + 0.006*\"\\'hire\\',\" + '\n",
      "  '0.006*\"\\'bedroom\\',\"'),\n",
      " (25,\n",
      "  '0.008*\"\\'find\\',\" + 0.007*\"\\'bad\\',\" + 0.006*\"\\'move\\',\" + '\n",
      "  '0.006*\"\\'learn\\',\" + 0.006*\"\\'group\\',\" + 0.006*\"\\'congressman\\',\" + '\n",
      "  '0.006*\"\\'get\\',\" + 0.005*\"\\'father\\',\" + 0.005*\"\\'star\\',\" + '\n",
      "  '0.005*\"\\'ralph\\',\"'),\n",
      " (1,\n",
      "  '0.015*\"\\'snake\\',\" + 0.008*\"\\'music\\',\" + 0.008*\"\\'join\\',\" + '\n",
      "  '0.007*\"\\'local\\',\" + 0.006*\"\\'make\\',\" + 0.006*\"\\'girl\\',\" + '\n",
      "  '0.006*\"\\'anyth\\',\" + 0.006*\"\\'post\\',\" + 0.006*\"\\'left\\',\" + '\n",
      "  '0.006*\"\\'love\\',\"'),\n",
      " (14,\n",
      "  '0.011*\"\\'movi\\',\" + 0.010*\"\\'offer\\',\" + 0.009*\"\\'woman\\',\" + '\n",
      "  '0.009*\"\\'open\\',\" + 0.009*\"\\'maud\\',\" + 0.009*\"\\'front\\',\" + '\n",
      "  '0.008*\"\\'phone\\',\" + 0.008*\"\\'leari\\',\" + 0.007*\"\\'present\\',\" + '\n",
      "  '0.007*\"\\'film\\',\"'),\n",
      " (2,\n",
      "  '0.010*\"\\'father\\',\" + 0.009*\"\\'game\\',\" + 0.008*\"\\'convinc\\',\" + '\n",
      "  '0.008*\"\\'willi\\',\" + 0.007*\"\\'bulli\\',\" + 0.007*\"\\'littl\\',\" + '\n",
      "  '0.007*\"\\'voic\\',\" + 0.007*\"\\'carl\\',\" + 0.007*\"\\'local\\',\" + '\n",
      "  '0.007*\"\\'ice\\',\"'),\n",
      " (15,\n",
      "  '0.009*\"\\'photo\\',\" + 0.008*\"\\'buy\\',\" + 0.008*\"\\'union\\',\" + '\n",
      "  '0.007*\"\\'promot\\',\" + 0.007*\"\\'win\\',\" + 0.007*\"\\'keep\\',\" + '\n",
      "  '0.007*\"\\'date\\',\" + 0.007*\"\\'littl\\',\" + 0.007*\"\\'talk\\',\" + '\n",
      "  '0.007*\"\\'mattress\\',\"'),\n",
      " (11,\n",
      "  '0.017*\"\\'selma\\',\" + 0.013*\"\\'boy\\',\" + 0.012*\"\\'marri\\',\" + '\n",
      "  '0.010*\"\\'babi\\',\" + 0.008*\"\\'chief\\',\" + 0.008*\"\\'busi\\',\" + '\n",
      "  '0.008*\"\\'adopt\\',\" + 0.007*\"\\'futur\\',\" + 0.007*\"\\'choos\\',\" + '\n",
      "  '0.005*\"\\'happen\\',\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:1 batches submitted to accumulate stats from 64 documents (7619 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:2 batches submitted to accumulate stats from 128 documents (11807 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:3 batches submitted to accumulate stats from 192 documents (16185 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:4 batches submitted to accumulate stats from 256 documents (18856 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:5 batches submitted to accumulate stats from 320 documents (25203 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:6 batches submitted to accumulate stats from 384 documents (30338 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:7 batches submitted to accumulate stats from 448 documents (35923 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:8 batches submitted to accumulate stats from 512 documents (39477 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:9 batches submitted to accumulate stats from 576 documents (44002 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:10 batches submitted to accumulate stats from 640 documents (44557 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:serializing accumulator to return to master...\n",
      "INFO:gensim.topic_coherence.text_analysis:serializing accumulator to return to master...\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulator serialized\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulator serialized\n",
      "INFO:gensim.topic_coherence.text_analysis:serializing accumulator to return to master...\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulator serialized\n",
      "INFO:gensim.topic_coherence.text_analysis:3 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 49542 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.2977411138673346\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamulticore:running online LDA training, 30 topics, 10 passes over the supplied corpus of 600 documents, updating every 300 documents, evaluating every ~600 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamulticore:training LDA model using 3 processes\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 0, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.001*\"'public',\" + 0.001*\"'woman',\" + 0.001*\"'save',\" + 0.001*\"'nuclear',\" + 0.001*\"'helper',\" + 0.001*\"'father',\" + 0.001*\"'part',\" + 0.001*\"'littl',\" + 0.001*\"'plant',\" + 0.001*\"'clown',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.001*\"'bulli',\" + 0.001*\"'beat',\" + 0.001*\"'win',\" + 0.001*\"'gang',\" + 0.001*\"'contest',\" + 0.001*\"'trip',\" + 0.001*\"'test',\" + 0.001*\"'elementari',\" + 0.001*\"'father',\" + 0.001*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.001*\"'stori',\" + 0.001*\"'race',\" + 0.001*\"'local',\" + 0.001*\"'employe',\" + 0.001*\"'father',\" + 0.001*\"'forc',\" + 0.001*\"'plant',\" + 0.001*\"'choos',\" + 0.001*\"'tell',\" + 0.001*\"'join',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.001*\"'stampi',\" + 0.001*\"'nelson',\" + 0.001*\"'bulli',\" + 0.001*\"'eleph',\" + 0.001*\"'choos',\" + 0.001*\"'bear',\" + 0.001*\"'win',\" + 0.001*\"'prize',\" + 0.001*\"'privat',\" + 0.001*\"'fight',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.002*\"'christma',\" + 0.001*\"'mayor',\" + 0.001*\"'prove',\" + 0.001*\"'set',\" + 0.001*\"'keep',\" + 0.001*\"'scratchi',\" + 0.001*\"'good',\" + 0.001*\"'plant',\" + 0.001*\"'place',\" + 0.001*\"'bob',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.426321, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:-9.526 per-word bound, 737.3 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.001*\"'bear',\" + 0.001*\"'team',\" + 0.001*\"'flame',\" + 0.001*\"'nelson',\" + 0.001*\"'group',\" + 0.001*\"'thing',\" + 0.001*\"'secret',\" + 0.001*\"'cletus',\" + 0.001*\"'bulli',\" + 0.001*\"'test',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.001*\"'boy',\" + 0.001*\"'bear',\" + 0.001*\"'bar',\" + 0.001*\"'math',\" + 0.001*\"'stori',\" + 0.001*\"'littl',\" + 0.001*\"'mitzvah',\" + 0.001*\"'helper',\" + 0.001*\"'elementari',\" + 0.001*\"'show',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.001*\"'quick',\" + 0.001*\"'offer',\" + 0.001*\"'second',\" + 0.001*\"'choos',\" + 0.001*\"'camera',\" + 0.001*\"'new',\" + 0.001*\"'toni',\" + 0.001*\"'someth',\" + 0.001*\"'lose',\" + 0.001*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.001*\"'love',\" + 0.001*\"'grampa',\" + 0.001*\"'movi',\" + 0.001*\"'stori',\" + 0.001*\"'life',\" + 0.001*\"'parti',\" + 0.001*\"'flashback',\" + 0.001*\"'seri',\" + 0.001*\"'compani',\" + 0.001*\"'guy',\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.001*\"'busi',\" + 0.001*\"'drive',\" + 0.001*\"'decid',\" + 0.001*\"'women',\" + 0.001*\"'bar',\" + 0.001*\"'hair',\" + 0.001*\"'charg',\" + 0.001*\"'tavern',\" + 0.001*\"'soon',\" + 0.001*\"'men',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.056942, rho=0.500000\n",
      "INFO:gensim.models.ldamodel:-8.675 per-word bound, 408.7 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 1, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.001*\"'bear',\" + 0.001*\"'nelson',\" + 0.001*\"'win',\" + 0.001*\"'choos',\" + 0.001*\"'stampi',\" + 0.001*\"'bulli',\" + 0.001*\"'eleph',\" + 0.001*\"'form',\" + 0.001*\"'actual',\" + 0.001*\"'teacher',\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.001*\"'team',\" + 0.001*\"'flame',\" + 0.001*\"'bear',\" + 0.001*\"'follow',\" + 0.001*\"'jebediah',\" + 0.001*\"'day',\" + 0.001*\"'steal',\" + 0.001*\"'nelson',\" + 0.001*\"'secret',\" + 0.001*\"'entir',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.001*\"'bulli',\" + 0.001*\"'beat',\" + 0.001*\"'win',\" + 0.001*\"'elementari',\" + 0.001*\"'gang',\" + 0.001*\"'contest',\" + 0.001*\"'trip',\" + 0.001*\"'test',\" + 0.001*\"'father',\" + 0.001*\"'boy',\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.001*\"'union',\" + 0.001*\"'buy',\" + 0.001*\"'last',\" + 0.001*\"'futur',\" + 0.001*\"'enlist',\" + 0.001*\"'best',\" + 0.001*\"'collect',\" + 0.001*\"'leader',\" + 0.001*\"['accident',\" + 0.001*\"'plant',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.001*\"'apu',\" + 0.001*\"'fail',\" + 0.001*\"'hand',\" + 0.001*\"'year',\" + 0.001*\"'celebr',\" + 0.001*\"'anoth',\" + 0.001*\"'illeg',\" + 0.001*\"'grade',\" + 0.001*\"'fake',\" + 0.001*\"'smither',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017732, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-8.891 per-word bound, 474.7 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.001*\"'open',\" + 0.001*\"'offer',\" + 0.001*\"'movi',\" + 0.001*\"'phone',\" + 0.001*\"'leari',\" + 0.001*\"'maud',\" + 0.001*\"'front',\" + 0.001*\"'move',\" + 0.001*\"'good',\" + 0.001*\"'friend',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.001*\"'selma',\" + 0.001*\"'babi',\" + 0.001*\"'busi',\" + 0.001*\"'chief',\" + 0.001*\"'futur',\" + 0.001*\"'choos',\" + 0.001*\"'adopt',\" + 0.001*\"'basement',\" + 0.001*\"'bender',\" + 0.001*\"'annual',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.001*\"'chloe',\" + 0.001*\"'fli',\" + 0.001*\"'chalmer',\" + 0.001*\"'littl',\" + 0.001*\"'parti',\" + 0.001*\"'invit',\" + 0.001*\"'edna',\" + 0.001*\"'boy',\" + 0.001*\"'forc',\" + 0.001*\"'santa',\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.001*\"'bad',\" + 0.001*\"'club',\" + 0.001*\"'apu',\" + 0.001*\"'littl',\" + 0.001*\"'replac',\" + 0.001*\"'bar',\" + 0.001*\"'live',\" + 0.001*\"'convinc',\" + 0.001*\"'sideshow',\" + 0.001*\"'job',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.002*\"'bear',\" + 0.002*\"'bar',\" + 0.002*\"'boy',\" + 0.002*\"'mitzvah',\" + 0.001*\"'show',\" + 0.001*\"'littl',\" + 0.001*\"'stori',\" + 0.001*\"'eventu',\" + 0.001*\"'actual',\" + 0.001*\"'dog',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.026904, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-8.524 per-word bound, 368.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 2, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.001*\"'stori',\" + 0.001*\"'employe',\" + 0.001*\"'local',\" + 0.001*\"'race',\" + 0.001*\"'plant',\" + 0.001*\"'star',\" + 0.001*\"'rag',\" + 0.001*\"'fellow',\" + 0.001*\"'forc',\" + 0.001*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.001*\"'segment',\" + 0.001*\"'local',\" + 0.001*\"'art',\" + 0.001*\"'father',\" + 0.001*\"'friend',\" + 0.001*\"'attack',\" + 0.001*\"'willi',\" + 0.001*\"'teacher',\" + 0.001*\"'film',\" + 0.001*\"'game',\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.002*\"'power',\" + 0.002*\"'nuclear',\" + 0.001*\"'plant',\" + 0.001*\"'friend',\" + 0.001*\"'grampa',\" + 0.001*\"'attract',\" + 0.001*\"'activ',\" + 0.001*\"'luann',\" + 0.001*\"'smither',\" + 0.001*\"'buy',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.001*\"'appear',\" + 0.001*\"'voic',\" + 0.001*\"'music',\" + 0.001*\"'last',\" + 0.001*\"'guest',\" + 0.001*\"'open',\" + 0.001*\"'scene',\" + 0.001*\"'featur',\" + 0.001*\"'hell',\" + 0.001*\"'terror',\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.001*\"'find',\" + 0.001*\"'father',\" + 0.001*\"'bad',\" + 0.001*\"'learn',\" + 0.001*\"'move',\" + 0.001*\"'ralph',\" + 0.001*\"'citizen',\" + 0.001*\"'church',\" + 0.001*\"'award',\" + 0.001*\"'star',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017947, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-8.737 per-word bound, 426.6 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.004*\"'pie',\" + 0.002*\"'man',\" + 0.001*\"'team',\" + 0.001*\"'children',\" + 0.001*\"'promis',\" + 0.001*\"'better',\" + 0.001*\"'ride',\" + 0.001*\"'competit',\" + 0.001*\"'face',\" + 0.001*\"'littl',\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.001*\"'buy',\" + 0.001*\"'union',\" + 0.001*\"'littl',\" + 0.001*\"'talk',\" + 0.001*\"'bed',\" + 0.001*\"'mattress',\" + 0.001*\"'promot',\" + 0.001*\"'photo',\" + 0.001*\"['accident',\" + 0.001*\"'plant',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.001*\"'star',\" + 0.001*\"'rag',\" + 0.001*\"'stori',\" + 0.001*\"'employe',\" + 0.001*\"'famili',\" + 0.001*\"'parodi',\" + 0.001*\"'friend',\" + 0.001*\"'fellow',\" + 0.001*\"'plant',\" + 0.001*\"'miss',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.001*\"'grampa',\" + 0.001*\"'write',\" + 0.001*\"'convinc',\" + 0.001*\"'stori',\" + 0.001*\"'life',\" + 0.001*\"'high',\" + 0.001*\"'take',\" + 0.001*\"'arti',\" + 0.001*\"'bashir',\" + 0.001*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.010): 0.002*\"'power',\" + 0.002*\"'nuclear',\" + 0.001*\"'friend',\" + 0.001*\"'plant',\" + 0.001*\"'activ',\" + 0.001*\"'santa',\" + 0.001*\"'grampa',\" + 0.001*\"'interest',\" + 0.001*\"'train',\" + 0.001*\"'christma',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.021517, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-8.491 per-word bound, 359.9 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 3, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.001*\"'bulli',\" + 0.001*\"'beat',\" + 0.001*\"'win',\" + 0.001*\"'elementari',\" + 0.001*\"'friend',\" + 0.001*\"'result',\" + 0.001*\"'stay',\" + 0.001*\"'gang',\" + 0.001*\"'contest',\" + 0.001*\"'trip',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.003*\"'bear',\" + 0.002*\"'bar',\" + 0.001*\"'mitzvah',\" + 0.001*\"'boy',\" + 0.001*\"'littl',\" + 0.001*\"'show',\" + 0.001*\"'helper',\" + 0.001*\"'stori',\" + 0.001*\"'eventu',\" + 0.001*\"'dog',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.001*\"'sara',\" + 0.001*\"'quick',\" + 0.001*\"'offer',\" + 0.001*\"'someth',\" + 0.001*\"'lose',\" + 0.001*\"'date',\" + 0.001*\"'choos',\" + 0.001*\"'new',\" + 0.001*\"'enter',\" + 0.001*\"'life',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.001*\"'segment',\" + 0.001*\"'art',\" + 0.001*\"'local',\" + 0.001*\"'father',\" + 0.001*\"'willi',\" + 0.001*\"'attack',\" + 0.001*\"'friend',\" + 0.001*\"'teacher',\" + 0.001*\"'game',\" + 0.001*\"'film',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.003*\"'pie',\" + 0.001*\"'team',\" + 0.001*\"'man',\" + 0.001*\"'better',\" + 0.001*\"'children',\" + 0.001*\"'littl',\" + 0.001*\"'promis',\" + 0.001*\"'new',\" + 0.001*\"'bowl',\" + 0.001*\"'dream',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.017016, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.002*\"'key',\" + 0.001*\"'assist',\" + 0.001*\"'trip',\" + 0.001*\"'keep',\" + 0.001*\"'popular',\" + 0.001*\"'boston',\" + 0.001*\"'find',\" + 0.001*\"'lead',\" + 0.001*\"'car',\" + 0.001*\"'duff',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.002*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'date',\" + 0.001*\"'quick',\" + 0.001*\"'someth',\" + 0.001*\"'second',\" + 0.001*\"'camera',\" + 0.001*\"'toni',\" + 0.001*\"'school',\" + 0.001*\"'comic',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.001*\"'christma',\" + 0.001*\"'friend',\" + 0.001*\"'good',\" + 0.001*\"'prompt',\" + 0.001*\"'set',\" + 0.001*\"'keep',\" + 0.001*\"'mayor',\" + 0.001*\"'prove',\" + 0.001*\"'creat',\" + 0.001*\"'video',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.010): 0.001*\"'lesson',\" + 0.001*\"'music',\" + 0.001*\"'last',\" + 0.001*\"'scene',\" + 0.001*\"'voic',\" + 0.001*\"'bob',\" + 0.001*\"'appear',\" + 0.001*\"'littl',\" + 0.001*\"'trial',\" + 0.001*\"'trap',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.001*\"'star',\" + 0.001*\"'rag',\" + 0.001*\"'employe',\" + 0.001*\"'stori',\" + 0.001*\"'famili',\" + 0.001*\"'parodi',\" + 0.001*\"'friend',\" + 0.001*\"'fellow',\" + 0.001*\"'plant',\" + 0.001*\"'local',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.018303, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-8.482 per-word bound, 357.5 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 4, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.001*\"'apu',\" + 0.001*\"'club',\" + 0.001*\"'bad',\" + 0.001*\"'job',\" + 0.001*\"'set',\" + 0.001*\"'mart',\" + 0.001*\"'kwik',\" + 0.001*\"'live',\" + 0.001*\"'convinc',\" + 0.001*\"'sideshow',\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.001*\"'maud',\" + 0.001*\"'open',\" + 0.001*\"'movi',\" + 0.001*\"'good',\" + 0.001*\"'offer',\" + 0.001*\"'accident',\" + 0.001*\"'front',\" + 0.001*\"'steal',\" + 0.001*\"'move',\" + 0.001*\"'mel',\"\n",
      "INFO:gensim.models.ldamodel:topic #22 (0.010): 0.002*\"'love',\" + 0.001*\"'grampa',\" + 0.001*\"'movi',\" + 0.001*\"'parti',\" + 0.001*\"'stori',\" + 0.001*\"'life',\" + 0.001*\"'fish',\" + 0.001*\"'plant',\" + 0.001*\"'comic',\" + 0.001*\"'princip',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.001*\"'mayor',\" + 0.001*\"'show',\" + 0.001*\"'save',\" + 0.001*\"'life',\" + 0.001*\"'church',\" + 0.001*\"'predict',\" + 0.001*\"'win',\" + 0.001*\"'bet',\" + 0.001*\"'behind',\" + 0.001*\"'quimbi',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.001*\"'line',\" + 0.001*\"'problem',\" + 0.001*\"'face',\" + 0.001*\"'littl',\" + 0.001*\"'learn',\" + 0.001*\"'seem',\" + 0.001*\"'perfect',\" + 0.001*\"'togeth',\" + 0.001*\"'real',\" + 0.001*\"'futur',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.015968, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-8.652 per-word bound, 402.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.001*\"'chloe',\" + 0.001*\"'fli',\" + 0.001*\"'chalmer',\" + 0.001*\"'parti',\" + 0.001*\"'invit',\" + 0.001*\"'edna',\" + 0.001*\"'boy',\" + 0.001*\"'littl',\" + 0.001*\"'forc',\" + 0.001*\"'snake',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.004*\"'bear',\" + 0.002*\"'bar',\" + 0.002*\"'mitzvah',\" + 0.002*\"'boy',\" + 0.002*\"'show',\" + 0.001*\"'littl',\" + 0.001*\"'eventu',\" + 0.001*\"'actual',\" + 0.001*\"'friend',\" + 0.001*\"'dog',\"\n",
      "INFO:gensim.models.ldamodel:topic #21 (0.010): 0.001*\"'princip',\" + 0.001*\"'enjoy',\" + 0.001*\"'teach',\" + 0.001*\"'calm',\" + 0.001*\"'itchi',\" + 0.001*\"'harper',\" + 0.001*\"'well',\" + 0.001*\"'woman',\" + 0.001*\"'partner',\" + 0.001*\"'rich',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.001*\"'selma',\" + 0.001*\"'babi',\" + 0.001*\"'busi',\" + 0.001*\"'chief',\" + 0.001*\"'adopt',\" + 0.001*\"'futur',\" + 0.001*\"'choos',\" + 0.001*\"'basement',\" + 0.001*\"'bender',\" + 0.001*\"'annual',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.002*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'date',\" + 0.001*\"'someth',\" + 0.001*\"'quick',\" + 0.001*\"'second',\" + 0.001*\"'camera',\" + 0.001*\"'school',\" + 0.001*\"'toni',\" + 0.001*\"'comic',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016424, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-8.479 per-word bound, 356.8 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 5, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.001*\"'cut',\" + 0.001*\"'love',\" + 0.001*\"'nightmar',\" + 0.001*\"'stori',\" + 0.001*\"'power',\" + 0.001*\"'order',\" + 0.001*\"'wayn',\" + 0.001*\"'treehous',\" + 0.001*\"'dream',\" + 0.001*\"'laura',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.001*\"'spi',\" + 0.001*\"'glass',\" + 0.001*\"'form',\" + 0.001*\"'gift',\" + 0.001*\"'secret',\" + 0.001*\"'choos',\" + 0.001*\"'stampi',\" + 0.001*\"'eleph',\" + 0.001*\"'win',\" + 0.001*\"'actual',\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.010): 0.001*\"'union',\" + 0.001*\"'buy',\" + 0.001*\"'enlist',\" + 0.001*\"'best',\" + 0.001*\"'last',\" + 0.001*\"'collect',\" + 0.001*\"'leader',\" + 0.001*\"['accident',\" + 0.001*\"'plant',\" + 0.001*\"'grandpa',\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.001*\"'apu',\" + 0.001*\"'club',\" + 0.001*\"'bad',\" + 0.001*\"'job',\" + 0.001*\"'set',\" + 0.001*\"'mart',\" + 0.001*\"'kwik',\" + 0.001*\"'live',\" + 0.001*\"'convinc',\" + 0.001*\"'sideshow',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.002*\"'snake',\" + 0.001*\"'join',\" + 0.001*\"'music',\" + 0.001*\"'local',\" + 0.001*\"'girl',\" + 0.001*\"'keep',\" + 0.001*\"'love',\" + 0.001*\"'buy',\" + 0.001*\"'polic',\" + 0.001*\"'post',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.015073, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-8.640 per-word bound, 398.9 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.004*\"'bear',\" + 0.002*\"'bar',\" + 0.002*\"'mitzvah',\" + 0.002*\"'boy',\" + 0.002*\"'littl',\" + 0.002*\"'show',\" + 0.001*\"'eventu',\" + 0.001*\"'actual',\" + 0.001*\"'helper',\" + 0.001*\"'friend',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.002*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'date',\" + 0.001*\"'someth',\" + 0.001*\"'quick',\" + 0.001*\"'second',\" + 0.001*\"'camera',\" + 0.001*\"'school',\" + 0.001*\"'toni',\" + 0.001*\"'comic',\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.010): 0.001*\"'christma',\" + 0.001*\"'friend',\" + 0.001*\"'prompt',\" + 0.001*\"'good',\" + 0.001*\"'keep',\" + 0.001*\"'mayor',\" + 0.001*\"'prove',\" + 0.001*\"'set',\" + 0.001*\"'creat',\" + 0.001*\"'video',\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.010): 0.004*\"'pie',\" + 0.002*\"'man',\" + 0.002*\"'team',\" + 0.001*\"'children',\" + 0.001*\"'promis',\" + 0.001*\"'better',\" + 0.001*\"'ride',\" + 0.001*\"'competit',\" + 0.001*\"'face',\" + 0.001*\"'littl',\"\n",
      "INFO:gensim.models.ldamodel:topic #18 (0.010): 0.002*\"'drive',\" + 0.001*\"'busi',\" + 0.001*\"'women',\" + 0.001*\"'bar',\" + 0.001*\"'soon',\" + 0.001*\"'hair',\" + 0.001*\"'tavern',\" + 0.001*\"'men',\" + 0.001*\"'charg',\" + 0.001*\"'costum',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.015240, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-8.477 per-word bound, 356.3 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 6, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.001*\"'key',\" + 0.001*\"'assist',\" + 0.001*\"'popular',\" + 0.001*\"'trip',\" + 0.001*\"'keep',\" + 0.001*\"'live',\" + 0.001*\"'convent',\" + 0.001*\"'candi',\" + 0.001*\"'perform',\" + 0.001*\"'famili',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.001*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'quick',\" + 0.001*\"'someth',\" + 0.001*\"'date',\" + 0.001*\"'lose',\" + 0.001*\"'sideshow',\" + 0.001*\"'choos',\" + 0.001*\"'new',\" + 0.001*\"'enter',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.001*\"'mayor',\" + 0.001*\"'show',\" + 0.001*\"'save',\" + 0.001*\"'life',\" + 0.001*\"'church',\" + 0.001*\"'predict',\" + 0.001*\"'win',\" + 0.001*\"'bet',\" + 0.001*\"'behind',\" + 0.001*\"'washington',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.001*\"'line',\" + 0.001*\"'problem',\" + 0.001*\"'face',\" + 0.001*\"'littl',\" + 0.001*\"'learn',\" + 0.001*\"'seem',\" + 0.001*\"'perfect',\" + 0.001*\"'togeth',\" + 0.001*\"'futur',\" + 0.001*\"'real',\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.002*\"'nelson',\" + 0.002*\"'bulli',\" + 0.001*\"'group',\" + 0.001*\"'stay',\" + 0.001*\"'grampa',\" + 0.001*\"'defend',\" + 0.001*\"'team',\" + 0.001*\"'flame',\" + 0.001*\"'leader',\" + 0.001*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014367, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-8.629 per-word bound, 396.0 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.002*\"'snake',\" + 0.001*\"'keep',\" + 0.001*\"'join',\" + 0.001*\"'girl',\" + 0.001*\"'local',\" + 0.001*\"'music',\" + 0.001*\"'post',\" + 0.001*\"'live',\" + 0.001*\"'anyth',\" + 0.001*\"'love',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #2 (0.010): 0.001*\"'game',\" + 0.001*\"'father',\" + 0.001*\"'willi',\" + 0.001*\"'littl',\" + 0.001*\"'bulli',\" + 0.001*\"'ice',\" + 0.001*\"'voic',\" + 0.001*\"'segment',\" + 0.001*\"'convinc',\" + 0.001*\"'win',\"\n",
      "INFO:gensim.models.ldamodel:topic #28 (0.010): 0.004*\"'bear',\" + 0.002*\"'bar',\" + 0.002*\"'boy',\" + 0.002*\"'mitzvah',\" + 0.002*\"'littl',\" + 0.002*\"'show',\" + 0.002*\"'helper',\" + 0.001*\"'eventu',\" + 0.001*\"'santa',\" + 0.001*\"'actual',\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.002*\"'open',\" + 0.001*\"'good',\" + 0.001*\"'move',\" + 0.001*\"'offer',\" + 0.001*\"'accident',\" + 0.001*\"'miss',\" + 0.001*\"'phone',\" + 0.001*\"'leari',\" + 0.001*\"'got',\" + 0.001*\"'movi',\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.010): 0.002*\"'key',\" + 0.001*\"'assist',\" + 0.001*\"'trip',\" + 0.001*\"'keep',\" + 0.001*\"'popular',\" + 0.001*\"'find',\" + 0.001*\"'lead',\" + 0.001*\"'car',\" + 0.001*\"'duff',\" + 0.001*\"'boston',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014335, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-8.477 per-word bound, 356.4 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 7, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.001*\"'write',\" + 0.001*\"'convinc',\" + 0.001*\"'stori',\" + 0.001*\"'grampa',\" + 0.001*\"'life',\" + 0.001*\"'high',\" + 0.001*\"'show',\" + 0.001*\"'give',\" + 0.001*\"'good',\" + 0.001*\"'son',\"\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.001*\"'chloe',\" + 0.001*\"'chalmer',\" + 0.001*\"'snake',\" + 0.001*\"'fli',\" + 0.001*\"'forc',\" + 0.001*\"'boy',\" + 0.001*\"'parti',\" + 0.001*\"'edna',\" + 0.001*\"'invit',\" + 0.001*\"'day',\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.002*\"'shirt',\" + 0.001*\"'nuclear',\" + 0.001*\"'decid',\" + 0.001*\"'busi',\" + 0.001*\"'food',\" + 0.001*\"'get',\" + 0.001*\"'lose',\" + 0.001*\"'goos',\" + 0.001*\"'plant',\" + 0.001*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.001*\"'stori',\" + 0.001*\"'employe',\" + 0.001*\"'local',\" + 0.001*\"'race',\" + 0.001*\"'star',\" + 0.001*\"'rag',\" + 0.001*\"'plant',\" + 0.001*\"'fellow',\" + 0.001*\"'famili',\" + 0.001*\"'parodi',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.001*\"'line',\" + 0.001*\"'problem',\" + 0.001*\"'face',\" + 0.001*\"'littl',\" + 0.001*\"'learn',\" + 0.001*\"'seem',\" + 0.001*\"'perfect',\" + 0.001*\"'togeth',\" + 0.001*\"'futur',\" + 0.001*\"'real',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013691, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-8.620 per-word bound, 393.5 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.001*\"'love',\" + 0.001*\"'cut',\" + 0.001*\"'wayn',\" + 0.001*\"'stori',\" + 0.001*\"'power',\" + 0.001*\"'nightmar',\" + 0.001*\"'food',\" + 0.001*\"'junk',\" + 0.001*\"'voic',\" + 0.001*\"'guest',\"\n",
      "INFO:gensim.models.ldamodel:topic #29 (0.010): 0.001*\"'grampa',\" + 0.001*\"'write',\" + 0.001*\"'convinc',\" + 0.001*\"'stori',\" + 0.001*\"'life',\" + 0.001*\"'high',\" + 0.001*\"'take',\" + 0.001*\"'arti',\" + 0.001*\"'bashir',\" + 0.001*\"'father',\"\n",
      "INFO:gensim.models.ldamodel:topic #26 (0.010): 0.001*\"'fail',\" + 0.001*\"'hand',\" + 0.001*\"'diari',\" + 0.001*\"'apu',\" + 0.001*\"'year',\" + 0.001*\"'celebr',\" + 0.001*\"'illeg',\" + 0.001*\"'tax',\" + 0.001*\"'smither',\" + 0.001*\"'scene',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.001*\"'spi',\" + 0.001*\"'glass',\" + 0.001*\"'secret',\" + 0.001*\"'form',\" + 0.001*\"'gift',\" + 0.001*\"'nelson',\" + 0.001*\"'presid',\" + 0.001*\"'due',\" + 0.001*\"'earli',\" + 0.001*\"'band',\"\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.001*\"'club',\" + 0.001*\"'bad',\" + 0.001*\"'apu',\" + 0.001*\"'replac',\" + 0.001*\"'bar',\" + 0.001*\"'live',\" + 0.001*\"'convinc',\" + 0.001*\"'sideshow',\" + 0.001*\"'job',\" + 0.001*\"'set',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013638, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-8.477 per-word bound, 356.4 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 8, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #20 (0.010): 0.001*\"'apu',\" + 0.001*\"'club',\" + 0.001*\"'bad',\" + 0.001*\"'job',\" + 0.001*\"'set',\" + 0.001*\"'kwik',\" + 0.001*\"'mart',\" + 0.001*\"'live',\" + 0.001*\"'convinc',\" + 0.001*\"'sideshow',\"\n",
      "INFO:gensim.models.ldamodel:topic #25 (0.010): 0.002*\"'learn',\" + 0.002*\"'father',\" + 0.002*\"'ralph',\" + 0.001*\"'find',\" + 0.001*\"'move',\" + 0.001*\"'bad',\" + 0.001*\"'get',\" + 0.001*\"'miss',\" + 0.001*\"'life',\" + 0.001*\"'spend',\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.010): 0.001*\"'line',\" + 0.001*\"'problem',\" + 0.001*\"'face',\" + 0.001*\"'littl',\" + 0.001*\"'learn',\" + 0.001*\"'seem',\" + 0.001*\"'perfect',\" + 0.001*\"'togeth',\" + 0.001*\"'futur',\" + 0.001*\"'real',\"\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.002*\"'shirt',\" + 0.001*\"'nuclear',\" + 0.001*\"'decid',\" + 0.001*\"'busi',\" + 0.001*\"'get',\" + 0.001*\"'food',\" + 0.001*\"'plant',\" + 0.001*\"'goos',\" + 0.001*\"'lose',\" + 0.001*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.010): 0.002*\"'snake',\" + 0.001*\"'join',\" + 0.001*\"'keep',\" + 0.001*\"'music',\" + 0.001*\"'local',\" + 0.001*\"'girl',\" + 0.001*\"'love',\" + 0.001*\"'buy',\" + 0.001*\"'polic',\" + 0.001*\"'post',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.013124, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-8.619 per-word bound, 393.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.002*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'date',\" + 0.001*\"'someth',\" + 0.001*\"'quick',\" + 0.001*\"'second',\" + 0.001*\"'school',\" + 0.001*\"'camera',\" + 0.001*\"'comic',\" + 0.001*\"'toni',\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.010): 0.001*\"'love',\" + 0.001*\"'cut',\" + 0.001*\"'wayn',\" + 0.001*\"'stori',\" + 0.001*\"'power',\" + 0.001*\"'nightmar',\" + 0.001*\"'food',\" + 0.001*\"'junk',\" + 0.001*\"'voic',\" + 0.001*\"'guest',\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.010): 0.001*\"'star',\" + 0.001*\"'rag',\" + 0.001*\"'employe',\" + 0.001*\"'stori',\" + 0.001*\"'famili',\" + 0.001*\"'friend',\" + 0.001*\"'parodi',\" + 0.001*\"'fellow',\" + 0.001*\"'plant',\" + 0.001*\"'local',\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.010): 0.002*\"'open',\" + 0.001*\"'good',\" + 0.001*\"'move',\" + 0.001*\"'offer',\" + 0.001*\"'miss',\" + 0.001*\"'accident',\" + 0.001*\"'phone',\" + 0.001*\"'leari',\" + 0.001*\"'got',\" + 0.001*\"'apart',\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.010): 0.001*\"'selma',\" + 0.001*\"'babi',\" + 0.001*\"'busi',\" + 0.001*\"'chief',\" + 0.001*\"'adopt',\" + 0.001*\"'futur',\" + 0.001*\"'choos',\" + 0.001*\"'basement',\" + 0.001*\"'bender',\" + 0.001*\"'might',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic diff=0.013119, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-8.475 per-word bound, 355.7 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #0 = documents up to #100/600, outstanding queue size 1\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #1 = documents up to #200/600, outstanding queue size 2\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #2 = documents up to #300/600, outstanding queue size 3\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #3 = documents up to #400/600, outstanding queue size 4\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #4 = documents up to #500/600, outstanding queue size 5\n",
      "INFO:gensim.models.ldamulticore:PROGRESS: pass 9, dispatched chunk #5 = documents up to #600/600, outstanding queue size 6\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #27 (0.010): 0.001*\"'chloe',\" + 0.001*\"'chalmer',\" + 0.001*\"'fli',\" + 0.001*\"'snake',\" + 0.001*\"'forc',\" + 0.001*\"'boy',\" + 0.001*\"'parti',\" + 0.001*\"'edna',\" + 0.001*\"'invit',\" + 0.001*\"'day',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.001*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'quick',\" + 0.001*\"'someth',\" + 0.001*\"'date',\" + 0.001*\"'lose',\" + 0.001*\"'sideshow',\" + 0.001*\"'choos',\" + 0.001*\"'new',\" + 0.001*\"'enter',\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.010): 0.001*\"'princip',\" + 0.001*\"'job',\" + 0.001*\"'smither',\" + 0.001*\"'fire',\" + 0.001*\"'drive',\" + 0.001*\"'save',\" + 0.001*\"'casino',\" + 0.001*\"'open',\" + 0.001*\"'clown',\" + 0.001*\"'adopt',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.001*\"'stay',\" + 0.001*\"'bulli',\" + 0.001*\"'win',\" + 0.001*\"'elementari',\" + 0.001*\"'friend',\" + 0.001*\"'result',\" + 0.001*\"'gang',\" + 0.001*\"'contest',\" + 0.001*\"'neighbor',\" + 0.001*\"'window',\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.010): 0.002*\"'nelson',\" + 0.002*\"'bulli',\" + 0.001*\"'group',\" + 0.001*\"'stay',\" + 0.001*\"'grampa',\" + 0.001*\"'defend',\" + 0.001*\"'leader',\" + 0.001*\"'team',\" + 0.001*\"'flame',\" + 0.001*\"'jebediah',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012621, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-8.612 per-word bound, 391.2 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n",
      "INFO:gensim.models.ldamodel:merging changes from 300 documents into a model of 600 documents\n",
      "INFO:gensim.models.ldamodel:topic #24 (0.010): 0.002*\"'shirt',\" + 0.002*\"'nuclear',\" + 0.002*\"'decid',\" + 0.001*\"'goos',\" + 0.001*\"'get',\" + 0.001*\"'plant',\" + 0.001*\"'busi',\" + 0.001*\"'store',\" + 0.001*\"'sell',\" + 0.001*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.010): 0.001*\"'spi',\" + 0.001*\"'glass',\" + 0.001*\"'secret',\" + 0.001*\"'form',\" + 0.001*\"'gift',\" + 0.001*\"'nelson',\" + 0.001*\"'presid',\" + 0.001*\"'due',\" + 0.001*\"'earli',\" + 0.001*\"'band',\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.010): 0.001*\"'stay',\" + 0.001*\"'friend',\" + 0.001*\"'result',\" + 0.001*\"'bulli',\" + 0.001*\"'win',\" + 0.001*\"'elementari',\" + 0.001*\"'live',\" + 0.001*\"'apart',\" + 0.001*\"'citi',\" + 0.001*\"'area',\"\n",
      "INFO:gensim.models.ldamodel:topic #23 (0.010): 0.002*\"'sara',\" + 0.001*\"'offer',\" + 0.001*\"'date',\" + 0.001*\"'someth',\" + 0.001*\"'quick',\" + 0.001*\"'second',\" + 0.001*\"'school',\" + 0.001*\"'camera',\" + 0.001*\"'comic',\" + 0.001*\"'toni',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.010): 0.001*\"'save',\" + 0.001*\"'mayor',\" + 0.001*\"'show',\" + 0.001*\"'univers',\" + 0.001*\"'well',\" + 0.001*\"'problem',\" + 0.001*\"'insist',\" + 0.001*\"'write',\" + 0.001*\"'love',\" + 0.001*\"'result',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.012569, rho=0.250000\n",
      "INFO:gensim.models.ldamodel:-8.476 per-word bound, 356.0 perplexity estimate based on a held-out corpus of 100 documents with 1559 words\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=K, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el174848130080809997403955\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el174848130080809997403955_data = {\"mdsDat\": {\"x\": [-0.024082918878344423, 0.002153462755435528, 0.00039032779635094395, -0.0002479964688081386, -8.459832889504227e-05, 0.00285392835038405, 0.0009915274704381336, -0.0004615780310542796, 0.0007728423069944928, -0.0005834960633211368, 0.0006323716414455503, 0.0008143347021647794, 0.00040294449473569536, 0.00039117483282064767, 0.001969523562493255, 0.0008855574366694168, 0.0002544490619920721, 0.0009611442204118532, 0.0014940808889592392, 0.0009037383277675773, 0.00023200873826272243, 0.0009868601780085094, 0.000972694351601467, 0.0008425068872545898, 0.0007800040156047894, 0.001500107953186915, 0.0011877408998316916, 0.0015546274223485882, 0.0006028375126369737, 0.0009297919626234943], \"y\": [-0.001052400704492194, -0.02139799572221462, 0.0007112005765887638, 0.002527397629746581, -0.0011082990108392521, 0.0018160391710554398, 0.0012208058133890809, -0.0001660968565488744, 0.001313327853188333, 0.0010676273815883766, -0.0005354750793700557, 0.00011907537127902386, 0.0016436291190293974, 0.0003744483781822141, 0.0014443001846875486, 0.0011715049740797913, 0.0011499813151693032, 0.00013734608287234898, 0.00024768901305845763, 0.0004511420154022702, 0.0006860607859888612, 0.0006045698290784253, 0.0011522704067204418, 0.0009419781083436572, 0.0013220582320517746, 0.0007889011135659043, 0.0006588113994553848, 0.0008613434121690928, 0.0007604147864679941, 0.0010883444203065328], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [11.695548057556152, 9.103671073913574, 6.022123336791992, 5.404257297515869, 4.969504356384277, 4.898008823394775, 4.446547508239746, 4.144837379455566, 3.9605815410614014, 3.497758150100708, 3.2788004875183105, 2.7544138431549072, 2.644151449203491, 2.588223457336426, 2.460794687271118, 2.3847601413726807, 2.367748737335205, 2.211183786392212, 2.1225476264953613, 2.1117255687713623, 2.074617624282837, 1.9968065023422241, 1.826397180557251, 1.7825487852096558, 1.6926212310791016, 1.6260101795196533, 1.600893259048462, 1.5901542901992798, 1.4257184267044067, 1.3170443773269653]}, \"tinfo\": {\"Term\": [\"'pie',\", \"'bear',\", \"'littl',\", \"'nelson',\", \"'bulli',\", \"'nuclear',\", \"'bar',\", \"'love',\", \"'snake',\", \"'shirt',\", \"'princip',\", \"'power',\", \"'helper',\", \"'santa',\", \"'stay',\", \"'key',\", \"'stori',\", \"'grampa',\", \"'busi',\", \"'save',\", \"'christma',\", \"'drive',\", \"'plant',\", \"'invit',\", \"'secret',\", \"'team',\", \"'man',\", \"'open',\", \"'boy',\", \"'friend',\", \"'ralph',\", \"'congressman',\", \"'bill',\", \"'learn',\", \"'traffic',\", \"'chang',\", \"'bad',\", \"'visit',\", \"'princ',\", \"'intend',\", \"'find',\", \"'citizen',\", \"'believ',\", \"'everi',\", \"'valentin',\", \"'realli',\", \"'protect',\", \"'lost',\", \"'mother',\", \"'church',\", \"'congress',\", \"'relat']\", \"'kemi',\", \"'group',\", \"'counselor',\", \"'lovejoy',\", \"'togeth',\", \"'advic',\", \"'lurleen',\", \"'father',\", \"'spend',\", \"'move',\", \"'krabappel',\", \"'miss',\", \"'citi',\", \"'get',\", \"'must',\", \"'win',\", \"'trip',\", \"'star',\", \"'well',\", \"'life',\", \"'order',\", \"'futur',\", \"'bear',\", \"'mitzvah',\", \"'helper',\", \"'santa',\", \"'bar',\", \"'littl',\", \"'eventu',\", \"'dog',\", \"'jewish',\", \"'boy',\", \"'math',\", \"'show',\", \"'puppi',\", \"'replac',\", \"'grant',\", \"'isabel',\", \"'tow',\", \"'armor',\", \"'make',\", \"'actual',\", \"'consid',\", \"'reveng',\", \"'hire',\", \"'discov',\", \"'jail',\", \"'stay',\", \"'attack',\", \"'walk',\", \"'confront',\", \"'concern',\", \"['date',\", \"'teach',\", \"'stori',\", \"'get',\", \"'friend',\", \"'snake',\", \"'elementari',\", \"'father',\", \"'save',\", \"'famili',\", \"'girl',\", \"'snake',\", \"'post',\", \"'anyth',\", \"'pari',\", \"'keep',\", \"'chose',\", \"'join',\", \"'owner',\", \"'jay',\", \"'plan',\", \"'polic',\", \"'age',\", \"'left',\", \"'truck',\", \"'manate',\", \"'packag',\", \"'contractor',\", \"'manag',\", \"'girl',\", \"'best',\", \"'chase',\", \"'brockman',\", \"'fell',\", \"'music',\", \"'let',\", \"'found',\", \"'fortun',\", \"'money',\", \"'theme',\", \"'escap',\", \"'local',\", \"'enjoy',\", \"'live',\", \"'hair',\", \"'promis',\", \"'buy',\", \"'love',\", \"'includ',\", \"'make',\", \"'gift',\", \"'life',\", \"'choos',\", \"'leari',\", \"'open',\", \"'apart',\", \"'maud',\", \"'got',\", \"'phone',\", \"'deni',\", \"'gay',\", \"'gradi',\", \"'closet',\", \"'amus',\", \"'offer',\", \"'front',\", \"'present',\", \"'good',\", \"'accident',\", \"'past',\", \"'mel',\", \"'burn',\", \"'hate',\", \"'julio',\", \"'prove',\", \"'miss',\", \"'alcohol',\", \"'sandwich',\", \"'entir',\", \"'christma',\", \"'movi',\", \"'kirk',\", \"'forget',\", \"'steal',\", \"'drunk',\", \"'move',\", \"'park',\", \"'anoth',\", \"'woman',\", \"'gift',\", \"'date',\", \"'break',\", \"'friend',\", \"'help',\", \"'get',\", \"'soon',\", \"'drive',\", \"'costum',\", \"'women',\", \"'busi',\", \"'charg',\", \"'drink',\", \"'tavern',\", \"'men',\", \"'staci',\", \"'hair',\", \"'electr',\", \"'kid',\", \"'enough',\", \"'relat',\", \"'rais',\", \"'short',\", \"'leav',\", \"'repair',\", \"'see',\", \"'basebal',\", \"'spell',\", \"'ship',\", \"'resid',\", \"'perfect',\", \"'hold',\", \"'school',\", \"'tenni',\", \"'longer',\", \"'trash',\", \"'decid',\", \"'bar',\", \"'peopl',\", \"'offer',\", \"'steal',\", \"'creat',\", \"'thank',\", \"'boy',\", \"'save',\", \"'team',\", \"'get',\", \"'power',\", \"'pie',\", \"'man',\", \"'children',\", \"'team',\", \"'promis',\", \"'ride',\", \"'competit',\", \"'texan',\", \"'face',\", \"'shut',\", \"'arm',\", \"'better',\", \"'day',\", \"'rich',\", \"'crowd',\", \"'cake',\", \"'employe',\", \"'sick',\", \"'allow',\", \"'warn',\", \"'angri',\", \"'turn',\", \"'hospit',\", \"'commerci',\", \"'sea',\", \"'next',\", \"'humili',\", \"'seri',\", \"'ticket',\", \"'ship',\", \"'student',\", \"'bowl',\", \"'lenni',\", \"'buy',\", \"'littl',\", \"'father',\", \"'boy',\", \"'break',\", \"'dream',\", \"'new',\", \"'plant',\", \"'anoth',\", \"'stori',\", \"'sara',\", \"'town',\", \"'drug',\", \"'camera',\", \"'offer',\", \"'toni',\", \"'busi']\", \"'someth',\", \"'cathol',\", \"'helen',\", \"'enter',\", \"'sideshow',\", \"'comic',\", \"'red',\", \"'otto',\", \"'follow',\", \"'quick',\", \"'sentenc',\", \"'date',\", \"'roll',\", \"'advantag',\", \"'school',\", \"'dinner',\", \"'second',\", \"'singl',\", \"'death',\", \"'new',\", \"'attend',\", \"'pictur',\", \"'beer',\", \"'abus',\", \"'join',\", \"'smither',\", \"'choos',\", \"'lose',\", \"'life',\", \"'instead',\", \"'father',\", \"'success',\", \"'son',\", \"'teach',\", \"'believ',\", \"'interest',\", \"'plant',\", \"'nuclear',\", \"'power',\", \"'activ',\", \"'bedroom',\", \"'train',\", \"'luann',\", \"'plant',\", \"'emili',\", \"'convent',\", \"'smither',\", \"'window',\", \"'christma',\", \"'investig',\", \"'daughter',\", \"'interest',\", \"['parodi',\", \"'deliv',\", \"'hole',\", \"'santa',\", \"'terribl',\", \"'hard',\", \"'attract',\", \"'van',\", \"'houten',\", \"'monkey',\", \"'hold',\", \"'marri',\", \"'health',\", \"'festiv',\", \"'hire',\", \"'remov',\", \"'could',\", \"'grampa',\", \"'friend',\", \"'helper',\", \"'buy',\", \"'get',\", \"'job',\", \"'gay',\", \"'littl',\", \"'break',\", \"'mani',\", \"'trip',\", \"'teacher',\", \"'shirt',\", \"'goos',\", \"'decid',\", \"'nuclear',\", \"'reactor',\", \"'item',\", \"'femal',\", \"'sell',\", \"'ask',\", \"'store',\", \"'small',\", \"'tooth',\", \"'busi',\", \"'child',\", \"'improv',\", \"'god',\", \"'licens',\", \"'food',\", \"'take',\", \"'write',\", \"'joke',\", \"'surviv',\", \"'fail',\", \"'destroy',\", \"'review',\", \"'marri',\", \"'bird',\", \"'mrs',\", \"'critic',\", \"'plant',\", \"'fair',\", \"'lose',\", \"'set',\", \"'get',\", \"'power',\", \"'mother',\", \"'show',\", \"'order',\", \"'tell',\", \"'flashback',\", \"'fish',\", \"'love',\", \"'movi',\", \"'jewel',\", \"'seri',\", \"'comic',\", \"'guy',\", \"'compani',\", \"'six',\", \"'parti',\", \"'marri']\", \"'version',\", \"'histori',\", \"'els',\", \"'friend']\", \"'retreat',\", \"'stori',\", \"'book',\", \"'weight',\", \"'young',\", \"'grampa',\", \"'nelson',\", \"'direct',\", \"'rainier',\", \"'princip',\", \"'true',\", \"'surpris',\", \"'hit',\", \"'lyle',\", \"'lose',\", \"'lead',\", \"'life',\", \"'teacher',\", \"'part',\", \"'fire',\", \"'krabappel',\", \"'store',\", \"'plant',\", \"'save',\", \"'get',\", \"'year',\", \"'segment',\", \"'ice',\", \"'willi',\", \"'bounti',\", \"'krupt',\", \"'game',\", \"'art',\", \"'spoof',\", \"'cream',\", \"'parodi',\", \"'failur',\", \"'board',\", \"'push',\", \"'far',\", \"'afford',\", \"'bulli',\", \"'contain',\", \"'deliv',\", \"'voic',\", \"'pull',\", \"'violent',\", \"'sister',\", \"'teacher',\", \"'convinc',\", \"'nightmar',\", \"'groundskeep',\", \"'paint',\", \"'film',\", \"'treehous',\", \"'horror',\", \"'father',\", \"'win',\", \"'carl',\", \"'littl',\", \"'attack',\", \"'student',\", \"'local',\", \"'friend',\", \"'suggest',\", \"'get',\", \"'child',\", \"'rag',\", \"'fellow',\", \"'employe',\", \"'tapestri',\", \"'ray',\", \"'race',\", \"'human',\", \"'parodi',\", \"'punch',\", \"'robot',\", \"'simon',\", \"'white',\", \"'star',\", \"'oper',\", \"'snow',\", \"'art',\", \"'famili',\", \"'thought',\", \"'roof',\", \"'toss',\", \"'product']\", \"'macbeth',\", \"'dig',\", \"['father',\", \"'compani',\", \"'beg',\", \"'went',\", \"'gain',\", \"'switch',\", \"'queen',\", \"'high',\", \"'build',\", \"'stori',\", \"'pair',\", \"'lenni',\", \"'selma',\", \"'place',\", \"'local',\", \"'plant',\", \"'spend',\", \"'friend',\", \"'miss',\", \"'move',\", \"'life',\", \"'lesson',\", \"'scene',\", \"'count',\", \"'insid',\", \"'trial',\", \"'bob',\", \"'trap',\", \"'last',\", \"'celebr',\", \"'especi',\", \"'end',\", \"'perform',\", \"'version',\", \"'listen',\", \"'hell',\", \"'terror',\", \"'cartoon',\", \"'shock',\", \"'crash',\", \"'itchi',\", \"'scratchi',\", \"'side',\", \"'appear',\", \"'voic',\", \"'die']\", \"'interest']\", \"'piano',\", \"'meal',\", \"['sing',\", \"'extra',\", \"'music',\", \"'happen',\", \"'hair',\", \"'movi',\", \"'convinc',\", \"'featur',\", \"'lead',\", \"'littl',\", \"'spend',\", \"'star',\", \"'father',\", \"'live',\", \"'good',\", \"'bashir',\", \"'arti',\", \"'write',\", \"'terror',\", \"'blood',\", \"'golf',\", \"'tall',\", \"'intellig',\", \"'convinc',\", \"'tale',\", \"'high',\", \"'role',\", \"'decor',\", \"['halloween',\", \"'style']\", \"['follow',\", \"'bin',\", \"'apolog',\", \"'laden',\", \"'treat',\", \"'prom',\", \"'feet',\", \"'pop',\", \"'shelter',\", \"'light',\", \"'georg',\", \"'short',\", \"'grampa',\", \"'stick',\", \"'blow',\", \"'kwik',\", \"'stori',\", \"'remov',\", \"'form',\", \"'take',\", \"'give',\", \"'lost',\", \"'better',\", \"'pair',\", \"'test',\", \"'chang',\", \"'life',\", \"'son',\", \"'forc',\", \"'school',\", \"'lose',\", \"'father',\", \"'show',\", \"'good',\", \"'result',\", \"'nelson',\", \"'bulli',\", \"'leader',\", \"'defend',\", \"['retir',\", \"'elder',\", \"'shoot',\", \"'frame',\", \"'serious',\", \"'wear',\", \"'group',\", \"'windmil',\", \"'jebediah',\", \"'flame',\", \"'cletus',\", \"'stay',\", \"'invit',\", \"'women',\", \"'close',\", \"'school',\", \"'grampa',\", \"'among',\", \"'score',\", \"'whale',\", \"'beach',\", \"'wait',\", \"'arm',\", \"'test',\", \"'save']\", \"'whose',\", \"'entir',\", \"'team',\", \"'secret',\", \"'day',\", \"'friend',\", \"'real',\", \"'follow',\", \"'power',\", \"'win',\", \"'citi',\", \"'adopt',\", \"'babi',\", \"'might',\", \"'selma',\", \"'bender',\", \"'basement',\", \"'chief',\", \"'introduc',\", \"'annual',\", \"'brother',\", \"'nelson',\", \"'busi',\", \"'futur',\", \"['grampa',\", \"'classroom',\", \"'doctor',\", \"'forest',\", \"'crew',\", \"'kill',\", \"'mess',\", \"'follow']\", \"'moonshin',\", \"'tast']\", \"'china',\", \"'mysteri',\", \"'firework',\", \"'mention',\", \"'scratchi',\", \"'helicopt',\", \"'foot',\", \"'happen',\", \"'choos',\", \"'stop',\", \"'suggest',\", \"'problem',\", \"'hous',\", \"'boy',\", \"'marri',\", \"'sudden',\", \"'six',\", \"'bond',\", \"'commit',\", \"'worri',\", \"'believ',\", \"'member',\", \"'key',\", \"'assist',\", \"'boston',\", \"'cemeteri',\", \"'ban',\", \"'duff',\", \"'tale',\", \"'behind',\", \"'car',\", \"'candi',\", \"'popular',\", \"'afraid',\", \"'construct',\", \"'crazi',\", \"'perform',\", \"'american',\", \"'toy',\", \"['learn',\", \"'bite',\", \"'protest',\", \"'keep',\", \"'number',\", \"'funer',\", \"'cletus',\", \"'convent',\", \"'alien',\", \"'senior',\", \"'nois',\", \"'famous',\", \"'lot',\", \"'trip',\", \"'deal',\", \"'hire',\", \"'lead',\", \"'find',\", \"'send',\", \"'move',\", \"'secret',\", \"'world',\", \"'order',\", \"'apu',\", \"'famili',\", \"'live',\", \"'lock',\", \"'spend',\", \"'stay',\", \"'hope',\", \"'area',\", \"'footbal',\", \"'hell',\", \"'gang',\", \"'sign',\", \"'garden',\", \"'apart',\", \"'window',\", \"'bulli',\", \"'result',\", \"'ever',\", \"'read',\", \"'alaska',\", \"'spread',\", \"'shauna',\", \"'instead']\", \"'abe',\", \"'commission',\", \"'stadium',\", \"'christma',\", \"'everybodi',\", \"'neighbor',\", \"'heaven',\", \"'tie',\", \"'person',\", \"'fourth',\", \"'sure',\", \"'gil',\", \"'contest',\", \"'pay',\", \"'elementari',\", \"'win',\", \"'happen',\", \"'new',\", \"'team',\", \"'best',\", \"'citi',\", \"'live',\", \"'friend',\", \"'lead',\", \"'break',\", \"'chloe',\", \"'chalmer',\", \"'fli',\", \"'edna',\", \"'live']\", \"'whack',\", \"'invit',\", \"'parti',\", \"'report',\", \"'attend',\", \"'birthday',\", \"'involv',\", \"'review',\", \"'seem',\", \"'high',\", \"'educ',\", \"'roosevelt',\", \"'least',\", \"['receiv',\", \"['edna',\", \"'jet',\", \"'media',\", \"'classmat',\", \"'done',\", \"'helicopt',\", \"'interest',\", \"'colleg',\", \"'full',\", \"'wed',\", \"'groundskeep',\", \"'forc',\", \"'convinc',\", \"'snake',\", \"'day',\", \"'willi',\", \"'boy',\", \"'entir',\", \"'springfield',\", \"'life',\", \"'save',\", \"'princip',\", \"'get',\", \"'club',\", \"'sideshow',\", \"'riot',\", \"'kwik',\", \"'apu',\", \"'toni',\", \"'countri',\", \"'fat',\", \"'replac',\", \"'suppli',\", \"['tavern',\", \"'play',\", \"['caught',\", \"'convinc',\", \"'armi',\", \"'boy']\", \"'mart',\", \"'door',\", \"'recruit',\", \"'live']\", \"'walt',\", \"'horrifi',\", \"'teen',\", \"'member',\", \"'well']\", \"'set',\", \"'four',\", \"'posit']\", \"'meat',\", \"'wear']\", \"'live',\", \"'realiti',\", \"'bar',\", \"'result',\", \"'job',\", \"'bad',\", \"'student',\", \"'team',\", \"'forc',\", \"'friend',\", \"'littl',\", \"'catch',\", \"'togeth',\", \"'secret',\", \"'best',\", \"'busi',\", \"'neighbor',\", \"'wayn',\", \"'junk',\", \"'magazin',\", \"'cut',\", \"'nightmar',\", \"'rescu']\", \"'laura',\", \"'oper',\", \"'treehous',\", \"'prize',\", \"'mind',\", \"'monkey',\", \"'food']\", \"['anoth',\", \"'enjoy']\", \"'entri',\", \"'favor',\", \"'bachelor',\", \"'hand',\", \"'stop']\", \"'deed',\", \"'love',\", \"'extra',\", \"'secur',\", \"'food',\", \"'unawar',\", \"'hope',\", \"'suffer',\", \"['valentin',\", \"'guest',\", \"'interest',\", \"'result',\", \"'voic',\", \"'includ',\", \"'stori',\", \"'quick',\", \"'power',\", \"'dream',\", \"'secret',\", \"'must',\", \"'attack',\", \"'order',\", \"'life',\", \"'calm',\", \"'enjoy',\", \"'harper',\", \"'princip',\", \"'itchi',\", \"'partner',\", \"'hutz',\", \"'teach',\", \"'sideshow',\", \"'crimin',\", \"'rich',\", \"'problem']\", \"'desert',\", \"'mad',\", \"'monster',\", \"'prevent']\", \"'cheech',\", \"'tabl',\", \"'chong',\", \"['jealous',\", \"'alway',\", \"'charact',\", \"'crazi',\", \"'scratchi',\", \"'pop',\", \"'donut',\", \"'life']\", \"'power']\", \"'ban',\", \"'human',\", \"'prompt',\", \"'school',\", \"'agre',\", \"'well',\", \"'chief',\", \"'move',\", \"'famili',\", \"'life',\", \"'grampa',\", \"'love',\", \"'woman',\", \"'good',\", \"'break',\", \"'dad',\", \"'bulli',\", \"'someth',\", \"'quimbi',\", \"'christma',\", \"'star']\", \"['parodi',\", \"'accid',\", \"'martin',\", \"'shop',\", \"'mall',\", \"'bob',\", \"'mayor',\", \"'prove',\", \"'prompt',\", \"'video',\", \"'network',\", \"'incid',\", \"'cliff',\", \"'low',\", \"'suspici',\", \"'itchi',\", \"'mention',\", \"'scratchi',\", \"'gain',\", \"'went',\", \"'bed',\", \"'injuri',\", \"'situat',\", \"'accus',\", \"'plane',\", \"'creat',\", \"'dream',\", \"'protest',\", \"'guest',\", \"'prank',\", \"'student',\", \"'keep',\", \"'set',\", \"'thing',\", \"'good',\", \"'secret',\", \"'success',\", \"'place',\", \"'friend',\", \"'class',\", \"'job',\", \"'close',\", \"'diari',\", \"'hand',\", \"'illeg',\", \"'fake',\", \"'celebr',\", \"'blame',\", \"'fail',\", \"'scene',\", \"'luck',\", \"'pray',\", \"['film',\", \"'along']\", \"'poor']\", \"'reward',\", \"'cast',\", \"'tax',\", \"'well']\", \"'smither',\", \"'total',\", \"'roll',\", \"'jealous',\", \"'god',\", \"'immigr',\", \"'various',\", \"'actual']\", \"['host',\", \"'deport',\", \"'shown',\", \"['bear',\", \"'countri']\", \"'origin',\", \"'tree',\", \"'grade',\", \"'event',\", \"'crimin',\", \"'rememb',\", \"'posit',\", \"'apu',\", \"'elementari',\", \"'year',\", \"'movi',\", \"'choos',\", \"'young',\", \"'escap',\", \"'girl',\", \"'someon',\", \"'glass',\", \"'spi',\", \"['employe',\", \"'earli',\", \"'succeed',\", \"'form',\", \"'realiti',\", \"'locat',\", \"'stampi',\", \"'eleph',\", \"'secret',\", \"'presid',\", \"'nelson',\", \"'grow',\", \"'band',\", \"'due',\", \"'parodi',\", \"'marriag',\", \"'counselor',\", \"'novel',\", \"'apu']\", \"'whether',\", \"'bodi',\", \"'valentin',\", \"['clown',\", \"'whose',\", \"'brand',\", \"['teacher',\", \"'ill',\", \"'hurt',\", \"'best',\", \"'teacher',\", \"'peopl',\", \"'gift',\", \"'love',\", \"'actual',\", \"'win',\", \"'choos',\", \"'voic',\", \"'guest',\", \"'union',\", \"'mattress',\", \"'bed',\", \"['accident',\", \"'photo',\", \"'promot',\", \"'grandpa',\", \"'leader',\", \"'enlist',\", \"'championship',\", \"'pub',\", \"'flanagan',\", \"'includ']\", \"'pose',\", \"'cost',\", \"'depart',\", \"'water',\", \"'collect',\", \"'execut',\", \"'refus',\", \"'talk',\", \"'trade',\", \"'wall',\", \"'flag',\", \"'request',\", \"'barbershop',\", \"'obvious',\", \"'beatl',\", \"'keep']\", \"'episod',\", \"'quit',\", \"'townspeopl',\", \"'last',\", \"'buy',\", \"'repair',\", \"'best',\", \"'littl',\", \"'plant',\", \"'american',\", \"'sell',\", \"'sleep',\", \"'assist',\", \"'second',\", \"'carl',\", \"'caught',\", \"['win',\", \"'team',\", \"'let',\", \"'princip',\", \"'licens',\", \"'smither',\", \"'adopt',\", \"'casino',\", \"'treehous',\", \"'fire',\", \"'nativ',\", \"'ralph']\", \"'candid',\", \"'presidenti',\", \"'suck',\", \"'receiv']\", \"'anoth']\", \"'relationship',\", \"['invit',\", \"'beg',\", \"'reward',\", \"'drive',\", \"'afterward']\", \"'want',\", \"'whose',\", \"'flee',\", \"'soul',\", \"'invit',\", \"'job',\", \"'ground',\", \"'practic',\", \"'control',\", \"'tast',\", \"'save',\", \"'clown',\", \"'includ',\", \"'open',\", \"'santa',\", \"'helper',\", \"'littl',\", \"'mean',\", \"'taken',\", \"'springfield',\", \"'american',\", \"'invent',\", \"'girl',\", \"'pretend',\", \"'claim',\", \"'report',\", \"'laney',\", \"'strangl',\", \"'clip',\", \"'bowl',\", \"'fear',\", \"'romant',\", \"'loss',\", \"'presum',\", \"'maya',\", \"'correct',\", \"['wed',\", \"'tavern']\", \"'hit',\", \"'ball',\", \"'feet',\", \"'face',\", \"'tall',\", \"['parent',\", \"'popular',\", \"'crime',\", \"'mistak',\", \"'snowbal',\", \"'poker',\", \"'dead',\", \"'settl',\", \"'beauti',\", \"'suppos',\", \"'apart']\", \"'jacqu',\", \"'colonel',\", \"'sent',\", \"'scare',\", \"'ultim',\", \"'quick',\", \"'show',\", \"'follow',\", \"'month',\", \"'woman',\", \"'relationship',\", \"'enter',\", \"'receiv',\", \"'frame',\", \"'contact',\", \"'third',\", \"'spend',\", \"'close',\", \"'eye',\", \"'parent',\", \"'rememb',\", \"'ever',\", \"'avoid',\", \"'univers',\", \"'predict',\", \"'washington',\", \"'insist',\", \"'bet',\", \"'mayor',\", \"['problem',\", \"'written',\", \"'corner',\", \"'everybodi',\", \"'door',\", \"'tune',\", \"'fit',\", \"'garag',\", \"'backyard',\", \"'quimbi',\", \"'wast',\", \"'insur',\", \"'messag',\", \"'repeat',\", \"'behind',\", \"'write',\", \"'rat',\", \"'fell',\", \"'owner',\", \"'fellow',\", \"'space',\", \"'save',\", \"'disappear',\", \"'morn',\", \"'problem',\", \"'result',\", \"'show',\", \"'well',\", \"'church',\", \"'love',\", \"'win',\", \"'life',\", \"'christma',\", \"'relationship',\", \"'invit',\", \"'charg',\", \"'includ',\", \"'hate',\", \"['land',\", \"'rocket',\", \"'line',\", \"'kang',\", \"'kodo',\", \"'terribl',\", \"'except',\", \"'perfect',\", \"'problem',\", \"'graduat',\", \"['friend',\", \"'equalia',\", \"'lunch',\", \"'ride',\", \"'prom',\", \"'treat',\", \"'seem',\", \"'provid',\", \"'readi',\", \"'yet',\", \"'basement',\", \"'senior',\", \"'punch',\", \"'imagin',\", \"'cure',\", \"'one']\", \"'real',\", \"'jack',\", \"'expect',\", \"'stop']\", \"'togeth',\", \"'worri',\", \"'futur',\", \"'face',\", \"'learn',\", \"'littl',\", \"'world',\", \"'friend',\", \"'attend',\", \"'fight',\", \"'professor',\", \"'punish',\", \"'scienc',\", \"'christma',\", \"'colleg',\", \"'chanc',\", \"'give',\"], \"Freq\": [3.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 5.0, 5.0, 1.517438530921936, 1.2186428308486938, 1.3120193481445312, 1.9636471271514893, 1.0078471899032593, 1.1085597276687622, 1.4752107858657837, 1.3554788827896118, 0.953093409538269, 0.9530932307243347, 1.4861934185028076, 1.0541657209396362, 1.380196213722229, 1.095054268836975, 0.9965720772743225, 1.0084205865859985, 1.0078604221343994, 1.161659598350525, 1.305045485496521, 1.0672003030776978, 0.797165036201477, 0.7971535325050354, 0.7971534729003906, 1.2192504405975342, 0.8977075815200806, 0.9534764289855957, 1.0949627161026, 1.008784532546997, 0.7978375554084778, 1.895405888557434, 1.230053424835205, 1.4766566753387451, 1.0083094835281372, 1.1879405975341797, 1.1621284484863281, 1.7284907102584839, 1.2043426036834717, 1.1614969968795776, 1.162503957748413, 1.1084697246551514, 1.094635009765625, 1.156012773513794, 1.0512629747390747, 1.0278675556182861, 3.133315324783325, 1.6690829992294312, 1.9154772758483887, 1.703686237335205, 2.010293483734131, 2.34480881690979, 1.1569935083389282, 1.1320017576217651, 0.9866617321968079, 2.0191879272460938, 0.8166447281837463, 1.3279509544372559, 0.771629273891449, 1.0113625526428223, 0.7509887218475342, 0.6458766460418701, 0.645558774471283, 0.645214319229126, 0.9864094853401184, 1.108089804649353, 0.6457397937774658, 0.6458762884140015, 0.8289287686347961, 0.6456284523010254, 0.6010695695877075, 0.7872691750526428, 0.8563323020935059, 0.6453486680984497, 0.5848736763000488, 0.4748334288597107, 0.4748334288597107, 0.7272424697875977, 0.9426071047782898, 1.21871817111969, 1.1058349609375, 0.7864498496055603, 0.7719460129737854, 0.8195832371711731, 0.7203112840652466, 0.6978686451911926, 0.6458829045295715, 1.2197318077087402, 0.5378047227859497, 0.5367305278778076, 0.4495556056499481, 0.7342942357063293, 0.4495536983013153, 0.6823127269744873, 0.3875369727611542, 0.4495794475078583, 0.4495140612125397, 0.5064918994903564, 0.417752206325531, 0.41883036494255066, 0.4188475012779236, 0.33093252778053284, 0.3307259678840637, 0.33069297671318054, 0.44966185092926025, 0.6564582586288452, 0.5218546986579895, 0.4186570346355438, 0.3309323191642761, 0.33091995120048523, 0.5947067737579346, 0.4497848451137543, 0.4495770335197449, 0.38754701614379883, 0.3307170271873474, 0.3309324383735657, 0.44977253675460815, 0.6256285905838013, 0.4185541272163391, 0.5369943976402283, 0.4497784972190857, 0.44954580068588257, 0.5066866278648376, 0.5067873597145081, 0.44987523555755615, 0.44966936111450195, 0.4496729373931885, 0.4499780535697937, 0.4187758266925812, 0.5167266726493835, 0.7822904586791992, 0.5133501291275024, 0.483722984790802, 0.5156953930854797, 0.5167266726493835, 0.40867504477500916, 0.510503351688385, 0.40593305230140686, 0.4082067608833313, 0.35227853059768677, 0.568428099155426, 0.46034449338912964, 0.4587762653827667, 0.6451133489608765, 0.5388575792312622, 0.3737442195415497, 0.32414722442626953, 0.300571084022522, 0.38046225905418396, 0.29857689142227173, 0.4081480801105499, 0.5609623193740845, 0.29861578345298767, 0.3006243407726288, 0.3769211173057556, 0.3787693381309509, 0.5124650597572327, 0.29857751727104187, 0.29844632744789124, 0.45929837226867676, 0.4016236364841461, 0.5925092101097107, 0.35226938128471375, 0.3804987370967865, 0.40867456793785095, 0.4086301624774933, 0.3997519016265869, 0.4001091420650482, 0.4087609648704529, 0.38047435879707336, 0.3806414008140564, 0.4789610505104065, 0.6787823438644409, 0.37860536575317383, 0.578731119632721, 0.6270473599433899, 0.42647984623908997, 0.3524535298347473, 0.4525764286518097, 0.45257046818733215, 0.300297349691391, 0.4742148220539093, 0.3524234890937805, 0.27848494052886963, 0.2787209153175354, 0.2785046100616455, 0.37847697734832764, 0.3263331651687622, 0.27871742844581604, 0.2784744203090668, 0.2787039577960968, 0.25231218338012695, 0.27850428223609924, 0.2784609794616699, 0.326350599527359, 0.27848735451698303, 0.3524337410926819, 0.3784264028072357, 0.22630056738853455, 0.27870896458625793, 0.22629952430725098, 0.3535192012786865, 0.5526055693626404, 0.37858492136001587, 0.3524464964866638, 0.35272863507270813, 0.3263997733592987, 0.32663494348526, 0.3529072701931, 0.3264201581478119, 0.30010730028152466, 0.27875128388404846, 0.278749018907547, 1.7510828971862793, 0.8648332953453064, 0.6420736312866211, 0.6895114779472351, 0.5695390105247498, 0.47137707471847534, 0.47113579511642456, 0.3725198805332184, 0.4709714651107788, 0.34694477915763855, 0.3727042078971863, 0.5184745192527771, 0.37248581647872925, 0.3724973201751709, 0.274027556180954, 0.27414029836654663, 0.3469313681125641, 0.27404138445854187, 0.3726350665092468, 0.2740243971347809, 0.24853788316249847, 0.2741389572620392, 0.2740516662597656, 0.27405327558517456, 0.27424103021621704, 0.27403736114501953, 0.2740486264228821, 0.321066677570343, 0.27402830123901367, 0.2742409408092499, 0.37280789017677307, 0.29569879174232483, 0.3468945026397705, 0.3727167844772339, 0.41981008648872375, 0.3727104365825653, 0.3727717101573944, 0.3214018642902374, 0.2956884205341339, 0.2956991493701935, 0.3212969899177551, 0.27576401829719543, 0.274761825799942, 0.7012348175048828, 0.34094077348709106, 0.34103289246559143, 0.34112071990966797, 0.49772992730140686, 0.34112000465393066, 0.3169446289539337, 0.38358524441719055, 0.25093135237693787, 0.2507242262363434, 0.31751012802124023, 0.29328852891921997, 0.3411203920841217, 0.2507113218307495, 0.2273242324590683, 0.3409202992916107, 0.3607548475265503, 0.2509306073188782, 0.43103864789009094, 0.2273244708776474, 0.2509310841560364, 0.34112080931663513, 0.2508297264575958, 0.34113600850105286, 0.22731561958789825, 0.22741299867630005, 0.3176019787788391, 0.2507360279560089, 0.2507448196411133, 0.2038954645395279, 0.2508447468280792, 0.3410262167453766, 0.25093114376068115, 0.3176097273826599, 0.29408368468284607, 0.3175011873245239, 0.2509301006793976, 0.25096020102500916, 0.25095120072364807, 0.2509467601776123, 0.2509434223175049, 0.2509312033653259, 0.2509310841560364, 0.25093114376068115, 0.6956780552864075, 0.7586681842803955, 0.4058593511581421, 0.3208528459072113, 0.3209676742553711, 0.2988603711128235, 0.6096267700195312, 0.23612363636493683, 0.29845964908599854, 0.29886019229888916, 0.23598508536815643, 0.3209611177444458, 0.23598535358905792, 0.23612351715564728, 0.3209908604621887, 0.23598535358905792, 0.236083984375, 0.2361239343881607, 0.40744996070861816, 0.23612336814403534, 0.23598511517047882, 0.25437864661216736, 0.2142105996608734, 0.21419881284236908, 0.2139931619167328, 0.27520936727523804, 0.32085123658180237, 0.23598511517047882, 0.21399304270744324, 0.29872211813926697, 0.2361610382795334, 0.27520278096199036, 0.36157917976379395, 0.4686996042728424, 0.2999919056892395, 0.2988487184047699, 0.2751680612564087, 0.25309449434280396, 0.2367640733718872, 0.2368791699409485, 0.23642675578594208, 0.23625455796718597, 0.23616400361061096, 0.23615692555904388, 0.8189787864685059, 0.469112753868103, 0.5500289797782898, 0.6044368147850037, 0.30678093433380127, 0.30683860182762146, 0.2861328721046448, 0.3877669870853424, 0.3068561553955078, 0.3880157172679901, 0.30687642097473145, 0.2257470190525055, 0.42689815163612366, 0.3070670962333679, 0.22606796026229858, 0.2260681837797165, 0.22576259076595306, 0.3036610782146454, 0.36725687980651855, 0.28584563732147217, 0.22576376795768738, 0.20488008856773376, 0.2646821439266205, 0.22566716372966766, 0.18362879753112793, 0.3073209822177887, 0.1836925894021988, 0.22606812417507172, 0.18361350893974304, 0.43978023529052734, 0.2047564536333084, 0.3236199915409088, 0.2676023840904236, 0.44717735052108765, 0.3363571763038635, 0.2649461030960083, 0.22591766715049744, 0.2258613109588623, 0.2257896363735199, 0.274105429649353, 0.21741175651550293, 0.48830655217170715, 0.4001518189907074, 0.20163466036319733, 0.27410557866096497, 0.27480822801589966, 0.2745283842086792, 0.2741057276725769, 0.2016347497701645, 0.289883017539978, 0.18261729180812836, 0.20167461037635803, 0.2016342580318451, 0.18273694813251495, 0.20163434743881226, 0.1638393998146057, 0.39931824803352356, 0.20163485407829285, 0.20163476467132568, 0.2016347050666809, 0.343456894159317, 0.20163466036319733, 0.1827368289232254, 0.16384108364582062, 0.25520750880241394, 0.16303430497646332, 0.18273833394050598, 0.18198184669017792, 0.129166379570961, 0.27410534024238586, 0.25415295362472534, 0.3278888761997223, 0.20163466036319733, 0.2016347497701645, 0.20163680613040924, 0.2016347050666809, 0.2016342729330063, 0.21741171181201935, 0.20180116593837738, 0.2016383409500122, 0.20163455605506897, 0.25481149554252625, 0.257920503616333, 0.3082992732524872, 0.18972903490066528, 0.1897289901971817, 0.364553302526474, 0.23910953104496002, 0.1897292286157608, 0.18972815573215485, 0.24008063971996307, 0.1719461977481842, 0.18972913920879364, 0.171968474984169, 0.18973231315612793, 0.18972884118556976, 0.25814133882522583, 0.1541091352701187, 0.17200566828250885, 0.2578861713409424, 0.1719464659690857, 0.18972916901111603, 0.15416818857192993, 0.2223588079214096, 0.24019856750965118, 0.15409807860851288, 0.1719108670949936, 0.15423797070980072, 0.22227071225643158, 0.1541423797607422, 0.154114231467247, 0.3083237409591675, 0.24019090831279755, 0.18981780111789703, 0.25833556056022644, 0.2044597566127777, 0.18972907960414886, 0.20475707948207855, 0.22244176268577576, 0.18978171050548553, 0.18973501026630402, 0.17224234342575073, 0.27662473917007446, 0.20369796454906464, 0.24645718932151794, 0.16093705594539642, 0.16093699634075165, 0.17352959513664246, 0.16093698143959045, 0.21878042817115784, 0.160936638712883, 0.16093844175338745, 0.16093647480010986, 0.16093683242797852, 0.27663618326187134, 0.14585335552692413, 0.16093719005584717, 0.16093768179416656, 0.21879896521568298, 0.14589868485927582, 0.10309562087059021, 0.10309557616710663, 0.10309557616710663, 0.10309546440839767, 0.1030951738357544, 0.10309498012065887, 0.16093875467777252, 0.1030956506729126, 0.10309562087059021, 0.10309518128633499, 0.10309512168169022, 0.10309547930955887, 0.1458357721567154, 0.1458555907011032, 0.23172003030776978, 0.14585354924201965, 0.1609419733285904, 0.16094285249710083, 0.16094975173473358, 0.173541858792305, 0.18861451745033264, 0.16093795001506805, 0.2187804877758026, 0.16105163097381592, 0.16100355982780457, 0.1609654575586319, 0.21074210107326508, 0.19615183770656586, 0.15499712526798248, 0.1550174355506897, 0.15503185987472534, 0.15533609688282013, 0.15503187477588654, 0.1962105631828308, 0.14048074185848236, 0.15500156581401825, 0.15500211715698242, 0.15499624609947205, 0.1404956579208374, 0.1550011932849884, 0.12596966326236725, 0.12596894800662994, 0.14049513638019562, 0.1550300419330597, 0.1550191044807434, 0.14049303531646729, 0.14049071073532104, 0.1405014842748642, 0.1671801507472992, 0.18172770738601685, 0.09931278228759766, 0.09931272268295288, 0.0993126928806305, 0.09930668771266937, 0.09930654615163803, 0.09927652031183243, 0.19622258841991425, 0.15499278903007507, 0.14050035178661346, 0.15500208735466003, 0.1405019313097, 0.12597037851810455, 0.1404784470796585, 0.15512755513191223, 0.14051449298858643, 0.14052695035934448, 0.14051127433776855, 0.14050060510635376, 0.14049623906612396, 0.15264809131622314, 0.15269224345684052, 0.2052101343870163, 0.13819552958011627, 0.12407135963439941, 0.12402597814798355, 0.12407155334949493, 0.1240711510181427, 0.20519815385341644, 0.12407155334949493, 0.16462719440460205, 0.1240716427564621, 0.09781446307897568, 0.09781443327665329, 0.09781306982040405, 0.09781304746866226, 0.09779555350542068, 0.09779272973537445, 0.09779015928506851, 0.0978144183754921, 0.0978139340877533, 0.0978139340877533, 0.09781443327665329, 0.09781444817781448, 0.09781446307897568, 0.09781304746866226, 0.12386219948530197, 0.21952027082443237, 0.0977879986166954, 0.09778521209955215, 0.12407118082046509, 0.205060675740242, 0.12403778731822968, 0.12405113875865936, 0.15271757543087006, 0.12409919500350952, 0.13838160037994385, 0.13836179673671722, 0.12405470013618469, 0.12407143414020538, 0.12404940277338028, 0.16464945673942566, 0.12407363206148148, 0.13838163018226624, 0.12407150119543076, 0.13840290904045105, 0.13841445744037628, 0.12422774732112885, 0.12407559156417847, 0.1240713894367218, 0.46799352765083313, 0.45623600482940674, 0.24887153506278992, 0.23511533439159393, 0.19679543375968933, 0.19679543375968933, 0.19679535925388336, 0.19679543375968933, 0.19679543375968933, 0.19679543375968933, 0.30094778537750244, 0.14488863945007324, 0.14446516335010529, 0.15622548758983612, 0.14488783478736877, 0.23529170453548431, 0.19679543375968933, 0.19679543375968933, 0.19679543375968933, 0.18320798873901367, 0.2351507842540741, 0.09281512349843979, 0.09281512349843979, 0.092815101146698, 0.092815101146698, 0.09281504154205322, 0.11755326390266418, 0.14488866925239563, 0.092815101146698, 0.09281504899263382, 0.13130933046340942, 0.15632398426532745, 0.13130931556224823, 0.11773020774126053, 0.19691102206707, 0.13130933046340942, 0.1177302747964859, 0.14488860964775085, 0.13130883872509003, 0.11959362030029297, 0.1906571090221405, 0.2410811185836792, 0.14031879603862762, 0.24108996987342834, 0.14031878113746643, 0.1403258591890335, 0.19072066247463226, 0.12716783583164215, 0.14031873643398285, 0.14031833410263062, 0.14031879603862762, 0.19075171649456024, 0.17760016024112701, 0.08988771587610245, 0.08988771587610245, 0.08988767117261887, 0.08988764882087708, 0.08988762646913528, 0.08988762646913528, 0.08988753706216812, 0.08988726884126663, 0.08987018465995789, 0.08986564725637436, 0.08985587954521179, 0.12716716527938843, 0.0898875817656517, 0.08988744020462036, 0.11401678621768951, 0.08988742530345917, 0.0898876041173935, 0.1403186023235321, 0.17757053673267365, 0.12717951834201813, 0.14025506377220154, 0.14024722576141357, 0.11401693522930145, 0.09005261212587357, 0.08993811160326004, 0.08991549164056778, 0.0899084061384201, 0.08990758657455444, 0.08989767730236053, 0.08989737927913666, 0.0898972824215889, 0.08989692479372025, 0.3908703327178955, 0.2139972597360611, 0.13974031805992126, 0.1397264450788498, 0.1266440600156784, 0.13974083960056305, 0.1135471984744072, 0.13971860706806183, 0.13974086940288544, 0.11358094960451126, 0.15067453682422638, 0.08950966596603394, 0.08950579166412354, 0.0895102322101593, 0.11357346922159195, 0.126643568277359, 0.08951740711927414, 0.08951699733734131, 0.08951620757579803, 0.08950517326593399, 0.1637628674507141, 0.08951747417449951, 0.08951742202043533, 0.08951685577630997, 0.11370272934436798, 0.08951617777347565, 0.08951741456985474, 0.0895175188779831, 0.08951687067747116, 0.08951691538095474, 0.1637715995311737, 0.11354715377092361, 0.12665854394435883, 0.13974086940288544, 0.13974088430404663, 0.11354690045118332, 0.13972456753253937, 0.11354723572731018, 0.1135469302535057, 0.12664370238780975, 0.11354713141918182, 0.11354729533195496, 0.11391168087720871, 0.09109601378440857, 0.09014806896448135, 0.2509481906890869, 0.1306491196155548, 0.13064923882484436, 0.13064242899417877, 0.11840354651212692, 0.1061597466468811, 0.1306491494178772, 0.1184038296341896, 0.13064926862716675, 0.1061394214630127, 0.16129262745380402, 0.1653592586517334, 0.11840437352657318, 0.1184036061167717, 0.08369346708059311, 0.08369346708059311, 0.08369305729866028, 0.08369292318820953, 0.08369074761867523, 0.08369015157222748, 0.08368998765945435, 0.12648695707321167, 0.0836898535490036, 0.10614984482526779, 0.08369335532188416, 0.08368951827287674, 0.1306491494178772, 0.08369305729866028, 0.08369343727827072, 0.07952829450368881, 0.10615968704223633, 0.13064903020858765, 0.15311667323112488, 0.15317098796367645, 0.11838813871145248, 0.11840007454156876, 0.1306413859128952, 0.11840436607599258, 0.13064923882484436, 0.1306752860546112, 0.1653617024421692, 0.11839987337589264, 0.11839447915554047, 0.2609616219997406, 0.20414352416992188, 0.2159036248922348, 0.1707671582698822, 0.11384470015764236, 0.10207180678844452, 0.17076709866523743, 0.17077390849590302, 0.12560345232486725, 0.12560148537158966, 0.11384296417236328, 0.11384285986423492, 0.1020718365907669, 0.1255948841571808, 0.12558114528656006, 0.08047045767307281, 0.08047043532133102, 0.08047042042016983, 0.08047040551900864, 0.08047038316726685, 0.08047015964984894, 0.08046978712081909, 0.08047015964984894, 0.08045937120914459, 0.0804487019777298, 0.12559868395328522, 0.1138286367058754, 0.08047040551900864, 0.08047038316726685, 0.10207577049732208, 0.1472543179988861, 0.1256178319454193, 0.1354537308216095, 0.102078877389431, 0.10207466781139374, 0.15899184346199036, 0.10207025706768036, 0.11382757127285004, 0.12559263408184052, 0.11383114010095596, 0.1020718589425087, 0.12564007937908173, 0.1801149696111679, 0.1468278169631958, 0.10179950296878815, 0.1350860744714737, 0.16837656497955322, 0.1252831518650055, 0.10179975628852844, 0.1252831518650055, 0.1585794985294342, 0.080255888402462, 0.08025577664375305, 0.0802556648850441, 0.08025488257408142, 0.14683179557323456, 0.08025538921356201, 0.08025588095188141, 0.1350860744714737, 0.08025568723678589, 0.08025536686182022, 0.0802551805973053, 0.08026944100856781, 0.08025583624839783, 0.08025488257408142, 0.11354425549507141, 0.080255888402462, 0.13510039448738098, 0.0802551880478859, 0.06851520389318466, 0.06851519644260406, 0.0685151144862175, 0.1468358188867569, 0.08032863587141037, 0.15857301652431488, 0.11354125291109085, 0.13510727882385254, 0.12565059959888458, 0.10179952532052994, 0.1017996147274971, 0.1018083393573761, 0.11354101449251175, 0.09613808989524841, 0.08128605037927628, 0.08094621449708939, 0.0803288072347641, 0.08032862842082977, 0.08027418702840805, 0.08027315139770508, 0.16695338487625122, 0.12281232327222824, 0.1227884292602539, 0.17466077208518982, 0.13241852819919586, 0.11130189150571823, 0.09979185461997986, 0.10976295173168182, 0.11241758614778519, 0.09979210048913956, 0.09979058057069778, 0.09979037940502167, 0.0786730945110321, 0.07867307960987091, 0.07867300510406494, 0.07866495102643967, 0.07866130769252777, 0.07866048067808151, 0.09979132562875748, 0.07867308706045151, 0.07867245376110077, 0.18808133900165558, 0.07866524904966354, 0.07867316901683807, 0.12281234562397003, 0.07866326719522476, 0.07867221534252167, 0.09610605239868164, 0.07867296785116196, 0.12281042337417603, 0.11130202561616898, 0.12280253320932388, 0.12281084060668945, 0.12279710173606873, 0.14393238723278046, 0.109763965010643, 0.14393070340156555, 0.09979438781738281, 0.09979210048913956, 0.11137339472770691, 0.10079099237918854, 0.09869124740362167, 0.10418754816055298, 0.1611640453338623, 0.1815519481897354, 0.11855392903089523, 0.192663311958313, 0.12783005833625793, 0.11855344474315643, 0.0963316261768341, 0.16116422414779663, 0.10744249820709229, 0.09633110463619232, 0.11855386942625046, 0.07594513148069382, 0.07594513148069382, 0.07594505697488785, 0.07594505697488785, 0.07594496756792068, 0.07594484835863113, 0.07594484835863113, 0.07594482600688934, 0.07594415545463562, 0.07594523578882217, 0.0963311567902565, 0.07594484835863113, 0.09633152931928635, 0.07594514638185501, 0.07594505697488785, 0.07594521343708038, 0.07594502717256546, 0.07594523578882217, 0.07594513148069382, 0.10744260251522064, 0.11855386942625046, 0.10744279623031616, 0.11855385452508926, 0.09633174538612366, 0.1075105220079422, 0.09633174538612366, 0.10747796297073364, 0.09633170068264008, 0.09633173048496246, 0.08150603622198105, 0.07608676701784134, 0.07606116682291031, 0.07594523578882217, 0.07594523578882217, 0.07594524323940277, 0.07594524323940277, 0.170171320438385, 0.1087261289358139, 0.10872625559568405, 0.10872619599103928, 0.10872606933116913, 0.09647493064403534, 0.09647490829229355, 0.08834629505872726, 0.11723652482032776, 0.11723440140485764, 0.11268100887537003, 0.10872741043567657, 0.06964972615242004, 0.0696495771408081, 0.06964946538209915, 0.06964942812919617, 0.06964945048093796, 0.0883462056517601, 0.06964974105358124, 0.08834625035524368, 0.06964974105358124, 0.06964972615242004, 0.06964955478906631, 0.06964974105358124, 0.06964974105358124, 0.06964930891990662, 0.06965320557355881, 0.10873880237340927, 0.10872622579336166, 0.06964971125125885, 0.10872619599103928, 0.10872597247362137, 0.10872595012187958, 0.11723759025335312, 0.09720080345869064, 0.09853608906269073, 0.10060878098011017, 0.08834609389305115, 0.08834613859653473, 0.08836304396390915, 0.11034135520458221, 0.08834626525640488, 0.07707594335079193, 0.07191673666238785, 0.10665770620107651, 0.1150033101439476, 0.08666571229696274, 0.08666558563709259, 0.08667928725481033, 0.0866655632853508, 0.11500338464975357, 0.08666568249464035, 0.0683244839310646, 0.06832445412874222, 0.06832441687583923, 0.06832440197467804, 0.06832430511713028, 0.06832446157932281, 0.0683245062828064, 0.08666568249464035, 0.0683244839310646, 0.08666568249464035, 0.06832452118396759, 0.06832440197467804, 0.06832446157932281, 0.0683244839310646, 0.058329448103904724, 0.05832944065332413, 0.05832944065332413, 0.05832944065332413, 0.05832942947745323, 0.05832942947745323, 0.05832942947745323, 0.05832942575216293, 0.06832441687583923, 0.06832452118396759, 0.08666545152664185, 0.06833522766828537, 0.06832452118396759, 0.06832432001829147, 0.06832432001829147, 0.08695237338542938, 0.08666537702083588, 0.08668001741170883, 0.06835032254457474, 0.06833171844482422, 0.06832453608512878, 0.0683245062828064, 0.0683245062828064, 0.0683244988322258, 0.17345234751701355, 0.17345236241817474, 0.10092219710350037, 0.10098088532686234, 0.10092218965291977, 0.1278105080127716, 0.10092218965291977, 0.10092219710350037, 0.08205275237560272, 0.08205272257328033, 0.13721640408039093, 0.10099055618047714, 0.10116833448410034, 0.09151659160852432, 0.10098077356815338, 0.1009884774684906, 0.10093801468610764, 0.10092219710350037, 0.10092221200466156, 0.06468797475099564, 0.06468788534402847, 0.06468787044286728, 0.06468798965215683, 0.10092215240001678, 0.06468787044286728, 0.0646880492568016, 0.0646880567073822, 0.0646880567073822, 0.06468787044286728, 0.06468789279460907, 0.10092216730117798, 0.09151660650968552, 0.10092347860336304, 0.10256386548280716, 0.10098075121641159, 0.09151975810527802, 0.09159781783819199, 0.08206634968519211, 0.06471677869558334, 0.0647139698266983, 0.1049836277961731, 0.09737714380025864, 0.09737714380025864, 0.08824972808361053, 0.09737653285264969, 0.09737704694271088, 0.0882285088300705, 0.07911267876625061, 0.07912418246269226, 0.062379490584135056, 0.062358926981687546, 0.06235545501112938, 0.062379419803619385, 0.06237940490245819, 0.062379490584135056, 0.062379490584135056, 0.06235630065202713, 0.0791240930557251, 0.062379419803619385, 0.06237949803471565, 0.09738051891326904, 0.06237949803471565, 0.062379419803619385, 0.062386542558670044, 0.06237940490245819, 0.053253836929798126, 0.05325382575392723, 0.05325381085276604, 0.05325376242399216, 0.053253669291734695, 0.06235635653138161, 0.06237949803471565, 0.07912380993366241, 0.11413266509771347, 0.06236409395933151, 0.07912418246269226, 0.09738361090421677, 0.08824536204338074, 0.062390636652708054, 0.06238758936524391, 0.06238596886396408, 0.06238558515906334, 0.06238233298063278, 0.06238149479031563, 0.06237950921058655, 0.06237950921058655, 0.06237949803471565, 0.06237948685884476, 0.1629534363746643, 0.08669986575841904, 0.10315152257680893, 0.07773327082395554, 0.07773391157388687, 0.08446678519248962, 0.11211755126714706, 0.06128323823213577, 0.061282940208911896, 0.061282940208911896, 0.061282940208911896, 0.061282895505428314, 0.061282698065042496, 0.061282455921173096, 0.09566575288772583, 0.06128295511007309, 0.0612826831638813, 0.06128325313329697, 0.12108363211154938, 0.05799659341573715, 0.06128307431936264, 0.06128299981355667, 0.05799660459160805, 0.0612829253077507, 0.09566566348075867, 0.12856920063495636, 0.061282698065042496, 0.061282988637685776, 0.06128325313329697, 0.06128306686878204, 0.121083565056324, 0.07773373275995255, 0.08669981360435486, 0.07773391157388687, 0.06632440537214279, 0.06507863849401474, 0.06279890239238739, 0.061302486807107925, 0.061297498643398285, 0.0612972155213356, 0.06128325313329697, 0.06128325313329697, 0.06128325313329697, 0.06128325313329697, 0.061283260583877563, 0.06128324940800667, 0.09515105187892914, 0.09515098482370377, 0.10443580895662308, 0.10259642452001572, 0.09515100717544556, 0.07732997834682465, 0.060953542590141296, 0.0609535314142704, 0.060953289270401, 0.06095310300588608, 0.06095309555530548, 0.06095312535762787, 0.08623301982879639, 0.0773157924413681, 0.060953233391046524, 0.09515028446912766, 0.06095330789685249, 0.06095336005091667, 0.09515119343996048, 0.060953520238399506, 0.060953401029109955, 0.06095307320356369, 0.060953401029109955, 0.060953542590141296, 0.06095338985323906, 0.060953203588724136, 0.060953497886657715, 0.052036579698324203, 0.05203653499484062, 0.05203644931316376, 0.06095309183001518, 0.06095336005091667, 0.06095337122678757, 0.07731544971466064, 0.07731557637453079, 0.060988109558820724, 0.060974497348070145, 0.06096869707107544, 0.060968220233917236, 0.06096820905804634, 0.06096813082695007, 0.060967981815338135, 0.06096585467457771, 0.06096561253070831, 0.060961123555898666, 0.06095355004072189, 0.06095356121659279, 0.060953542590141296, 0.060953542590141296, 0.060953542590141296, 0.060953520238399506, 0.08569063246250153, 0.06962892413139343, 0.06962888687849045, 0.08566928654909134, 0.06962889432907104, 0.09239611774682999, 0.05489320680499077, 0.05489320680499077, 0.054884761571884155, 0.05489320680499077, 0.05488233640789986, 0.05490961670875549, 0.05489320680499077, 0.05488632246851921, 0.05487886443734169, 0.06962888687849045, 0.05488454923033714, 0.0548827089369297, 0.05489320680499077, 0.05488460883498192, 0.06962890177965164, 0.07765982300043106, 0.04686298221349716, 0.054896410554647446, 0.05488398298621178, 0.054884228855371475, 0.04686283692717552, 0.11692359298467636, 0.0548819936811924, 0.05489550530910492, 0.08566981554031372, 0.07765020430088043, 0.0923960879445076, 0.08569007366895676, 0.06967860460281372, 0.0776597112417221, 0.06962890177965164, 0.07009444385766983, 0.055334463715553284, 0.054906103760004044, 0.05489911511540413, 0.05489734187722206, 0.05489444360136986, 0.05489320680499077, 0.07913919538259506, 0.07913918048143387, 0.10017822682857513, 0.07913916558027267, 0.07913920283317566, 0.07913918048143387, 0.07913916558027267, 0.07176408916711807, 0.10763425379991531, 0.05072607472538948, 0.05072597414255142, 0.05072595924139023, 0.05071455240249634, 0.07913916558027267, 0.05072610452771187, 0.050725966691970825, 0.07176411896944046, 0.05072610452771187, 0.050726089626550674, 0.05072609707713127, 0.05072610825300217, 0.05072609707713127, 0.05071376636624336, 0.050712950527668, 0.043305084109306335, 0.043305013328790665, 0.07918550819158554, 0.04330513998866081, 0.05072609707713127, 0.04330514371395111, 0.07919707894325256, 0.05072597414255142, 0.07918564230203629, 0.06434252113103867, 0.07190920412540436, 0.07195485383272171, 0.05077207833528519, 0.050740063190460205, 0.05072609707713127, 0.050726089626550674, 0.05072610825300217, 0.05072609707713127, 0.05072609707713127, 0.05072610825300217, 0.05072609707713127, 0.050726089626550674, 0.050726089626550674], \"Total\": [3.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 5.0, 5.0, 2.9400594234466553, 2.6394784450531006, 2.9222288131713867, 4.6011061668396, 2.428635358810425, 2.6805689334869385, 3.6076786518096924, 3.337857961654663, 2.3739278316497803, 2.3739278316497803, 3.7202844619750977, 2.734041690826416, 3.6167004108428955, 2.911818265914917, 2.675696849822998, 2.7251498699188232, 2.73447847366333, 3.1893324851989746, 3.600323438644409, 2.9658970832824707, 2.217893600463867, 2.2179880142211914, 2.2179880142211914, 3.3996753692626953, 2.5252766609191895, 2.6832878589630127, 3.083486795425415, 2.842789649963379, 2.251680374145508, 5.353796005249023, 3.4925105571746826, 4.370523452758789, 2.897814989089966, 3.546313762664795, 3.509721040725708, 6.188905715942383, 3.861905336380005, 3.9359781742095947, 3.9768292903900146, 3.6724023818969727, 3.550170660018921, 4.917327880859375, 3.7577266693115234, 3.197826623916626, 4.87222146987915, 3.121593713760376, 3.7372946739196777, 3.621938467025757, 4.469616889953613, 5.222769737243652, 2.707817316055298, 2.705998420715332, 2.5290536880493164, 5.4540205001831055, 2.268662929534912, 3.758967638015747, 2.2238152027130127, 3.102496862411499, 2.318422317504883, 2.0978951454162598, 2.0976810455322266, 2.0974230766296387, 3.2762954235076904, 3.769456148147583, 2.235679864883423, 2.259953022003174, 2.951530933380127, 2.313255786895752, 2.1990256309509277, 3.03725004196167, 3.3747057914733887, 2.574134349822998, 2.3550877571105957, 1.9269330501556396, 1.9269330501556396, 3.046729803085327, 4.1859846115112305, 6.188905715942383, 5.905041217803955, 3.5148119926452637, 3.4042298793792725, 5.353796005249023, 4.11343240737915, 3.382220506668091, 3.6720666885375977, 3.5148119926452637, 2.1116445064544678, 2.1355974674224854, 1.942330241203308, 3.2468037605285645, 2.113647222518921, 3.218118667602539, 1.9109745025634766, 2.216916561126709, 2.225579261779785, 2.5411856174468994, 2.211806297302246, 2.300351858139038, 2.3031039237976074, 1.8235106468200684, 1.823431134223938, 1.82341468334198, 2.5018584728240967, 3.6720666885375977, 2.923936605453491, 2.3520050048828125, 1.8704512119293213, 1.897033452987671, 3.417025566101074, 2.5984947681427, 2.6046526432037354, 2.2666571140289307, 1.9458744525909424, 1.9547884464263916, 2.6570637226104736, 3.75575852394104, 2.4867231845855713, 3.70786714553833, 2.9019343852996826, 3.0007741451263428, 3.7868640422821045, 3.989928960800171, 3.2031514644622803, 3.2762954235076904, 3.3007922172546387, 4.917327880859375, 3.9365174770355225, 2.0178308486938477, 3.2043614387512207, 2.138573408126831, 2.092428684234619, 2.3568785190582275, 2.391551971435547, 1.9097793102264404, 2.4021522998809814, 1.9110866785049438, 1.9911646842956543, 1.8534178733825684, 3.020026206970215, 2.4587337970733643, 2.454136371612549, 3.58388352394104, 2.999833345413208, 2.1019222736358643, 1.825251579284668, 1.8017003536224365, 2.2971293926239014, 1.8028042316436768, 2.5512266159057617, 3.546313762664795, 1.92121160030365, 1.952206015586853, 2.4777841567993164, 2.497392177581787, 3.428130626678467, 2.0119566917419434, 2.022418737411499, 3.14172101020813, 2.749302387237549, 4.370523452758789, 2.4298312664031982, 2.7641918659210205, 3.1241614818573, 3.3007922172546387, 3.4195752143859863, 3.8533363342285156, 5.905041217803955, 3.1383886337280273, 6.188905715942383, 2.278014898300171, 3.359011173248291, 1.8859320878982544, 2.923673152923584, 3.3335490226745605, 2.2745120525360107, 1.9674948453903198, 2.528069019317627, 2.6373507976531982, 1.807624101638794, 2.9019343852996826, 2.252859354019165, 1.7858288288116455, 1.8671027421951294, 1.8733292818069458, 2.54750657081604, 2.225228786468506, 1.939566969871521, 1.9413604736328125, 1.9758312702178955, 1.8325220346450806, 2.0383613109588623, 2.040719747543335, 2.397852897644043, 2.063786506652832, 2.6137635707855225, 2.8137221336364746, 1.733627200126648, 2.151050567626953, 1.7619518041610718, 2.803208827972412, 4.469616889953613, 3.1936492919921875, 3.020026206970215, 3.14172101020813, 2.763904571533203, 2.859199285507202, 5.4540205001831055, 4.11343240737915, 3.371318817138672, 6.188905715942383, 4.369935512542725, 3.261319160461426, 2.3743131160736084, 3.042356252670288, 3.371318817138672, 3.0007741451263428, 2.52287220954895, 2.5781216621398926, 2.051999568939209, 2.6326944828033447, 1.9556142091751099, 2.103969097137451, 3.203336000442505, 2.437443971633911, 2.4782700538635254, 1.8384428024291992, 1.8406028747558594, 2.345665693283081, 1.8555525541305542, 2.5238819122314453, 1.8828204870224, 1.7570642232894897, 1.950822353363037, 1.970325231552124, 1.9803045988082886, 1.9851832389831543, 1.9934152364730835, 2.0106639862060547, 2.368422031402588, 2.03715181350708, 2.040719747543335, 2.9007816314697266, 2.2383406162261963, 3.0155045986175537, 3.7868640422821045, 5.222769737243652, 5.353796005249023, 5.4540205001831055, 3.8533363342285156, 2.7668745517730713, 2.797606945037842, 4.515429496765137, 2.7641918659210205, 4.1859846115112305, 2.216580629348755, 2.006366014480591, 2.0546224117279053, 2.067756414413452, 3.020026206970215, 2.2979698181152344, 2.1396684646606445, 2.6233720779418945, 1.7660150527954102, 1.765892744064331, 2.3065173625946045, 2.1515204906463623, 2.514220952987671, 1.899162769317627, 1.7424451112747192, 2.6241612434387207, 2.7981653213500977, 1.9792678356170654, 3.4195752143859863, 1.817875862121582, 2.0566418170928955, 2.8137221336364746, 2.081800699234009, 2.899864673614502, 1.9548289775848389, 1.974138855934143, 2.797606945037842, 2.2191109657287598, 2.2270724773406982, 1.827695608139038, 2.2724359035491943, 3.218118667602539, 2.286539316177368, 3.9365174770355225, 3.684805393218994, 4.917327880859375, 2.372589349746704, 5.353796005249023, 2.959110975265503, 2.701064348220825, 3.046729803085327, 3.6167004108428955, 2.643193483352661, 4.515429496765137, 3.3966548442840576, 4.369935512542725, 2.4281015396118164, 1.993784785270691, 2.124268054962158, 2.0081520080566406, 4.515429496765137, 1.7553728818893433, 2.2794384956359863, 2.286539316177368, 1.8247261047363281, 2.497392177581787, 1.8841410875320435, 1.9429197311401367, 2.643193483352661, 1.9871286153793335, 1.9928598403930664, 2.0349981784820557, 3.621938467025757, 2.1524980068206787, 2.1560757160186768, 2.333559036254883, 1.9663141965866089, 1.9663125276565552, 2.0091805458068848, 2.6137635707855225, 3.1266510486602783, 2.300564765930176, 2.107213020324707, 2.951530933380127, 2.335233688354492, 2.8003084659576416, 3.973663330078125, 5.905041217803955, 3.7372946739196777, 3.7868640422821045, 6.188905715942383, 3.7249011993408203, 2.4021522998809814, 5.222769737243652, 3.8533363342285156, 2.8955609798431396, 3.9768292903900146, 2.7482826709747314, 2.3490357398986816, 1.9921560287475586, 2.803208827972412, 3.3966548442840576, 1.8295801877975464, 2.0355334281921387, 1.9731041193008423, 2.8774280548095703, 2.3179140090942383, 2.9862985610961914, 2.3647868633270264, 1.7482566833496094, 3.3335490226745605, 2.455338716506958, 1.88077712059021, 1.8849977254867554, 1.908807635307312, 2.6650052070617676, 3.2681334018707275, 2.621274948120117, 2.1034841537475586, 1.9210485219955444, 2.633309841156006, 2.264394998550415, 1.852351188659668, 3.1266510486602783, 1.8763030767440796, 2.3100666999816895, 1.8764867782592773, 4.515429496765137, 2.116694450378418, 3.684805393218994, 3.0134947299957275, 6.188905715942383, 4.369935512542725, 3.600323438644409, 3.758967638015747, 3.7577266693115234, 2.767188549041748, 2.006772994995117, 1.7463630437850952, 3.989928960800171, 3.428130626678467, 1.730586051940918, 2.368422031402588, 2.514220952987671, 2.539047956466675, 2.587958335876465, 1.9088772535324097, 2.8063220977783203, 1.7893043756484985, 1.9957976341247559, 2.023362159729004, 1.867544174194336, 2.067436695098877, 1.6927907466888428, 4.1859846115112305, 2.1368370056152344, 2.140439748764038, 2.249643564224243, 3.973663330078125, 2.3602993488311768, 2.1735987663269043, 1.9534825086593628, 3.1097710132598877, 2.004672050476074, 2.3156843185424805, 2.3222060203552246, 1.658117651939392, 3.684805393218994, 3.4810891151428223, 4.917327880859375, 2.7482826709747314, 2.8187544345855713, 2.846163749694824, 2.897814989089966, 2.9862985610961914, 4.515429496765137, 4.11343240737915, 6.188905715942383, 3.467543601989746, 1.7874141931533813, 1.9565094709396362, 2.474539041519165, 1.7220295667648315, 1.722029447555542, 3.3112595081329346, 2.231471061706543, 1.806865930557251, 1.8409268856048584, 2.3990190029144287, 1.7669544219970703, 1.9670945405960083, 1.8371446132659912, 2.069732427597046, 2.0828840732574463, 2.8982958793640137, 1.766338586807251, 1.9928598403930664, 3.0031700134277344, 2.019683599472046, 2.2617106437683105, 1.897257924079895, 2.7482826709747314, 2.985327959060669, 1.9402471780776978, 2.239633560180664, 2.021355628967285, 2.9396770000457764, 2.081996202468872, 2.0826823711395264, 5.353796005249023, 3.9359781742095947, 2.814371347427368, 5.222769737243652, 3.3747057914733887, 2.9007816314697266, 3.75575852394104, 5.905041217803955, 3.2352406978607178, 6.188905715942383, 2.455338716506958, 1.817024827003479, 1.9244611263275146, 2.345665693283081, 1.7013370990753174, 1.7013369798660278, 1.8752679824829102, 1.7439320087432861, 2.3990190029144287, 1.8282805681228638, 1.99595308303833, 2.002347469329834, 2.026430368423462, 3.6724023818969727, 1.946211814880371, 2.162923574447632, 2.231471061706543, 3.382220506668091, 2.3143272399902344, 1.6434956789016724, 1.6434955596923828, 1.6434955596923828, 1.6434954404830933, 1.6434952020645142, 1.643494963645935, 2.587958335876465, 1.677866816520691, 1.682559847831726, 1.6825593709945679, 1.6840465068817139, 1.6991965770721436, 2.4410898685455322, 2.4502413272857666, 4.1859846115112305, 2.6156935691833496, 3.0155045986175537, 3.0403292179107666, 3.0658388137817383, 3.75575852394104, 4.515429496765137, 3.4925105571746826, 5.905041217803955, 3.546313762664795, 4.370523452758789, 4.917327880859375, 1.8513381481170654, 2.03883957862854, 1.6970824003219604, 1.7632704973220825, 1.8376542329788208, 1.8857684135437012, 1.9668281078338623, 2.5057525634765625, 1.8120499849319458, 2.0658416748046875, 2.1305785179138184, 2.1336004734039307, 1.9957976341247559, 2.2094058990478516, 1.8240621089935303, 1.8301076889038086, 2.0612707138061523, 2.299942970275879, 2.321470260620117, 2.1234183311462402, 2.1291823387145996, 2.1493899822235107, 2.7538225650787354, 3.0031700134277344, 1.6413739919662476, 1.641373872756958, 1.6413739919662476, 1.6413719654083252, 1.6413719654083252, 1.6854945421218872, 3.417025566101074, 2.7797398567199707, 2.9019343852996826, 3.428130626678467, 2.985327959060669, 2.637596607208252, 3.4810891151428223, 5.222769737243652, 3.4925105571746826, 3.6724023818969727, 5.353796005249023, 3.70786714553833, 3.58388352394104, 1.6954046487808228, 1.7164411544799805, 2.621274948120117, 1.8301076889038086, 1.6667906045913696, 1.7000473737716675, 1.7009785175323486, 1.7668527364730835, 2.985327959060669, 1.8395586013793945, 2.4410898685455322, 2.0298123359680176, 1.640533685684204, 1.640533685684204, 1.640532374382019, 1.6405322551727295, 1.6405307054519653, 1.6405301094055176, 1.640529751777649, 1.6689841747283936, 1.668983817100525, 1.674721360206604, 1.6831287145614624, 1.7253692150115967, 1.730688452720642, 1.7392224073410034, 2.225228786468506, 3.973663330078125, 1.7753287553787231, 1.781327724456787, 2.32859468460083, 4.1859846115112305, 2.335233688354492, 2.366487741470337, 3.2681334018707275, 2.4501585960388184, 3.1893324851989746, 3.203336000442505, 2.6156935691833496, 2.6790895462036133, 2.6805689334869385, 4.917327880859375, 2.701064348220825, 3.5042996406555176, 2.8137221336364746, 3.684805393218994, 5.353796005249023, 3.758967638015747, 3.58388352394104, 2.9758617877960205, 2.3602993488311768, 2.8982958793640137, 1.8456968069076538, 1.819388747215271, 1.7418822050094604, 1.8644585609436035, 2.0074400901794434, 2.0701351165771484, 2.0734329223632812, 2.0762295722961426, 3.3996753692626953, 1.6898032426834106, 1.6981974840164185, 1.9119963645935059, 1.790412425994873, 3.03725004196167, 2.7704639434814453, 2.923673152923584, 2.9798665046691895, 2.8137221336364746, 3.973663330078125, 1.6377297639846802, 1.6377297639846802, 1.6377296447753906, 1.6377296447753906, 1.6377296447753906, 2.103969097137451, 2.6790895462036133, 1.7377653121948242, 1.7489339113235474, 2.4777841567993164, 3.371318817138672, 2.8909125328063965, 2.437443971633911, 5.905041217803955, 2.951815366744995, 2.6241612434387207, 4.369935512542725, 3.9359781742095947, 3.509721040725708, 1.7878022193908691, 2.8409597873687744, 1.7191346883773804, 3.0403292179107666, 1.7952475547790527, 1.8135082721710205, 2.7221827507019043, 1.8741406202316284, 2.0805318355560303, 2.146986961364746, 2.3602993488311768, 3.3335490226745605, 3.197826623916626, 1.6360878944396973, 1.6360878944396973, 1.6360877752304077, 1.6360877752304077, 1.6360877752304077, 1.6360877752304077, 1.6360876560211182, 1.636087417602539, 1.6360810995101929, 1.6360793113708496, 1.6360968351364136, 2.3448269367218018, 1.674566626548767, 1.6751517057418823, 2.1291823387145996, 1.6812340021133423, 1.6865041255950928, 2.7797398567199707, 3.9365174770355225, 2.6182548999786377, 3.2352406978607178, 3.258141279220581, 2.755958080291748, 5.4540205001831055, 3.1266510486602783, 2.232603073120117, 1.9088772535324097, 2.549713611602783, 1.7822940349578857, 1.9487462043762207, 3.6167004108428955, 2.525312900543213, 2.344404458999634, 2.3615150451660156, 1.686103105545044, 1.6861051321029663, 1.7366315126419067, 1.943554401397705, 1.8395586013793945, 2.343928813934326, 2.4044809341430664, 2.000992774963379, 2.7140793800354004, 1.635880947113037, 1.6358814239501953, 1.6784757375717163, 2.1336004734039307, 2.430482864379883, 1.7460289001464844, 1.7568867206573486, 1.7724547386169434, 1.7734326124191284, 3.2468037605285645, 1.7771614789962769, 1.7895915508270264, 1.790412425994873, 2.2794384956359863, 1.8191986083984375, 1.8257455825805664, 1.8465516567230225, 1.8500044345855713, 1.8533064126968384, 3.9768292903900146, 2.530345916748047, 2.951530933380127, 3.4810891151428223, 3.7202844619750977, 2.7197928428649902, 4.370523452758789, 2.8909125328063965, 2.9107935428619385, 3.7577266693115234, 3.077820301055908, 3.382220506668091, 3.70786714553833, 1.9289026260375977, 3.4925105571746826, 3.03725004196167, 1.7642461061477661, 1.8870126008987427, 2.000093698501587, 1.8240621089935303, 1.6956313848495483, 2.124293565750122, 1.9298244714736938, 2.138573408126831, 1.8247261047363281, 2.8982958793640137, 2.9758617877960205, 2.1362502574920654, 2.23809814453125, 1.6326137781143188, 1.6326137781143188, 1.6326133012771606, 1.632613182067871, 1.6326156854629517, 1.6326160430908203, 1.6326161623001099, 2.497392177581787, 1.663404107093811, 2.151594400405884, 1.6986002922058105, 1.7007834911346436, 2.66046404838562, 1.7113538980484009, 1.7138898372650146, 1.6389763355255127, 2.1944239139556885, 2.7948737144470215, 3.4042298793792725, 3.9359781742095947, 2.7797398567199707, 2.797606945037842, 3.371318817138672, 2.923936605453491, 3.509721040725708, 3.70786714553833, 5.905041217803955, 3.4810891151428223, 3.8533363342285156, 1.8114662170410156, 1.8183642625808716, 2.574402332305908, 2.1618196964263916, 1.7091925144195557, 1.6524074077606201, 2.7704639434814453, 2.8063220977783203, 2.148865222930908, 2.2191109657287598, 2.0466086864471436, 2.065708637237549, 1.852351188659668, 2.3773114681243896, 2.4410898685455322, 1.6308060884475708, 1.6308060884475708, 1.6308060884475708, 1.6308060884475708, 1.6308060884475708, 1.6308058500289917, 1.6308053731918335, 1.6576236486434937, 1.6640849113464355, 1.6812340021133423, 2.643193483352661, 2.4326889514923096, 1.736254334449768, 1.7546236515045166, 2.239633560180664, 3.5042996406555176, 2.985327959060669, 3.5148119926452637, 2.437443971633911, 2.474539041519165, 5.4540205001831055, 2.4777841567993164, 3.5055043697357178, 4.917327880859375, 4.11343240737915, 3.1097710132598877, 6.188905715942383, 2.227156400680542, 2.1515204906463623, 1.705777883529663, 2.32859468460083, 3.077820301055908, 2.2979698181152344, 1.9058595895767212, 2.4276115894317627, 3.102496862411499, 1.6306856870651245, 1.630685567855835, 1.6306854486465454, 1.630684733390808, 2.985327959060669, 1.656091570854187, 1.6632273197174072, 2.8252408504486084, 1.6940919160842896, 1.7046475410461426, 1.7091925144195557, 1.7119591236114502, 1.7175260782241821, 1.7535343170166016, 2.525312900543213, 1.7879027128219604, 3.0134947299957275, 1.8278179168701172, 1.6189450025558472, 1.6189450025558472, 1.6189448833465576, 3.70786714553833, 1.9403537511825562, 4.469616889953613, 2.9758617877960205, 3.7249011993408203, 3.6076786518096924, 2.9007816314697266, 3.371318817138672, 3.5042996406555176, 5.905041217803955, 5.222769737243652, 2.323606252670288, 3.083486795425415, 2.8909125328063965, 2.923936605453491, 3.3335490226745605, 2.151594400405884, 1.7180782556533813, 1.6739370822906494, 1.708631157875061, 2.53175950050354, 1.9402471780776978, 1.7695682048797607, 1.6509166955947876, 1.946211814880371, 2.081996202468872, 1.8722856044769287, 1.9100300073623657, 2.0091805458068848, 1.6297979354858398, 1.6297979354858398, 1.6297978162765503, 1.6297969818115234, 1.6297965049743652, 1.6297963857650757, 2.0913209915161133, 1.6508276462554932, 1.66690993309021, 3.989928960800171, 1.6854945421218872, 1.7026280164718628, 2.6650052070617676, 1.7199524641036987, 1.7642461061477661, 2.1667678356170654, 1.7842172384262085, 2.794750213623047, 2.643193483352661, 2.9758617877960205, 3.0031700134277344, 3.2031514644622803, 4.1859846115112305, 2.7981653213500977, 4.369935512542725, 2.7668745517730713, 2.8909125328063965, 3.861905336380005, 3.3747057914733887, 3.7577266693115234, 4.917327880859375, 1.7816541194915771, 2.4867231845855713, 1.6708766222000122, 3.1097710132598877, 2.1234183311462402, 2.0151822566986084, 1.7365394830703735, 3.046729803085327, 2.1515204906463623, 1.9860262870788574, 2.4782700538635254, 1.6282678842544556, 1.6282678842544556, 1.628267765045166, 1.628267765045166, 1.628267765045166, 1.6282676458358765, 1.6282676458358765, 1.628267526626587, 1.6282669305801392, 1.6565937995910645, 2.1102511882781982, 1.6784757375717163, 2.1291823387145996, 1.6831287145614624, 1.690975308418274, 1.7184240818023682, 1.726797103881836, 1.7366315126419067, 1.7439320087432861, 2.5093204975128174, 2.8137221336364746, 2.8280107975006104, 3.550170660018921, 2.7221827507019043, 4.370523452758789, 3.382220506668091, 4.917327880859375, 3.973663330078125, 3.989928960800171, 3.1241614818573, 3.58388352394104, 3.8533363342285156, 2.132779359817505, 2.8982958793640137, 2.6233720779418945, 2.25114107131958, 2.497392177581787, 1.8388041257858276, 1.9871286153793335, 2.0479466915130615, 2.170044183731079, 1.9456676244735718, 2.0015854835510254, 1.8857684135437012, 2.5494754314422607, 2.5512266159057617, 2.5093204975128174, 2.4832074642181396, 1.624737024307251, 1.6247369050979614, 1.6247367858886719, 1.6247367858886719, 1.6501433849334717, 2.1234183311462402, 1.6751517057418823, 2.1291823387145996, 1.6825593709945679, 1.682559847831726, 1.6947212219238281, 1.6971797943115234, 1.7059602737426758, 1.7669544219970703, 1.7694573402404785, 2.763904571533203, 2.7668745517730713, 1.7734326124191284, 2.794750213623047, 2.839838743209839, 2.9007816314697266, 3.2468037605285645, 3.0134947299957275, 3.425053358078003, 3.58388352394104, 2.8909125328063965, 2.959110975265503, 3.0658388137817383, 5.905041217803955, 3.177485466003418, 3.7249011993408203, 2.9798665046691895, 1.6623270511627197, 2.0913209915161133, 1.784957766532898, 1.803566813468933, 1.8120499849319458, 1.823594570159912, 2.633309841156006, 2.03883957862854, 1.6239937543869019, 1.6239937543869019, 1.6239937543869019, 1.6239937543869019, 1.6239936351776123, 1.6989167928695679, 1.765228509902954, 2.2553863525390625, 1.7879027128219604, 2.286539316177368, 1.8119393587112427, 1.817875862121582, 1.8516179323196411, 1.8849977254867554, 1.6139987707138062, 1.6139987707138062, 1.6139987707138062, 1.6139987707138062, 1.6139987707138062, 1.6139987707138062, 1.6139987707138062, 1.6139987707138062, 1.8944618701934814, 1.9302480220794678, 2.549323558807373, 1.98224937915802, 1.9860262870788574, 2.0433168411254883, 2.0487308502197266, 3.077820301055908, 3.4042298793792725, 3.467543601989746, 3.428130626678467, 3.9365174770355225, 2.249643564224243, 2.6570637226104736, 3.6720666885375977, 2.39031982421875, 1.73086416721344, 1.921415090560913, 1.6582612991333008, 1.7582759857177734, 1.7765958309173584, 2.366487741470337, 1.9403537511825562, 1.9883465766906738, 1.6393189430236816, 1.6393189430236816, 2.8909125328063965, 2.2344272136688232, 2.3602993488311768, 2.140026330947876, 2.3702967166900635, 2.393866777420044, 2.3990190029144287, 2.486715316772461, 2.5252766609191895, 1.6219542026519775, 1.621954083442688, 1.621954083442688, 1.6473608016967773, 2.675696849822998, 1.7219915390014648, 1.7489339113235474, 1.772430419921875, 1.7778102159500122, 1.7778096199035645, 1.8106485605239868, 2.923936605453491, 2.7482826709747314, 3.1936492919921875, 3.3007922172546387, 3.989928960800171, 3.769456148147583, 3.9359781742095947, 3.9365174770355225, 3.0031700134277344, 2.794750213623047, 1.6632840633392334, 1.655657172203064, 1.6947212219238281, 1.6465296745300293, 2.1153810024261475, 2.123115062713623, 2.016930103302002, 1.8456968069076538, 1.9222220182418823, 1.6206594705581665, 1.6206786632537842, 1.620681881904602, 1.6822965145111084, 1.7044306993484497, 1.7395561933517456, 1.7395575046539307, 1.745030403137207, 2.2393510341644287, 1.7807292938232422, 1.803985357284546, 2.82053542137146, 1.8134844303131104, 1.815923810005188, 1.8313289880752563, 1.8472232818603516, 1.6115338802337646, 1.611533761024475, 1.611533761024475, 1.611533761024475, 1.6115336418151855, 1.8997042179107666, 1.920771598815918, 2.5057525634765625, 3.7868640422821045, 1.9413604736328125, 2.923936605453491, 5.222769737243652, 4.515429496765137, 2.430482864379883, 2.8774280548095703, 2.106525421142578, 2.3615150451660156, 2.899864673614502, 2.814371347427368, 1.9940658807754517, 1.9666661024093628, 3.371318817138672, 2.5984947681427, 3.1097710132598877, 1.908807635307312, 2.286539316177368, 1.7878022193908691, 1.86520516872406, 2.081996202468872, 2.846163749694824, 1.6200445890426636, 1.6200443506240845, 1.6200443506240845, 1.6200443506240845, 1.620044231414795, 1.6200441122055054, 1.6200437545776367, 2.5363845825195312, 1.662784457206726, 1.677866816520691, 1.6989167928695679, 3.359011173248291, 1.6330630779266357, 1.7389405965805054, 1.7489339113235474, 1.6583328247070312, 1.761549949645996, 2.7704639434814453, 3.7249011993408203, 1.790705919265747, 1.7989364862442017, 1.8223170042037964, 1.8370164632797241, 4.11343240737915, 2.4389610290527344, 3.2031514644622803, 3.2043614387512207, 3.621938467025757, 3.7372946739196777, 5.222769737243652, 2.167999744415283, 2.0675485134124756, 3.5055043697357178, 2.430482864379883, 2.0805037021636963, 3.6720666885375977, 2.0961902141571045, 2.1792876720428467, 2.148865222930908, 1.654057264328003, 1.6540571451187134, 1.850443959236145, 2.2383406162261963, 2.1387577056884766, 1.9626388549804688, 1.6198596954345703, 1.6198596954345703, 1.6198606491088867, 1.6198593378067017, 1.6198593378067017, 1.6198612451553345, 2.3222060203552246, 2.095851421356201, 1.674721360206604, 2.6326944828033447, 1.7009785175323486, 1.7199212312698364, 2.7140793800354004, 1.7553939819335938, 1.7603904008865356, 1.7861443758010864, 1.7905566692352295, 1.814264178276062, 1.8168883323669434, 1.831723928451538, 1.85224449634552, 1.6109427213668823, 1.6109427213668823, 1.6109426021575928, 1.8915880918502808, 1.894202709197998, 1.901265263557434, 2.7981653213500977, 3.758967638015747, 2.6241612434387207, 2.0519988536834717, 3.1241614818573, 2.5363845825195312, 2.3065173625946045, 3.5286355018615723, 2.0701351165771484, 2.069735288619995, 1.944515347480774, 3.4925105571746826, 2.9798665046691895, 2.1034181118011475, 2.5268547534942627, 2.0433168411254883, 2.1362502574920654, 2.015040636062622, 1.774033546447754, 1.63119637966156, 1.6658931970596313, 2.086301565170288, 1.9149818420410156, 2.5494754314422607, 1.6164606809616089, 1.6164606809616089, 1.6572545766830444, 1.663404107093811, 1.6940919160842896, 1.7065610885620117, 1.7221776247024536, 1.735319972038269, 1.7497445344924927, 2.25114107131958, 1.8056144714355469, 1.820552945137024, 1.827315330505371, 1.8339170217514038, 2.343928813934326, 2.621274948120117, 1.6084303855895996, 1.897033452987671, 1.9109745025634766, 1.9244611263275146, 1.6455416679382324, 4.11343240737915, 1.9340022802352905, 1.943703055381775, 3.258141279220581, 2.9758617877960205, 3.758967638015747, 3.550170660018921, 2.9658970832824707, 3.989928960800171, 3.9359781742095947, 4.917327880859375, 2.497392177581787, 2.5363845825195312, 2.7704639434814453, 2.2745120525360107, 3.2031514644622803, 2.2971293926239014, 1.6427288055419922, 1.6427289247512817, 2.177067279815674, 1.9930391311645508, 2.0330886840820312, 2.1524980068206787, 2.202430009841919, 2.063786506652832, 3.258141279220581, 1.6141234636306763, 1.6141233444213867, 1.6141233444213867, 1.6141257286071777, 2.52287220954895, 1.668983817100525, 1.6689841747283936, 2.3773114681243896, 1.7603116035461426, 1.7662031650543213, 1.7664872407913208, 1.8135082721710205, 1.8257455825805664, 1.8282805681228638, 1.8653552532196045, 1.606702446937561, 1.606702446937561, 2.951815366744995, 1.6393187046051025, 1.920300006866455, 1.6508276462554932, 3.083486795425415, 1.9487462043762207, 3.197826623916626, 2.6326944828033447, 4.6011061668396, 5.222769737243652, 2.9107935428619385, 5.905041217803955, 2.2191109657287598, 2.7080557346343994, 2.067676305770874, 2.299618721008301, 2.0189528465270996, 2.497392177581787, 2.4326889514923096, 2.7789649963378906, 2.4501585960388184], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic21\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic22\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic23\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic24\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic25\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic26\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic27\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic28\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic29\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\", \"Topic30\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.5640997886657715, -6.783400058746338, -6.709499835968018, -6.306300163269043, -6.973299980163574, -6.877999782562256, -6.592299938201904, -6.677000045776367, -7.029099941253662, -7.029099941253662, -6.58489990234375, -6.928400039672852, -6.658899784088135, -6.8902997970581055, -6.984499931335449, -6.972700119018555, -6.973299980163574, -6.831299781799316, -6.714900016784668, -6.916100025177002, -7.207799911499023, -7.207799911499023, -7.207799911499023, -6.782899856567383, -7.089000225067139, -7.02869987487793, -6.890399932861328, -6.972400188446045, -7.206999778747559, -6.341700077056885, -6.77400016784668, -6.591300010681152, -6.972799777984619, -6.808899879455566, -6.830900192260742, -6.433899879455566, -6.795199871063232, -6.831399917602539, -6.83050012588501, -6.8780999183654785, -6.890699863433838, -6.836100101470947, -6.931099891662598, -6.95359992980957, -5.588500022888184, -6.218299865722656, -6.080599784851074, -6.197800159454346, -6.032299995422363, -5.878399848937988, -6.584799766540527, -6.606599807739258, -6.74399995803833, -6.027900218963623, -6.93310022354126, -6.446899890899658, -6.989799976348877, -6.719299793243408, -7.016900062561035, -7.167699813842773, -7.1682000160217285, -7.168700218200684, -6.74429988861084, -6.627900123596191, -7.167900085449219, -7.167699813842773, -6.9182000160217285, -7.168099880218506, -7.23960018157959, -6.969799995422363, -6.885700225830078, -7.168499946594238, -7.266900062561035, -7.475399971008301, -7.475399971008301, -7.049099922180176, -6.789700031280518, -6.532800197601318, -6.630000114440918, -6.970799922943115, -6.9893999099731445, -6.929500102996826, -7.058599948883057, -7.0903000831604, -7.167699813842773, -6.11870002746582, -6.937600135803223, -6.939599990844727, -7.116799831390381, -6.626200199127197, -7.116799831390381, -6.6996002197265625, -7.2652997970581055, -7.116799831390381, -7.1168999671936035, -6.997600078582764, -7.190199851989746, -7.187600135803223, -7.187600135803223, -7.4232001304626465, -7.423799991607666, -7.423900127410889, -7.116600036621094, -6.7382001876831055, -6.967700004577637, -7.188000202178955, -7.4232001304626465, -7.4232001304626465, -6.836999893188477, -7.116300106048584, -7.116799831390381, -7.2652997970581055, -7.423799991607666, -7.4232001304626465, -7.116399765014648, -6.786300182342529, -7.188300132751465, -6.9390997886657715, -7.116300106048584, -7.1168999671936035, -6.997200012207031, -6.997000217437744, -7.116099834442139, -7.116600036621094, -7.116600036621094, -7.115900039672852, -7.18779993057251, -6.86929988861084, -6.454599857330322, -6.875899791717529, -6.935299873352051, -6.871300220489502, -6.86929988861084, -7.103899955749512, -6.881400108337402, -7.1107001304626465, -7.105100154876709, -7.252399921417236, -6.77400016784668, -6.984899997711182, -6.98829984664917, -6.64739990234375, -6.827400207519531, -7.193299770355225, -7.335599899291992, -7.411200046539307, -7.17549991607666, -7.417799949645996, -7.105199813842773, -6.787199974060059, -7.417699813842773, -7.410999774932861, -7.184800148010254, -7.179900169372559, -6.877600193023682, -7.417799949645996, -7.4182000160217285, -6.987100124359131, -7.121300220489502, -6.732500076293945, -7.252399921417236, -7.1753997802734375, -7.103899955749512, -7.104000091552734, -7.125999927520752, -7.125100135803223, -7.103700160980225, -7.1753997802734375, -7.175000190734863, -6.861400127410889, -6.512700080871582, -7.096499919891357, -6.672100067138672, -6.5920000076293945, -6.977399826049805, -7.168099880218506, -6.918000221252441, -6.918000221252441, -7.328199863433838, -6.871300220489502, -7.168099880218506, -7.403600215911865, -7.4028000831604, -7.403500080108643, -7.096799850463867, -7.245100021362305, -7.4028000831604, -7.403600215911865, -7.4028000831604, -7.502299785614014, -7.403500080108643, -7.40369987487793, -7.244999885559082, -7.403600215911865, -7.168099880218506, -7.0970001220703125, -7.611100196838379, -7.4028000831604, -7.611100196838379, -7.164999961853027, -6.718299865722656, -7.096499919891357, -7.168099880218506, -7.167300224304199, -7.244800090789795, -7.244100093841553, -7.166800022125244, -7.244800090789795, -7.328800201416016, -7.402699947357178, -7.402699947357178, -5.55049991607666, -6.255899906158447, -6.553800106048584, -6.482500076293945, -6.673699855804443, -6.862800121307373, -6.86329984664917, -7.098199844360352, -6.863699913024902, -7.169300079345703, -7.097700119018555, -6.767600059509277, -7.098299980163574, -7.098299980163574, -7.405300140380859, -7.404799938201904, -7.169400215148926, -7.405200004577637, -7.097899913787842, -7.405300140380859, -7.502900123596191, -7.404799938201904, -7.405200004577637, -7.405200004577637, -7.4045000076293945, -7.405200004577637, -7.405200004577637, -7.246799945831299, -7.405200004577637, -7.4045000076293945, -7.097400188446045, -7.329100131988525, -7.16949987411499, -7.097700119018555, -6.978700160980225, -7.097700119018555, -7.097499847412109, -7.245800018310547, -7.32919979095459, -7.329100131988525, -7.246099948883057, -7.398900032043457, -7.402599811553955, -6.368899822235107, -7.090099811553955, -7.089799880981445, -7.0894999504089355, -6.711699962615967, -7.0894999504089355, -7.163099765777588, -6.9721999168396, -7.396599769592285, -7.39739990234375, -7.161300182342529, -7.240600109100342, -7.0894999504089355, -7.397500038146973, -7.4953999519348145, -7.090099811553955, -7.033599853515625, -7.396599769592285, -6.855599880218506, -7.4953999519348145, -7.396599769592285, -7.0894999504089355, -7.396999835968018, -7.0894999504089355, -7.4953999519348145, -7.494999885559082, -7.160999774932861, -7.39739990234375, -7.397299766540527, -7.6041998863220215, -7.396900177001953, -7.089799880981445, -7.396599769592285, -7.160999774932861, -7.2378997802734375, -7.161300182342529, -7.396599769592285, -7.396500110626221, -7.396500110626221, -7.396500110626221, -7.396599769592285, -7.396599769592285, -7.396599769592285, -7.396599769592285, -6.306600093841553, -6.21999979019165, -6.8454999923706055, -7.08050012588501, -7.0802001953125, -7.151500225067139, -6.438700199127197, -7.387199878692627, -7.152900218963623, -7.151500225067139, -7.387700080871582, -7.0802001953125, -7.387700080871582, -7.387199878692627, -7.080100059509277, -7.387700080871582, -7.38730001449585, -7.387199878692627, -6.841599941253662, -7.387199878692627, -7.387700080871582, -7.312699794769287, -7.484600067138672, -7.484600067138672, -7.485599994659424, -7.234000205993652, -7.08050012588501, -7.387700080871582, -7.485599994659424, -7.1519999504089355, -7.38700008392334, -7.234000205993652, -6.960999965667725, -6.701600074768066, -7.147799968719482, -7.151599884033203, -7.234099864959717, -7.317800045013428, -7.384500026702881, -7.383999824523926, -7.385900020599365, -7.386600017547607, -7.38700008392334, -7.38700008392334, -6.0980000495910645, -6.655200004577637, -6.496099948883057, -6.401700019836426, -7.079899787902832, -7.079699993133545, -7.149600028991699, -6.845600128173828, -7.079699993133545, -6.84499979019165, -7.079599857330322, -7.386600017547607, -6.749499797821045, -7.078999996185303, -7.385200023651123, -7.385200023651123, -7.386600017547607, -7.090099811553955, -6.900000095367432, -7.150599956512451, -7.386600017547607, -7.48360013961792, -7.227499961853027, -7.38700008392334, -7.593100070953369, -7.078199863433838, -7.592800140380859, -7.385200023651123, -7.593200206756592, -6.719799995422363, -7.4842000007629395, -7.026500225067139, -7.2164998054504395, -6.703100204467773, -6.9878997802734375, -7.226500034332275, -7.385900020599365, -7.386099815368652, -7.38640022277832, -7.068299770355225, -7.300000190734863, -6.490799903869629, -6.689899921417236, -7.37529993057251, -7.068299770355225, -7.065700054168701, -7.066699981689453, -7.068299770355225, -7.37529993057251, -7.01230001449585, -7.474400043487549, -7.375100135803223, -7.37529993057251, -7.473700046539307, -7.37529993057251, -7.582900047302246, -6.691999912261963, -7.37529993057251, -7.37529993057251, -7.37529993057251, -6.842700004577637, -7.37529993057251, -7.473700046539307, -7.582900047302246, -7.139699935913086, -7.587800025939941, -7.473700046539307, -7.47790002822876, -7.820700168609619, -7.068299770355225, -7.143799781799316, -6.889100074768066, -7.37529993057251, -7.37529993057251, -7.37529993057251, -7.37529993057251, -7.37529993057251, -7.300000190734863, -7.374499797821045, -7.37529993057251, -7.37529993057251, -7.076600074768066, -7.064499855041504, -6.886099815368652, -7.371500015258789, -7.371500015258789, -6.718500137329102, -7.140200138092041, -7.371500015258789, -7.371500015258789, -7.136199951171875, -7.469900131225586, -7.371500015258789, -7.469799995422363, -7.371500015258789, -7.371500015258789, -7.063600063323975, -7.579500198364258, -7.469600200653076, -7.064599990844727, -7.469900131225586, -7.371500015258789, -7.579100131988525, -7.212800025939941, -7.135700225830078, -7.579500198364258, -7.470200061798096, -7.57859992980957, -7.213200092315674, -7.5792999267578125, -7.579400062561035, -6.886000156402588, -7.135700225830078, -7.371099948883057, -7.062900066375732, -7.296800136566162, -7.371500015258789, -7.295300006866455, -7.212500095367432, -7.371300220489502, -7.371500015258789, -7.468200206756592, -6.820199966430664, -7.126200199127197, -6.935699939727783, -7.361800193786621, -7.361800193786621, -7.286499977111816, -7.361800193786621, -7.054800033569336, -7.361800193786621, -7.361800193786621, -7.361800193786621, -7.361800193786621, -6.820199966430664, -7.460299968719482, -7.361800193786621, -7.361800193786621, -7.054699897766113, -7.45989990234375, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.361800193786621, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.807199954986572, -7.460400104522705, -7.46019983291626, -6.997300148010254, -7.460299968719482, -7.361800193786621, -7.361800193786621, -7.361800193786621, -7.286399841308594, -7.203199863433838, -7.361800193786621, -7.054800033569336, -7.361100196838379, -7.361400127410889, -7.361700057983398, -7.051400184631348, -7.1230998039245605, -7.35860013961792, -7.358500003814697, -7.358399868011475, -7.356400012969971, -7.358399868011475, -7.122799873352051, -7.456900119781494, -7.35860013961792, -7.35860013961792, -7.35860013961792, -7.4567999839782715, -7.35860013961792, -7.565999984741211, -7.565999984741211, -7.4567999839782715, -7.358399868011475, -7.358500003814697, -7.4567999839782715, -7.456900119781494, -7.4567999839782715, -7.282899856567383, -7.19950008392334, -7.803699970245361, -7.803699970245361, -7.803699970245361, -7.803800106048584, -7.803800106048584, -7.804100036621094, -7.122799873352051, -7.35860013961792, -7.4567999839782715, -7.35860013961792, -7.4567999839782715, -7.565999984741211, -7.456900119781494, -7.357800006866455, -7.456699848175049, -7.456600189208984, -7.456699848175049, -7.4567999839782715, -7.4567999839782715, -7.352499961853027, -7.352200031280518, -7.056600093841553, -7.452000141143799, -7.559800148010254, -7.560100078582764, -7.559800148010254, -7.559800148010254, -7.056600093841553, -7.559800148010254, -7.276899814605713, -7.559800148010254, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.797699928283691, -7.797800064086914, -7.797800064086914, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.797599792480469, -7.561500072479248, -6.989200115203857, -7.797800064086914, -7.797900199890137, -7.559800148010254, -7.057300090789795, -7.559999942779541, -7.559899806976318, -7.3520002365112305, -7.559500217437744, -7.4506001472473145, -7.450799942016602, -7.559899806976318, -7.559800148010254, -7.559899806976318, -7.276800155639648, -7.559700012207031, -7.4506001472473145, -7.559800148010254, -7.450500011444092, -7.450399875640869, -7.558499813079834, -7.559700012207031, -7.559800148010254, -6.181700229644775, -6.207099914550781, -6.813199996948242, -6.870100021362305, -7.047999858856201, -7.047999858856201, -7.047999858856201, -7.047999858856201, -7.047999858856201, -7.047999858856201, -6.623199939727783, -7.3541998863220215, -7.357100009918213, -7.278800010681152, -7.3541998863220215, -6.86929988861084, -7.047999858856201, -7.047999858856201, -7.047999858856201, -7.119500160217285, -6.869900226593018, -7.799499988555908, -7.799499988555908, -7.799499988555908, -7.799499988555908, -7.799499988555908, -7.563199996948242, -7.3541998863220215, -7.799499988555908, -7.799499988555908, -7.452600002288818, -7.278200149536133, -7.452600002288818, -7.561699867248535, -7.047399997711182, -7.452600002288818, -7.561699867248535, -7.3541998863220215, -7.452600002288818, -7.546000003814697, -7.048299789428711, -6.813600063323975, -7.354800224304199, -6.813600063323975, -7.354800224304199, -7.354800224304199, -7.047900199890137, -7.453199863433838, -7.354800224304199, -7.354800224304199, -7.354800224304199, -7.047800064086914, -7.119200229644775, -7.80019998550415, -7.80019998550415, -7.80019998550415, -7.80019998550415, -7.80019998550415, -7.80019998550415, -7.80019998550415, -7.80019998550415, -7.8003997802734375, -7.8003997802734375, -7.80049991607666, -7.453199863433838, -7.80019998550415, -7.80019998550415, -7.562399864196777, -7.80019998550415, -7.80019998550415, -7.354800224304199, -7.1194000244140625, -7.453199863433838, -7.355299949645996, -7.355299949645996, -7.562399864196777, -7.798399925231934, -7.799600124359131, -7.799900054931641, -7.800000190734863, -7.800000190734863, -7.800099849700928, -7.800099849700928, -7.800099849700928, -7.800099849700928, -6.323200225830078, -6.925600051879883, -7.351799964904785, -7.351900100708008, -7.450200080871582, -7.351799964904785, -7.5594000816345215, -7.3520002365112305, -7.351799964904785, -7.559100151062012, -7.276500225067139, -7.7972002029418945, -7.797299861907959, -7.7972002029418945, -7.559100151062012, -7.450200080871582, -7.7972002029418945, -7.7972002029418945, -7.7972002029418945, -7.797299861907959, -7.19320011138916, -7.7972002029418945, -7.7972002029418945, -7.7972002029418945, -7.558000087738037, -7.7972002029418945, -7.7972002029418945, -7.7972002029418945, -7.7972002029418945, -7.7972002029418945, -7.1930999755859375, -7.5594000816345215, -7.450099945068359, -7.351799964904785, -7.351799964904785, -7.5594000816345215, -7.351900100708008, -7.5594000816345215, -7.5594000816345215, -7.450200080871582, -7.5594000816345215, -7.5594000816345215, -7.55620002746582, -7.779699802398682, -7.79010009765625, -6.69789981842041, -7.3506999015808105, -7.3506999015808105, -7.3506999015808105, -7.449100017547607, -7.558199882507324, -7.3506999015808105, -7.449100017547607, -7.3506999015808105, -7.5584001541137695, -7.139999866485596, -7.115099906921387, -7.449100017547607, -7.449100017547607, -7.796000003814697, -7.796000003814697, -7.796000003814697, -7.796000003814697, -7.79610013961792, -7.79610013961792, -7.79610013961792, -7.382999897003174, -7.79610013961792, -7.558300018310547, -7.796000003814697, -7.79610013961792, -7.3506999015808105, -7.796000003814697, -7.796000003814697, -7.847099781036377, -7.558199882507324, -7.3506999015808105, -7.191999912261963, -7.1915998458862305, -7.44920015335083, -7.449100017547607, -7.3506999015808105, -7.449100017547607, -7.3506999015808105, -7.350500106811523, -7.114999771118164, -7.449100017547607, -7.44920015335083, -6.6178998947143555, -6.863399982452393, -6.807400226593018, -7.041999816894531, -7.447400093078613, -7.556600093841553, -7.041999816894531, -7.041900157928467, -7.349100112915039, -7.3491997718811035, -7.447400093078613, -7.447400093078613, -7.556600093841553, -7.3491997718811035, -7.349299907684326, -7.794400215148926, -7.794400215148926, -7.794400215148926, -7.794400215148926, -7.794400215148926, -7.794400215148926, -7.794400215148926, -7.794400215148926, -7.79449987411499, -7.794600009918213, -7.3491997718811035, -7.4475998878479, -7.794400215148926, -7.794400215148926, -7.556600093841553, -7.190100193023682, -7.348999977111816, -7.273600101470947, -7.55649995803833, -7.556600093841553, -7.113399982452393, -7.556600093841553, -7.4475998878479, -7.3491997718811035, -7.4475998878479, -7.556600093841553, -7.348800182342529, -6.98360013961792, -7.187900066375732, -7.554200172424316, -7.271200180053711, -7.051000118255615, -7.34660005569458, -7.554200172424316, -7.34660005569458, -7.110899925231934, -7.791900157928467, -7.791900157928467, -7.791900157928467, -7.791999816894531, -7.187900066375732, -7.791900157928467, -7.791900157928467, -7.271200180053711, -7.791900157928467, -7.791900157928467, -7.791900157928467, -7.791800022125244, -7.791900157928467, -7.791999816894531, -7.445000171661377, -7.791900157928467, -7.271100044250488, -7.791900157928467, -7.950099945068359, -7.950099945068359, -7.950099945068359, -7.18779993057251, -7.790999889373779, -7.110899925231934, -7.445000171661377, -7.271100044250488, -7.343699932098389, -7.554200172424316, -7.554200172424316, -7.554100036621094, -7.445000171661377, -7.611400127410889, -7.779200077056885, -7.783400058746338, -7.790999889373779, -7.790999889373779, -7.7916998863220215, -7.7916998863220215, -7.0416998863220215, -7.348800182342529, -7.348999977111816, -6.996600151062012, -7.273499965667725, -7.447199821472168, -7.556300163269043, -7.461100101470947, -7.43720006942749, -7.556300163269043, -7.556399822235107, -7.556399822235107, -7.794099807739258, -7.794099807739258, -7.794099807739258, -7.7941999435424805, -7.794300079345703, -7.794300079345703, -7.556300163269043, -7.794099807739258, -7.794099807739258, -6.922599792480469, -7.7941999435424805, -7.794099807739258, -7.348800182342529, -7.794300079345703, -7.794099807739258, -7.593999862670898, -7.794099807739258, -7.348800182342529, -7.447199821472168, -7.348899841308594, -7.348800182342529, -7.348899841308594, -7.190100193023682, -7.461100101470947, -7.190100193023682, -7.556300163269043, -7.556300163269043, -7.446499824523926, -7.54640007019043, -7.567399978637695, -7.513199806213379, -7.03879976272583, -6.9197001457214355, -7.345799922943115, -6.860300064086914, -7.270500183105469, -7.345799922943115, -7.553400039672852, -7.03879976272583, -7.444200038909912, -7.553400039672852, -7.345799922943115, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.553400039672852, -7.791200160980225, -7.553400039672852, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.444200038909912, -7.345799922943115, -7.444200038909912, -7.345799922943115, -7.553400039672852, -7.443600177764893, -7.553400039672852, -7.443900108337402, -7.553400039672852, -7.553400039672852, -7.7204999923706055, -7.789299964904785, -7.789700031280518, -7.791200160980225, -7.791200160980225, -7.791200160980225, -7.791200160980225, -6.895199775695801, -7.343200206756592, -7.343200206756592, -7.343200206756592, -7.343200206756592, -7.462699890136719, -7.462699890136719, -7.5507001876831055, -7.2677998542785645, -7.2677998542785645, -7.307400226593018, -7.343200206756592, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.5507001876831055, -7.78849983215332, -7.5507001876831055, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.78849983215332, -7.3429999351501465, -7.343200206756592, -7.78849983215332, -7.343200206756592, -7.343200206756592, -7.343200206756592, -7.2677998542785645, -7.4552001953125, -7.4415998458862305, -7.42080020904541, -7.5507001876831055, -7.5507001876831055, -7.55049991607666, -7.328400135040283, -7.5507001876831055, -7.68720006942749, -7.756499767303467, -7.338099956512451, -7.262700080871582, -7.545599937438965, -7.545599937438965, -7.545499801635742, -7.545599937438965, -7.262700080871582, -7.545599937438965, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.545599937438965, -7.783400058746338, -7.545599937438965, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.9415998458862305, -7.9415998458862305, -7.9415998458862305, -7.9415998458862305, -7.9415998458862305, -7.9415998458862305, -7.9415998458862305, -7.9415998458862305, -7.783400058746338, -7.783400058746338, -7.545599937438965, -7.783299922943115, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.542300224304199, -7.545599937438965, -7.545499801635742, -7.7829999923706055, -7.783299922943115, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -6.800000190734863, -6.800000190734863, -7.341599941253662, -7.341000080108643, -7.341599941253662, -7.105400085449219, -7.341599941253662, -7.341599941253662, -7.548600196838379, -7.548600196838379, -7.03439998626709, -7.34089994430542, -7.339099884033203, -7.4394001960754395, -7.341000080108643, -7.34089994430542, -7.341400146484375, -7.341599941253662, -7.341599941253662, -7.786399841308594, -7.786399841308594, -7.786399841308594, -7.786399841308594, -7.341599941253662, -7.786399841308594, -7.786399841308594, -7.786399841308594, -7.786399841308594, -7.786399841308594, -7.786399841308594, -7.341599941253662, -7.4394001960754395, -7.341599941253662, -7.325399875640869, -7.341000080108643, -7.4394001960754395, -7.438499927520752, -7.548399925231934, -7.785900115966797, -7.785999774932861, -7.26200008392334, -7.337200164794922, -7.337200164794922, -7.4355998039245605, -7.337200164794922, -7.337200164794922, -7.4359002113342285, -7.544899940490723, -7.5447998046875, -7.78249979019165, -7.782899856567383, -7.782899856567383, -7.78249979019165, -7.78249979019165, -7.78249979019165, -7.78249979019165, -7.782899856567383, -7.5447998046875, -7.78249979019165, -7.78249979019165, -7.337200164794922, -7.78249979019165, -7.78249979019165, -7.782400131225586, -7.78249979019165, -7.940700054168701, -7.940700054168701, -7.940700054168701, -7.940700054168701, -7.940700054168701, -7.782899856567383, -7.78249979019165, -7.5447998046875, -7.178400039672852, -7.782800197601318, -7.5447998046875, -7.337100028991699, -7.435699939727783, -7.782400131225586, -7.782400131225586, -7.782400131225586, -7.782400131225586, -7.78249979019165, -7.78249979019165, -7.78249979019165, -7.78249979019165, -7.78249979019165, -7.78249979019165, -6.806700229644775, -7.43779993057251, -7.263999938964844, -7.546899795532227, -7.546899795532227, -7.463900089263916, -7.180699825286865, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.339399814605713, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.103700160980225, -7.839799880981445, -7.7846999168396, -7.7846999168396, -7.839799880981445, -7.7846999168396, -7.339399814605713, -7.043700218200684, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.103700160980225, -7.546899795532227, -7.43779993057251, -7.546899795532227, -7.705699920654297, -7.724599838256836, -7.760300159454346, -7.78439998626709, -7.7845001220703125, -7.7845001220703125, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.7846999168396, -7.3379998207092285, -7.3379998207092285, -7.244900226593018, -7.262700080871582, -7.3379998207092285, -7.545400142669678, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.436399936676025, -7.545599937438965, -7.783400058746338, -7.3379998207092285, -7.783400058746338, -7.783400058746338, -7.3379998207092285, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.941500186920166, -7.941500186920166, -7.941500186920166, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.545599937438965, -7.545599937438965, -7.782800197601318, -7.7829999923706055, -7.783100128173828, -7.783100128173828, -7.783100128173828, -7.783100128173828, -7.783100128173828, -7.783199787139893, -7.783199787139893, -7.783199787139893, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.783400058746338, -7.333600044250488, -7.541100025177002, -7.541100025177002, -7.333799839019775, -7.541100025177002, -7.258200168609619, -7.778900146484375, -7.778900146484375, -7.779099941253662, -7.778900146484375, -7.779099941253662, -7.778600215911865, -7.778900146484375, -7.779099941253662, -7.779200077056885, -7.541100025177002, -7.779099941253662, -7.779099941253662, -7.778900146484375, -7.779099941253662, -7.541100025177002, -7.432000160217285, -7.937099933624268, -7.778900146484375, -7.779099941253662, -7.779099941253662, -7.937099933624268, -7.022799968719482, -7.779099941253662, -7.778900146484375, -7.333799839019775, -7.43209981918335, -7.258200168609619, -7.333600044250488, -7.54040002822876, -7.432000160217285, -7.541100025177002, -7.5345001220703125, -7.770899772644043, -7.77869987487793, -7.778800010681152, -7.778900146484375, -7.778900146484375, -7.778900146484375, -7.333799839019775, -7.333799839019775, -7.098100185394287, -7.333799839019775, -7.333799839019775, -7.333799839019775, -7.333799839019775, -7.431700229644775, -7.026299953460693, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778800010681152, -7.333799839019775, -7.778600215911865, -7.778600215911865, -7.431700229644775, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778800010681152, -7.778900146484375, -7.936800003051758, -7.936800003051758, -7.333199977874756, -7.936800003051758, -7.778600215911865, -7.936800003051758, -7.333099842071533, -7.778600215911865, -7.333199977874756, -7.540800094604492, -7.429599761962891, -7.428999900817871, -7.777699947357178, -7.778299808502197, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865, -7.778600215911865], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4845999479293823, 1.3731000423431396, 1.3451999425888062, 1.2944999933242798, 1.2663999795913696, 1.2630000114440918, 1.2517000436782837, 1.2447999715805054, 1.2333999872207642, 1.2333999872207642, 1.2283999919891357, 1.1928999423980713, 1.1826000213623047, 1.1679999828338623, 1.1583000421524048, 1.1518000364303589, 1.1478999853134155, 1.1360000371932983, 1.1311999559402466, 1.1238000392913818, 1.1226999759674072, 1.1226999759674072, 1.1226999759674072, 1.1204999685287476, 1.1117000579833984, 1.111299991607666, 1.1105999946594238, 1.1098999977111816, 1.1083999872207642, 1.1075999736785889, 1.1023999452590942, 1.0608999729156494, 1.0902999639511108, 1.052299976348877, 1.0406999588012695, 0.8705000281333923, 0.9807000160217285, 0.9254999756813049, 0.916100025177002, 0.9480999708175659, 0.9693999886512756, 0.698199987411499, 0.8720999956130981, 1.0110000371932983, 1.9550000429153442, 1.770400047302246, 1.7280999422073364, 1.642300009727478, 1.597499966621399, 1.5957000255584717, 1.5462000370025635, 1.524999976158142, 1.455199956893921, 1.4027999639511108, 1.3747999668121338, 1.3559999465942383, 1.3380000591278076, 1.2755999565124512, 1.2691999673843384, 1.218400001525879, 1.218000054359436, 1.2175999879837036, 1.1960999965667725, 1.1721999645233154, 1.1546000242233276, 1.1440000534057617, 1.1265000104904175, 1.120300054550171, 1.0994000434875488, 1.0463999509811401, 1.0250999927520752, 1.0130000114440918, 1.003600001335144, 0.9958000183105469, 0.9958000183105469, 0.9639000296592712, 0.9056000113487244, 0.7714999914169312, 0.7213000059127808, 0.8992999792098999, 0.9125999808311462, 0.5196999907493591, 0.65420001745224, 0.8181999921798706, 0.6585999727249146, 1.7513999938964844, 1.4420000314712524, 1.4286999702453613, 1.3463000059127808, 1.323199987411499, 1.2618000507354736, 1.2587000131607056, 1.2142000198364258, 1.2142000198364258, 1.2101000547409058, 1.1969000101089478, 1.1431000232696533, 1.1064000129699707, 1.1052000522613525, 1.1030999422073364, 1.1024999618530273, 1.1024999618530273, 1.093400001525879, 1.0880999565124512, 1.086400032043457, 1.083799958229065, 1.0777000188827515, 1.063599944114685, 1.0613000392913818, 1.055799961090088, 1.0529999732971191, 1.0434999465942383, 1.037500023841858, 1.0335999727249146, 1.0334999561309814, 1.0174000263214111, 1.0277999639511108, 0.8774999976158142, 0.9453999996185303, 0.911300003528595, 0.79830002784729, 0.7462999820709229, 0.8468000292778015, 0.8238000273704529, 0.8162999749183655, 0.41839998960494995, 0.5690000057220459, 1.5556999444961548, 1.5078999996185303, 1.4910000562667847, 1.4534000158309937, 1.3983999490737915, 1.3858000040054321, 1.3761999607086182, 1.3693000078201294, 1.3687000274658203, 1.333299994468689, 1.257599949836731, 1.2477999925613403, 1.2425999641418457, 1.2410000562667847, 1.2031999826431274, 1.2010999917984009, 1.1908999681472778, 1.1897000074386597, 1.1272000074386597, 1.1200000047683716, 1.1198999881744385, 1.0852999687194824, 1.0740000009536743, 1.056399941444397, 1.0470999479293823, 1.0348999500274658, 1.0319000482559204, 1.0174000263214111, 1.01010000705719, 1.0045000314712524, 0.995199978351593, 0.9944000244140625, 0.919700026512146, 0.9868000149726868, 0.9350000023841858, 0.8840000033378601, 0.8288999795913696, 0.7716000080108643, 0.652999997138977, 0.2476000040769577, 0.8079000115394592, 0.12929999828338623, 1.4423999786376953, 1.4026999473571777, 1.3961999416351318, 1.382099986076355, 1.3310999870300293, 1.3279000520706177, 1.2822999954223633, 1.281599998474121, 1.239300012588501, 1.2069000005722046, 1.1904000043869019, 1.1467000246047974, 1.1435999870300293, 1.0999000072479248, 1.0958000421524048, 1.0951000452041626, 1.082200050354004, 1.0618000030517578, 1.059999942779541, 1.0433000326156616, 1.0190999507904053, 1.0113999843597412, 1.01010000705719, 1.0075000524520874, 0.9988999962806702, 0.998199999332428, 0.9955999851226807, 0.9656999707221985, 0.958299994468689, 0.9495000243186951, 0.9312999844551086, 0.9114000201225281, 0.8694000244140625, 0.8536999821662903, 0.8149999976158142, 0.8655999898910522, 0.8324000239372253, 0.2639000117778778, 0.46799999475479126, 0.5828999876976013, -0.09830000251531601, 0.24969999492168427, 2.394399881362915, 2.0064001083374023, 1.4607000350952148, 1.4292999505996704, 1.3545000553131104, 1.3387999534606934, 1.3166999816894531, 1.3100999593734741, 1.2954000234603882, 1.2869999408721924, 1.2855000495910645, 1.1952999830245972, 1.1377999782562256, 1.1212999820709229, 1.1129000186920166, 1.1121000051498413, 1.1051000356674194, 1.103700041770935, 1.1033999919891357, 1.0889999866485596, 1.0605000257492065, 1.0540000200271606, 1.0436999797821045, 1.038699984550476, 1.0369000434875488, 1.031999945640564, 1.0233999490737915, 1.0180000066757202, 1.0103000402450562, 1.0092999935150146, 0.9646999835968018, 0.9922000169754028, 0.8537999987602234, 0.6978999972343445, 0.49540001153945923, 0.3515999913215637, 0.33320000767707825, 0.5322999954223633, 0.7802000045776367, 0.7692000269889832, 0.3734999895095825, 0.7113999724388123, 0.29269999265670776, 1.9622000455856323, 1.3407000303268433, 1.317199945449829, 1.3111000061035156, 1.3100999593734741, 1.2055000066757202, 1.2034000158309937, 1.1904000043869019, 1.1617000102996826, 1.1610000133514404, 1.1301000118255615, 1.120300054550171, 1.1155999898910522, 1.0881999731063843, 1.0764000415802002, 1.0721999406814575, 1.0644999742507935, 1.047700047492981, 1.0420000553131104, 1.034000039100647, 1.0094000101089478, 1.003000020980835, 0.9968000054359436, 0.9728999733924866, 0.9613000154495239, 0.9519000053405762, 0.9373000264167786, 0.9326000213623047, 0.9290000200271606, 0.9197999835014343, 0.9093000292778015, 0.868399977684021, 0.9034000039100647, 0.59579998254776, 0.5849000215530396, 0.37299999594688416, 0.8665000200271606, 0.052799999713897705, 0.6456999778747559, 0.7368999719619751, 0.6164000034332275, 0.4449000060558319, 0.7584999799728394, 0.22300000488758087, 1.597599983215332, 1.4323999881744385, 1.3944000005722046, 1.3565000295639038, 1.2934999465942383, 1.2783000469207764, 1.180899977684021, 1.1771999597549438, 1.1503000259399414, 1.1484999656677246, 1.1378999948501587, 1.131600022315979, 1.1058000326156616, 1.075700044631958, 1.0750000476837158, 1.0526000261306763, 1.0501999855041504, 1.0293999910354614, 0.9984999895095825, 0.9732999801635742, 0.9710000157356262, 0.9670000076293945, 0.9664000272750854, 0.9663000106811523, 0.9437999725341797, 0.9322999715805054, 0.9065999984741211, 0.9061999917030334, 0.8960999846458435, 0.8927000164985657, 0.8920000195503235, 0.8633000254631042, 0.786300003528595, 0.6496999859809875, 0.6608999967575073, 0.6439999938011169, 0.07020000368356705, 0.4943000078201294, 0.8662999868392944, 0.09009999781847, 0.392300009727478, 0.677299976348877, 0.3596000075340271, 0.7290999889373779, 2.175100088119507, 1.7826000452041626, 1.6002000570297241, 1.502500057220459, 1.4430999755859375, 1.3365999460220337, 1.2978999614715576, 1.2244999408721924, 1.2066999673843384, 1.187999963760376, 1.1868000030517578, 1.1818000078201294, 1.1734999418258667, 1.1497999429702759, 1.110200047492981, 1.1079000234603882, 1.093999981880188, 1.0566999912261963, 1.0428999662399292, 1.0127999782562256, 0.9969000220298767, 0.9905999898910522, 0.9312999844551086, 0.9228000044822693, 0.9175000190734863, 0.9089999794960022, 0.9049999713897705, 0.9046000242233276, 0.9045000076293945, 0.8998000025749207, 0.8930000066757202, 0.7964000105857849, 0.8073999881744385, 0.6011999845504761, 0.6643999814987183, 0.6194999814033508, 0.4171000123023987, 0.4171000123023987, 0.7228000164031982, 1.3623000383377075, 1.2696000337600708, 1.252500057220459, 1.2051000595092773, 1.2032999992370605, 1.1965999603271484, 1.1394000053405762, 1.128600001335144, 1.1079000234603882, 1.1052000522613525, 1.082900047302246, 1.0708999633789062, 1.0608999729156494, 1.0470000505447388, 1.0286999940872192, 1.0254000425338745, 1.017799973487854, 1.0032999515533447, 0.9923999905586243, 0.9907000064849854, 0.9409999847412109, 0.904699981212616, 0.8930000066757202, 0.8769999742507935, 0.8745999932289124, 0.8528000116348267, 0.8438000082969666, 0.8136000037193298, 0.8066999912261963, 0.8007000088691711, 0.7545999884605408, 0.7358999848365784, 0.6452000141143799, 0.7408000230789185, 0.715499997138977, 0.7057999968528748, 0.6877999901771545, 0.6577000021934509, 0.319599986076355, 0.3382999897003174, -0.07100000232458115, 0.5083000063896179, 1.4696999788284302, 1.3913999795913696, 1.3350000381469727, 1.2120000123977661, 1.2120000123977661, 1.211300015449524, 1.1842000484466553, 1.1639000177383423, 1.145300030708313, 1.1159000396728516, 1.0879000425338745, 1.0789999961853027, 1.0490000247955322, 1.0281000137329102, 1.0218000411987305, 0.9993000030517578, 0.9786999821662903, 0.9678999781608582, 0.9628000259399414, 0.954200029373169, 0.9394000172615051, 0.9075999855995178, 0.9032999873161316, 0.8977000117301941, 0.8847000002861023, 0.850600004196167, 0.8446999788284302, 0.8355000019073486, 0.8144999742507935, 0.8140000104904175, 0.5633000135421753, 0.6212000250816345, 0.7213000059127808, 0.41119998693466187, 0.6140000224113464, 0.6905999779701233, 0.5084999799728394, 0.1387999951839447, 0.5817000269889832, -0.06719999760389328, 0.7605999708175659, 1.7096999883651733, 1.3461999893188477, 1.3387999534606934, 1.2338000535964966, 1.2338000535964966, 1.2117999792099, 1.2091000080108643, 1.1971999406814575, 1.1618000268936157, 1.0741000175476074, 1.0708999633789062, 1.058899998664856, 1.006100058555603, 1.0009000301361084, 0.9937999844551086, 0.9625999927520752, 0.8537999987602234, 0.828000009059906, 0.8230000138282776, 0.8230000138282776, 0.8230000138282776, 0.8230000138282776, 0.8230000138282776, 0.8230000138282776, 0.8144000172615051, 0.802299976348877, 0.7996000051498413, 0.7994999885559082, 0.7986999750137329, 0.7896999716758728, 0.7742000222206116, 0.7706000208854675, 0.6980000138282776, 0.705299973487854, 0.6614999771118164, 0.6532999873161316, 0.6449999809265137, 0.517300009727478, 0.4163999855518341, 0.5145999789237976, 0.29649999737739563, 0.5, 0.290800005197525, 0.17260000109672546, 1.4598000049591064, 1.291599988937378, 1.2395999431610107, 1.2014000415802002, 1.1601999998092651, 1.136299967765808, 1.0923000574111938, 1.0857000350952148, 1.075700044631958, 1.0429999828338623, 1.0120999813079834, 1.010699987411499, 0.979200005531311, 0.9757999777793884, 0.9599999785423279, 0.9567000269889832, 0.9469000101089478, 0.9358000159263611, 0.9264000058174133, 0.9172000288963318, 0.9144999980926514, 0.9050999879837036, 0.8310999870300293, 0.8278999924659729, 0.8277999758720398, 0.8277999758720398, 0.8277999758720398, 0.8277000188827515, 0.8277000188827515, 0.8008999824523926, 0.7754999995231628, 0.7461000084877014, 0.6049000024795532, 0.5364999771118164, 0.5766000151634216, 0.5911999940872192, 0.4228000044822693, 0.11630000174045563, 0.4198000133037567, 0.36959999799728394, -0.007499999832361937, 0.3598000109195709, 0.3937999904155731, 1.2467000484466553, 1.2345999479293823, 1.1067999601364136, 1.0707000494003296, 1.056399941444397, 1.0362999439239502, 1.0361000299453735, 0.9980999827384949, 0.9767000079154968, 0.9577999711036682, 0.9577000141143799, 0.8593999743461609, 0.8345000147819519, 0.8345000147819519, 0.8345000147819519, 0.8345000147819519, 0.8342999815940857, 0.8342999815940857, 0.8342000246047974, 0.817300021648407, 0.817300021648407, 0.8138999938964844, 0.808899998664856, 0.7840999960899353, 0.781000018119812, 0.7760999798774719, 0.7657999992370605, 0.7581999897956848, 0.755299985408783, 0.7519000172615051, 0.722000002861023, 0.6380000114440918, 0.7189000248908997, 0.7056999802589417, 0.5907999873161316, 0.6714000105857849, 0.5166000127792358, 0.5120999813079834, 0.6055999994277954, 0.5817999839782715, 0.5810999870300293, 0.2574999928474426, 0.5737000107765198, 0.42250001430511475, 0.532800018787384, 0.3723999857902527, -0.0010999999940395355, 0.2443999946117401, 0.29089999198913574, 0.47679999470710754, 2.0866000652313232, 1.8558000326156616, 1.7009999752044678, 1.6584999561309814, 1.5240999460220337, 1.4560999870300293, 1.382200002670288, 1.3515000343322754, 1.3499000072479248, 1.3485000133514404, 1.2802000045776367, 1.2482999563217163, 1.240399956703186, 1.2000999450683594, 1.1904000043869019, 1.1468000411987305, 1.0600999593734741, 1.0062999725341797, 0.9872000217437744, 0.9729999899864197, 0.8774999976158142, 0.8342000246047974, 0.8342000246047974, 0.8342000246047974, 0.8342000246047974, 0.8342000246047974, 0.8199999928474426, 0.7874000072479248, 0.7749000191688538, 0.7684999704360962, 0.7670999765396118, 0.6335999965667725, 0.6129000186920166, 0.6743999719619751, 0.30390000343322754, 0.5921000242233276, 0.600600004196167, 0.29809999465942383, 0.3043000102043152, 0.3255000114440918, 1.4977999925613403, 1.2692999839782715, 1.2303999662399292, 1.2015000581741333, 1.1871000528335571, 1.1770000457763672, 1.0777000188827515, 1.045699954032898, 1.0396000146865845, 1.0082000494003296, 0.9133999943733215, 0.8752999901771545, 0.8453999757766724, 0.8345999717712402, 0.8345999717712402, 0.8345999717712402, 0.8345999717712402, 0.8345999717712402, 0.8345999717712402, 0.8345999717712402, 0.8345999717712402, 0.8343999981880188, 0.8342999815940857, 0.8342000246047974, 0.8216000199317932, 0.8112999796867371, 0.8109999895095825, 0.808899998664856, 0.8072999715805054, 0.8041999936103821, 0.7498999834060669, 0.6373999714851379, 0.7113999724388123, 0.5976999998092651, 0.5906000137329102, 0.5508999824523926, -0.3675999939441681, 0.1875, 0.5239999890327454, 0.6805999875068665, 0.3910999894142151, 0.7491000294685364, 0.6597999930381775, 0.0414000004529953, 0.40059998631477356, 1.951799988746643, 1.3421000242233276, 1.2527999877929688, 1.2526999711990356, 1.124899983406067, 1.110700011253357, 0.9581999778747559, 0.92330002784729, 0.8978999853134155, 0.8743000030517578, 0.8521000146865845, 0.8375999927520752, 0.8375999927520752, 0.8119000196456909, 0.8101000189781189, 0.7888000011444092, 0.772599995136261, 0.7663999795913696, 0.7574999928474426, 0.7569000124931335, 0.7562000155448914, 0.7548999786376953, 0.7479000091552734, 0.7475000023841858, 0.7451000213623047, 0.7315000295639038, 0.7279000282287598, 0.7166000008583069, 0.7146999835968018, 0.7128999829292297, 0.5534999966621399, 0.6392999887466431, 0.5946000218391418, 0.527899980545044, 0.46149998903274536, 0.5670999884605408, 0.3003000020980835, 0.5060999989509583, 0.4993000030517578, 0.3529999852180481, 0.44350001215934753, 0.3492000102996826, 0.2603999972343445, 0.6904000043869019, 0.08630000054836273, 1.3181999921798706, 1.2086999416351318, 1.1413999795913696, 1.0831999778747559, 1.0769000053405762, 1.0407999753952026, 1.0230000019073486, 1.0205999612808228, 1.0162999629974365, 0.967199981212616, 0.9229999780654907, 0.921500027179718, 0.9189000129699707, 0.8723999857902527, 0.8409000039100647, 0.8409000039100647, 0.8409000039100647, 0.8409000039100647, 0.8407999873161316, 0.8407999873161316, 0.8407999873161316, 0.8288000226020813, 0.8220999836921692, 0.8025000095367432, 0.8011999726295471, 0.7998999953269958, 0.7979000210762024, 0.7937999963760376, 0.7922999858856201, 0.7858999967575073, 0.7828999757766724, 0.7486000061035156, 0.710099995136261, 0.5652999877929688, 0.6554999947547913, 0.6492000222206116, 0.5609999895095825, 0.6050999760627747, 0.5209000110626221, 0.4661000072956085, 0.2362000048160553, 0.43059998750686646, 0.32899999618530273, 1.9149999618530273, 1.6656999588012695, 1.3739999532699585, 1.3141000270843506, 1.1435999870300293, 1.0681999921798706, 1.066100001335144, 1.0533000230789185, 1.0130000114440918, 0.9807999730110168, 0.9634000062942505, 0.9541000127792358, 0.9539999961853027, 0.911899983882904, 0.8852999806404114, 0.8435999751091003, 0.8435999751091003, 0.8435999751091003, 0.8435999751091003, 0.8435999751091003, 0.8435999751091003, 0.8435999751091003, 0.8273000121116638, 0.8233000040054321, 0.8129000067710876, 0.805899977684021, 0.7904999852180481, 0.781000018119812, 0.7703999876976013, 0.76419997215271, 0.6830000281333923, 0.6843000054359436, 0.5964000225067139, 0.6796000003814697, 0.6643999814987183, 0.3172999918460846, 0.663100004196167, 0.4250999987125397, 0.1851000040769577, 0.2653000056743622, 0.4359000027179718, -0.04450000077486038, 1.3428000211715698, 1.1729999780654907, 1.0389000177383423, 1.010599970817566, 0.9519000053405762, 0.9484999775886536, 0.9279999732971191, 0.8935999870300293, 0.8840000033378601, 0.8460999727249146, 0.8460999727249146, 0.8460999727249146, 0.8460999727249146, 0.8454999923706055, 0.8306999802589417, 0.8263999819755554, 0.8172000050544739, 0.8080000281333923, 0.801800012588501, 0.7990999817848206, 0.7976999878883362, 0.7942000031471252, 0.7735000252723694, 0.7556999921798706, 0.7541000247001648, 0.7527999877929688, 0.7319999933242798, 0.6952000260353088, 0.6952000260353088, 0.6952000260353088, 0.6287999749183655, 0.6732000112533569, 0.5188000202178955, 0.5914999842643738, 0.5408999919891357, 0.5002999901771545, 0.5078999996185303, 0.35760000348091125, 0.3190000057220459, -0.09369999915361404, -0.13729999959468842, 0.504800021648407, 0.2176000028848648, 0.2745000123977661, 0.2630999982357025, 0.13130000233650208, 0.569100022315979, 1.544100046157837, 1.263100028038025, 1.242400050163269, 1.2015999555587769, 1.1907999515533447, 1.1090999841690063, 1.0693999528884888, 1.000100016593933, 0.9564999938011169, 0.9435999989509583, 0.9236000180244446, 0.8730000257492065, 0.8445000052452087, 0.8445000052452087, 0.8445000052452087, 0.8443999886512756, 0.8442999720573425, 0.8442999720573425, 0.8328999876976013, 0.8317000269889832, 0.8220000267028809, 0.8206999897956848, 0.8108000159263611, 0.8008000254631042, 0.7980999946594238, 0.7904999852180481, 0.7652000188827515, 0.7598999738693237, 0.7540000081062317, 0.7505000233650208, 0.7078999876976013, 0.6876999735832214, 0.678600013256073, 0.6140000224113464, 0.5052000284194946, 0.6370000243186951, 0.46219998598098755, 0.5529999732971191, 0.5091999769210815, 0.3294000029563904, 0.3643999993801117, 0.23579999804496765, 0.0210999995470047, 1.510699987411499, 1.2963999509811401, 1.267899990081787, 1.1323000192642212, 1.1035000085830688, 1.0805000066757202, 1.0218000411987305, 0.9742000102996826, 0.9165999889373779, 0.887499988079071, 0.8737000226974487, 0.8483999967575073, 0.8483999967575073, 0.8483999967575073, 0.8483999967575073, 0.8483999967575073, 0.8483999967575073, 0.8483999967575073, 0.8483999967575073, 0.8482999801635742, 0.8310999870300293, 0.8269000053405762, 0.8180000185966492, 0.8179000020027161, 0.8151999711990356, 0.8105999827384949, 0.7944999933242798, 0.7896000146865845, 0.7839000225067139, 0.779699981212616, 0.7627999782562256, 0.7466999888420105, 0.6432999968528748, 0.51419997215271, 0.5722000002861023, 0.2085999995470047, 0.35510000586509705, 0.09040000289678574, 0.1940000057220459, 0.1898999959230423, 0.26739999651908875, 0.06129999831318855, -0.011500000022351742, 0.578499972820282, 0.2718000113964081, 0.37139999866485596, 0.524399995803833, 1.31659996509552, 1.1748000383377075, 1.0972000360488892, 1.0671000480651855, 1.0091999769210815, 0.9987000226974487, 0.9703999757766724, 0.9419999718666077, 0.9233999848365784, 0.9226999878883362, 0.8996000289916992, 0.8744000196456909, 0.8532000184059143, 0.8532000184059143, 0.8532000184059143, 0.8532000184059143, 0.8377000093460083, 0.8233000040054321, 0.8226000070571899, 0.8205999732017517, 0.8181999921798706, 0.8181999921798706, 0.8109999895095825, 0.8095999956130981, 0.8044000267982483, 0.7692999839782715, 0.7678999900817871, 0.7674000263214111, 0.7662000060081482, 0.7656000256538391, 0.7562000155448914, 0.7401999831199646, 0.7189000248908997, 0.6815999746322632, 0.5687000155448914, 0.4544000029563904, 0.42989999055862427, 0.5148000121116638, 0.49140000343322754, 0.4562000036239624, 0.02280000038444996, 0.420199990272522, 0.12479999661445618, 0.27869999408721924, 1.2807999849319458, 1.1265000104904175, 1.0019999742507935, 0.9916999936103821, 0.9871000051498413, 0.9805999994277954, 0.8960999846458435, 0.8690000176429749, 0.8587999939918518, 0.8586999773979187, 0.8586999773979187, 0.8586999773979187, 0.8586999773979187, 0.8136000037193298, 0.7753999829292297, 0.7681000232696533, 0.7626000046730042, 0.7544000148773193, 0.7491999864578247, 0.7459999918937683, 0.7275999784469604, 0.7096999883651733, 0.7067999839782715, 0.7067999839782715, 0.7067999839782715, 0.7067999839782715, 0.7067999839782715, 0.7067999839782715, 0.7067999839782715, 0.7067999839782715, 0.7046999931335449, 0.6859999895095825, 0.6456000208854675, 0.659600019454956, 0.6575000286102295, 0.6291000247001648, 0.6263999938964844, 0.46050000190734863, 0.3564000129699707, 0.33809998631477356, 0.1120000034570694, -0.026599999517202377, 0.5328999757766724, 0.36640000343322754, 0.042899999767541885, 0.4722000062465668, 1.77839994430542, 1.6740000247955322, 1.2797000408172607, 1.2216999530792236, 1.210800051689148, 1.1603000164031982, 1.1225999593734741, 1.0981999635696411, 1.0842000246047974, 1.0842000246047974, 1.0311000347137451, 0.982200026512146, 0.929099977016449, 0.926800012588501, 0.9230999946594238, 0.9132000207901001, 0.9106000065803528, 0.8744999766349792, 0.8590999841690063, 0.8571000099182129, 0.8571000099182129, 0.8571000099182129, 0.8414999842643738, 0.8012999892234802, 0.7972000241279602, 0.7817000150680542, 0.7684000134468079, 0.7652999758720398, 0.7652999758720398, 0.746999979019165, 0.7125999927520752, 0.6766999959945679, 0.6243000030517578, 0.6075000166893005, 0.40230000019073486, 0.36079999804496765, 0.31839999556541443, 0.20839999616146088, 0.24150000512599945, 0.313400000333786, 1.3562999963760376, 1.2856999635696411, 1.2624000310897827, 1.1928000450134277, 1.0405999422073364, 1.0369999408721924, 0.9896000027656555, 0.9692999720573425, 0.9287999868392944, 0.8616999983787537, 0.861299991607666, 0.861299991607666, 0.824400007724762, 0.8112999796867371, 0.7908999919891357, 0.7908999919891357, 0.7874000072479248, 0.7760999798774719, 0.7674999833106995, 0.7544999718666077, 0.753000020980835, 0.7493000030517578, 0.7479000091552734, 0.7396000027656555, 0.7307999730110168, 0.7092000246047974, 0.7092000246047974, 0.7092000246047974, 0.7092000246047974, 0.7092000246047974, 0.7024999856948853, 0.6917999982833862, 0.6636999845504761, 0.6171000003814697, 0.680899977684021, 0.5094000101089478, 0.13689999282360077, 0.18389999866485596, 0.45660001039505005, 0.28780001401901245, 0.5996000170707703, 0.4853000044822693, 0.2799000144004822, 0.30979999899864197, 0.6542999744415283, 0.6682000160217285, 0.12919999659061432, 0.38960000872612, 1.1857999563217163, 1.042799949645996, 1.0360000133514404, 0.9991000294685364, 0.9567999839782715, 0.9298999905586243, 0.9003999829292297, 0.8598999977111816, 0.8598999977111816, 0.8598999977111816, 0.8598999977111816, 0.8598999977111816, 0.8598999977111816, 0.8598999977111816, 0.8569999933242798, 0.833899974822998, 0.8248000144958496, 0.8123999834060669, 0.8116999864578247, 0.7968000173568726, 0.7890999913215637, 0.78329998254776, 0.7814000248908997, 0.776199996471405, 0.7687000036239624, 0.7682999968528748, 0.7597000002861023, 0.7552000284194946, 0.7422999739646912, 0.7342000007629395, 0.6090999841690063, 0.6886000037193298, 0.5252000093460083, 0.4156000018119812, 0.13439999520778656, 0.08410000056028366, -0.28619998693466187, 0.5688999891281128, 0.6161999702453613, 0.08829999715089798, 0.4542999863624573, 0.6097000241279602, 0.041600000113248825, 0.6021999716758728, 0.5633999705314636, 0.5774000287055969, 1.2857999801635742, 1.2857999801635742, 1.266700029373169, 1.0586999654769897, 1.0288000106811523, 0.9074000120162964, 0.8614000082015991, 0.8614000082015991, 0.8614000082015991, 0.861299991607666, 0.861299991607666, 0.861299991607666, 0.8481000065803528, 0.8414999842643738, 0.828000009059906, 0.8209999799728394, 0.8125, 0.8014000058174133, 0.7906000018119812, 0.781000018119812, 0.7781999707221985, 0.7635999917984009, 0.7612000107765198, 0.7480000257492065, 0.7465999722480774, 0.7383999824523926, 0.7272999882698059, 0.7087000012397766, 0.7087000012397766, 0.7087000012397766, 0.7063000202178955, 0.7049000263214111, 0.701200008392334, 0.5525000095367432, 0.2572999894618988, 0.37950000166893005, 0.6251999735832214, 0.20479999482631683, 0.4131999909877777, 0.5081999897956848, 0.08299999684095383, 0.6162999868392944, 0.6165000200271606, 0.6789000034332275, 0.09319999814033508, 0.251800000667572, 0.6000999808311462, 0.41670000553131104, 0.6291000247001648, 0.5845999717712402, 0.6431000232696533, 1.2201999425888062, 1.09660005569458, 1.075600028038025, 1.057800054550171, 0.9362000226974487, 0.9329000115394592, 0.867900013923645, 0.867900013923645, 0.8428000211715698, 0.8392999768257141, 0.8208000063896179, 0.8138999938964844, 0.8044999837875366, 0.7968000173568726, 0.7883999943733215, 0.7745000123977661, 0.757099986076355, 0.7487999796867371, 0.7452999949455261, 0.7415000200271606, 0.7340999841690063, 0.7314000129699707, 0.7146999835968018, 0.7078999876976013, 0.7002999782562256, 0.6933000087738037, 0.6919000148773193, 0.6899999976158142, 0.6883000135421753, 0.6836000084877014, 0.6121000051498413, 0.6043999791145325, 0.544700026512146, 0.5264999866485596, 0.49950000643730164, 0.31130000948905945, 0.21580000221729279, -0.00019999999494757503, 0.4408999979496002, 0.41760000586509705, 0.32919999957084656, 0.5264000296592712, 0.18400000035762787, 0.5164999961853027, 1.2969000339508057, 1.2969000339508057, 1.2510000467300415, 1.103600025177002, 1.0836999416351318, 1.0266000032424927, 1.0037000179290771, 0.9708999991416931, 0.9196000099182129, 0.869700014591217, 0.869700014591217, 0.869700014591217, 0.8694000244140625, 0.8677999973297119, 0.8363000154495239, 0.8361999988555908, 0.8294000029563904, 0.7829999923706055, 0.7796000242233276, 0.7795000076293945, 0.7531999945640564, 0.7465000152587891, 0.7447999715805054, 0.7247999906539917, 0.7160999774932861, 0.7160999774932861, 0.7113999724388123, 0.6959999799728394, 0.6959999799728394, 0.6890000104904175, 0.667900025844574, 0.6812999844551086, 0.6312999725341797, 0.6182000041007996, 0.17110000550746918, 0.04500000178813934, 0.2809000015258789, -0.4271000027656555, 0.5514000058174133, 0.3522000014781952, 0.621999979019165, 0.5156999826431274, 0.6459000110626221, 0.43320000171661377, 0.4595000147819519, 0.3264000117778778, 0.4523000121116638]}, \"token.table\": {\"Topic\": [1, 4, 2, 1, 1, 1, 1, 3, 4, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 5, 2, 1, 3, 1, 6, 1, 1, 1, 2, 1, 5, 2, 3, 2, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 9, 2, 2, 1, 5, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 4, 1, 2, 1, 2, 1, 2, 3, 1, 1, 4, 4, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3, 3, 1, 1, 1, 1, 4, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 3, 1, 1, 1, 3, 1, 1, 2, 6, 1, 1, 2, 1, 1, 1, 1, 1, 4, 2, 1, 1, 4, 1, 4, 1, 3, 1, 2, 1, 8, 9, 4, 4, 1, 1, 1, 1, 4, 6, 8, 3, 1, 3, 8, 1, 1, 1, 1, 6, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 7, 1, 2, 2, 1, 1, 1, 9, 2, 2, 3, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 6, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 5, 1, 1], \"Freq\": [0.33335185050964355, 0.33335185050964355, 0.2652902603149414, 0.3517671525478363, 0.3536054491996765, 0.4114408791065216, 0.3617693781852722, 0.4682530462741852, 0.4676014482975006, 0.3631316125392914, 0.32490524649620056, 0.47677552700042725, 0.29632213711738586, 0.29632213711738586, 0.35199370980262756, 0.2771865427494049, 0.2771865427494049, 0.4218881130218506, 0.4474656581878662, 0.2237328290939331, 0.6157355308532715, 0.2764951288700104, 0.3420046865940094, 0.31217455863952637, 0.31217455863952637, 0.3422045409679413, 0.39220091700553894, 0.18335098028182983, 0.36670196056365967, 0.2595153748989105, 0.2999805808067322, 0.2640707492828369, 0.2640707492828369, 0.35531914234161377, 0.43036550283432007, 0.35984620451927185, 0.3730551302433014, 0.32869261503219604, 0.25403162837028503, 0.3371661305427551, 0.28492292761802673, 0.36575886607170105, 0.314714252948761, 0.33558550477027893, 0.4100106656551361, 0.41106775403022766, 0.4246126413345337, 0.4508782625198364, 0.37886273860931396, 0.44729122519493103, 0.39599621295928955, 0.2924339771270752, 0.3952028751373291, 0.356734037399292, 0.4322911500930786, 0.36954936385154724, 0.36141863465309143, 0.297706663608551, 0.3637286424636841, 0.41773417592048645, 0.29375219345092773, 0.29375219345092773, 0.3693011403083801, 0.34342801570892334, 0.37975022196769714, 0.2956637442111969, 0.2956637442111969, 0.37356671690940857, 0.18678335845470428, 0.2687966525554657, 0.38843968510627747, 0.37523379921913147, 0.28536373376846313, 0.16934682428836823, 0.16934682428836823, 0.3127124011516571, 0.30199989676475525, 0.41629335284233093, 0.3231589198112488, 0.1615794599056244, 0.30295756459236145, 0.30295756459236145, 0.27232620120048523, 0.27232620120048523, 0.27232620120048523, 0.40813684463500977, 0.27902692556381226, 0.27902692556381226, 0.4242900013923645, 0.2516569495201111, 0.43132779002189636, 0.29414573311805725, 0.3938484191894531, 0.344597727060318, 0.31863483786582947, 0.5351464748382568, 0.33880722522735596, 0.36285021901130676, 0.31219252943992615, 0.4212428033351898, 0.36095038056373596, 0.47666823863983154, 0.45474687218666077, 0.3954048156738281, 0.26846349239349365, 0.31074056029319763, 0.3079952001571655, 0.45085906982421875, 0.4265475571155548, 0.34508758783340454, 0.3990817070007324, 0.4955816864967346, 0.4346780776977539, 0.3316194713115692, 0.38483819365501404, 0.20336247980594635, 0.20336247980594635, 0.4526103734970093, 0.38293856382369995, 0.26969683170318604, 0.26969683170318604, 0.26625779271125793, 0.26625779271125793, 0.27138474583625793, 0.31354522705078125, 0.25063103437423706, 0.25063103437423706, 0.37267711758613586, 0.44411277770996094, 0.3052227795124054, 0.42117443680763245, 0.3453562259674072, 0.3539521098136902, 0.44078826904296875, 0.3922375440597534, 0.46125465631484985, 0.3959905207157135, 0.3791683614253998, 0.281982958316803, 0.281982958316803, 0.6406983733177185, 0.2777528166770935, 0.2288055419921875, 0.2288055419921875, 0.2917041778564453, 0.2917041778564453, 0.2926521897315979, 0.2926521897315979, 0.2589395344257355, 0.2589395344257355, 0.42647069692611694, 0.29440730810165405, 0.29440730810165405, 0.3311229646205902, 0.3120746612548828, 0.2661183476448059, 0.39574891328811646, 0.3547666370868683, 0.31312140822410583, 0.4181385338306427, 0.6132487654685974, 0.22146287560462952, 0.3935171067714691, 0.36844906210899353, 0.4735645651817322, 0.228836327791214, 0.4475419819355011, 0.4212428033351898, 0.30692344903945923, 0.3332473337650299, 0.3332473337650299, 0.36570045351982117, 0.44967764616012573, 0.444219172000885, 0.39254069328308105, 0.6802583336830139, 0.33877456188201904, 0.3669523000717163, 0.2833956778049469, 0.2833956778049469, 0.45085906982421875, 0.3942619860172272, 0.3223210275173187, 0.44248706102371216, 0.5521904826164246, 0.45114532113075256, 0.24310597777366638, 0.24310597777366638, 0.34484368562698364, 0.42064324021339417, 0.32891175150871277, 0.3318406343460083, 0.4257065951824188, 0.266030490398407, 0.28451022505760193, 0.28451022505760193, 0.3702244162559509, 0.28632697463035583, 0.28526565432548523, 0.2723013162612915, 0.3292452096939087, 0.318296879529953, 0.3819337785243988, 0.23889242112636566, 0.30909600853919983, 0.30598506331443787, 0.30598506331443787, 0.35454261302948, 0.44338300824165344, 0.32822075486183167, 0.29661983251571655, 0.36137762665748596, 0.36137762665748596, 0.34974825382232666, 0.2919662594795227, 0.2919662594795227, 0.3243081867694855, 0.47671690583229065, 0.4117538630962372, 0.251456618309021, 0.37373441457748413, 0.29959332942962646, 0.3329814672470093, 0.3884800970554352, 0.46719372272491455, 0.28167659044265747, 0.25406643748283386, 0.32008588314056396, 0.32008588314056396, 0.3420355021953583, 0.3435489237308502, 0.28838858008384705], \"Term\": [\"'accident',\", \"'accident',\", \"'actual',\", \"'advic',\", \"'agre',\", \"'american',\", \"'anoth',\", \"'anyth',\", \"'apart',\", \"'appear',\", \"'apu',\", \"'armor',\", \"'attack',\", \"'attack',\", \"'babi',\", \"'bad',\", \"'bad',\", \"'band',\", \"'bar',\", \"'bar',\", \"'bear',\", \"'believ',\", \"'best',\", \"'better',\", \"'better',\", \"'bill',\", \"'bond',\", \"'boy',\", \"'boy',\", \"'break',\", \"'busi',\", \"'buy',\", \"'buy',\", \"'carl',\", \"'catch',\", \"'chanc',\", \"'chang',\", \"'children',\", \"'choos',\", \"'church',\", \"'citi',\", \"'citizen',\", \"'class',\", \"'close',\", \"'clown',\", \"'colleg',\", \"'confront',\", \"'congress',\", \"'congressman',\", \"'consid',\", \"'counselor',\", \"'date',\", \"'deal',\", \"'decid',\", \"'discov',\", \"'dog',\", \"'dream',\", \"'drive',\", \"'drunk',\", \"'due',\", \"'elementari',\", \"'elementari',\", \"'eventu',\", \"'everi',\", \"'fail',\", \"'famili',\", \"'famili',\", \"'father',\", \"'father',\", \"'find',\", \"'fli',\", \"'food',\", \"'forc',\", \"'friend',\", \"'friend',\", \"'futur',\", \"'game',\", \"'gay',\", \"'get',\", \"'get',\", \"'gift',\", \"'gift',\", \"'girl',\", \"'girl',\", \"'girl',\", \"'give',\", \"'good',\", \"'good',\", \"'got',\", \"'grampa',\", \"'grant',\", \"'group',\", \"'guy',\", \"'hair',\", \"'help',\", \"'helper',\", \"'hire',\", \"'hous',\", \"'includ',\", \"'intend',\", \"'invit',\", \"'isabel',\", \"'jail',\", \"'jewish',\", \"'job',\", \"'join',\", \"'keep',\", \"'kemi',\", \"'key',\", \"'krabappel',\", \"'last',\", \"'leari',\", \"'learn',\", \"'lenni',\", \"'let',\", \"'life',\", \"'life',\", \"'listen',\", \"'littl',\", \"'live',\", \"'live',\", \"'local',\", \"'local',\", \"'lose',\", \"'lost',\", \"'love',\", \"'love',\", \"'lovejoy',\", \"'lurleen',\", \"'make',\", \"'man',\", \"'mani',\", \"'mart',\", \"'math',\", \"'mayor',\", \"'mean',\", \"'member',\", \"'men',\", \"'miss',\", \"'miss',\", \"'mitzvah',\", \"'mother',\", \"'move',\", \"'move',\", \"'movi',\", \"'movi',\", \"'music',\", \"'music',\", \"'must',\", \"'must',\", \"'mysteri',\", \"'nuclear',\", \"'nuclear',\", \"'offer',\", \"'open',\", \"'order',\", \"'parent',\", \"'part',\", \"'peopl',\", \"'phone',\", \"'pie',\", \"'plant',\", \"'polic',\", \"'popular',\", \"'post',\", \"'power',\", \"'presid',\", \"'princ',\", \"'problem',\", \"'promis',\", \"'promis',\", \"'protect',\", \"'puppi',\", \"'quimbi',\", \"'rais',\", \"'ralph',\", \"'real',\", \"'realli',\", \"'receiv',\", \"'receiv',\", \"'relat']\", \"'relationship',\", \"'replac',\", \"'reveng',\", \"'santa',\", \"'sara',\", \"'save',\", \"'save',\", \"'second',\", \"'seem',\", \"'selma',\", \"'set',\", \"'shirt',\", \"'show',\", \"'snake',\", \"'snake',\", \"'son',\", \"'spend',\", \"'springfield',\", \"'star',\", \"'stay',\", \"'steal',\", \"'stop',\", \"'stori',\", \"'suggest',\", \"'take',\", \"'take',\", \"'talk',\", \"'tax',\", \"'teach',\", \"'team',\", \"'tell',\", \"'tell',\", \"'thank',\", \"'thing',\", \"'thing',\", \"'togeth',\", \"'tow',\", \"'traffic',\", \"'trip',\", \"'valentin',\", \"'visit',\", \"'voic',\", \"'walk',\", \"'weight',\", \"'well',\", \"'win',\", \"'woman',\", \"'woman',\", \"'women',\", \"'world',\", \"'year',\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [26, 29, 2, 15, 19, 9, 24, 17, 25, 23, 3, 7, 4, 30, 13, 12, 18, 10, 28, 21, 6, 22, 14, 27, 20, 16, 11, 1, 5, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el174848130080809997403955\", ldavis_el174848130080809997403955_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el174848130080809997403955\", ldavis_el174848130080809997403955_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el174848130080809997403955\", ldavis_el174848130080809997403955_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "25    -0.024083 -0.001052       1        1  11.695548\n",
       "28     0.002153 -0.021398       2        1   9.103671\n",
       "1      0.000390  0.000711       3        1   6.022123\n",
       "14    -0.000248  0.002527       4        1   5.404257\n",
       "18    -0.000085 -0.001108       5        1   4.969504\n",
       "8      0.002854  0.001816       6        1   4.898009\n",
       "23     0.000992  0.001221       7        1   4.446548\n",
       "16    -0.000462 -0.000166       8        1   4.144837\n",
       "24     0.000773  0.001313       9        1   3.960582\n",
       "22    -0.000583  0.001068      10        1   3.497758\n",
       "2      0.000632 -0.000535      11        1   3.278800\n",
       "6      0.000814  0.000119      12        1   2.754414\n",
       "3      0.000403  0.001644      13        1   2.644151\n",
       "29     0.000391  0.000374      14        1   2.588223\n",
       "12     0.001970  0.001444      15        1   2.460795\n",
       "11     0.000886  0.001172      16        1   2.384760\n",
       "17     0.000254  0.001150      17        1   2.367749\n",
       "9      0.000961  0.000137      18        1   2.211184\n",
       "27     0.001494  0.000248      19        1   2.122548\n",
       "20     0.000904  0.000451      20        1   2.111726\n",
       "5      0.000232  0.000686      21        1   2.074618\n",
       "21     0.000987  0.000605      22        1   1.996807\n",
       "13     0.000973  0.001152      23        1   1.826397\n",
       "26     0.000843  0.000942      24        1   1.782549\n",
       "19     0.000780  0.001322      25        1   1.692621\n",
       "15     0.001500  0.000789      26        1   1.626010\n",
       "10     0.001188  0.000659      27        1   1.600893\n",
       "0      0.001555  0.000861      28        1   1.590154\n",
       "4      0.000603  0.000760      29        1   1.425718\n",
       "7      0.000930  0.001088      30        1   1.317044, topic_info=             Term      Freq     Total Category  logprob  loglift\n",
       "1384       'pie',  3.000000  3.000000  Default  30.0000  30.0000\n",
       "843       'bear',  4.000000  4.000000  Default  29.0000  29.0000\n",
       "207      'littl',  5.000000  5.000000  Default  28.0000  28.0000\n",
       "760     'nelson',  2.000000  2.000000  Default  27.0000  27.0000\n",
       "731      'bulli',  2.000000  2.000000  Default  26.0000  26.0000\n",
       "...           ...       ...       ...      ...      ...      ...\n",
       "1312    'scienc',  0.050726  2.018953  Topic30  -7.7786   0.6459\n",
       "62    'christma',  0.050726  2.497392  Topic30  -7.7786   0.4332\n",
       "1251    'colleg',  0.050726  2.432689  Topic30  -7.7786   0.4595\n",
       "55       'chanc',  0.050726  2.778965  Topic30  -7.7786   0.3264\n",
       "144       'give',  0.050726  2.450159  Topic30  -7.7786   0.4523\n",
       "\n",
       "[1349 rows x 6 columns], token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "1         1  0.333352  'accident',\n",
       "1         4  0.333352  'accident',\n",
       "5         2  0.265290    'actual',\n",
       "719       1  0.351767     'advic',\n",
       "8         1  0.353605      'agre',\n",
       "...     ...       ...          ...\n",
       "2005      1  0.320086     'woman',\n",
       "2005      2  0.320086     'woman',\n",
       "1057      5  0.342036     'women',\n",
       "389       1  0.343549     'world',\n",
       "395       1  0.288389      'year',\n",
       "\n",
       "[232 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[26, 29, 2, 15, 19, 9, 24, 17, 25, 23, 3, 7, 4, 30, 13, 12, 18, 10, 28, 21, 6, 22, 14, 27, 20, 16, 11, 1, 5, 8])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see certain topics are clustered together, this indicates the similarity between topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annað gensim model\n",
    "https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(5302 unique tokens: [\"'abe',\", \"'accident',\", \"'across',\", \"'act',\", \"'action',\"]...) from 600 documents (total 108774 corpus positions)\n",
      "INFO:gensim.utils:saving Dictionary object under dictionary.gensim, separately None\n",
      "INFO:gensim.utils:saved dictionary.gensim\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(data_lemmatized)\n",
    "corpus = [dictionary.doc2bow(text) for text in data_lemmatized]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are asking LDA to find 5 topics in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.2\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.2\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (multi-pass) LDA training, 5 topics, 15 passes over the supplied corpus of 600 documents, updating model once every 600 documents, evaluating perplexity every 600 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamodel:-9.265 per-word bound, 615.3 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.012*\"'get',\" + 0.007*\"'famili',\" + 0.006*\"'tell',\" + 0.004*\"'bob',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'springfield',\" + 0.004*\"'find',\" + 0.003*\"'show',\" + 0.003*\"'tri',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.008*\"'get',\" + 0.006*\"'famili',\" + 0.005*\"'tell',\" + 0.005*\"'make',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'springfield',\" + 0.004*\"'show',\" + 0.003*\"'see',\" + 0.003*\"'find',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'say',\" + 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.005*\"'famili',\" + 0.005*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'springfield',\" + 0.003*\"'howev',\" + 0.003*\"'see',\" + 0.003*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.009*\"'get',\" + 0.007*\"'tell',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'springfield',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.003*\"'find',\" + 0.003*\"'back',\" + 0.003*\"'show',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'springfield',\" + 0.006*\"'get',\" + 0.006*\"'tell',\" + 0.006*\"'famili',\" + 0.006*\"'make',\" + 0.005*\"'back',\" + 0.005*\"'take',\" + 0.004*\"'tri',\" + 0.003*\"'home',\" + 0.003*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=2.611328, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:-7.653 per-word bound, 201.3 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.012*\"'get',\" + 0.008*\"'famili',\" + 0.006*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'show',\" + 0.003*\"'find',\" + 0.003*\"'tri',\" + 0.003*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.005*\"'school',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.005*\"'tell',\" + 0.005*\"'back',\" + 0.004*\"'show',\" + 0.004*\"'springfield',\" + 0.004*\"'comic',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'say',\" + 0.006*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'springfield',\" + 0.003*\"'howev',\" + 0.003*\"'see',\" + 0.003*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.009*\"'get',\" + 0.007*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'springfield',\" + 0.005*\"'make',\" + 0.004*\"'tri',\" + 0.004*\"'take',\" + 0.003*\"'smither',\" + 0.003*\"'stori',\" + 0.003*\"'fire',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'springfield',\" + 0.006*\"'get',\" + 0.005*\"'make',\" + 0.005*\"'famili',\" + 0.005*\"'back',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.003*\"'home',\" + 0.003*\"'school',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.529785, rho=0.577350\n",
      "INFO:gensim.models.ldamodel:-7.586 per-word bound, 192.1 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.011*\"'get',\" + 0.008*\"'famili',\" + 0.007*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'take',\" + 0.004*\"'show',\" + 0.004*\"'make',\" + 0.004*\"'tri',\" + 0.003*\"'find',\" + 0.003*\"'hous',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.006*\"'school',\" + 0.005*\"'make',\" + 0.005*\"'famili',\" + 0.005*\"'tell',\" + 0.005*\"'back',\" + 0.004*\"'comic',\" + 0.004*\"'show',\" + 0.004*\"'springfield',\" + 0.004*\"'store',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.007*\"'say',\" + 0.007*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'famili',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'springfield',\" + 0.003*\"'howev',\" + 0.003*\"'see',\" + 0.003*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.008*\"'get',\" + 0.007*\"'tell',\" + 0.005*\"'springfield',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'tri',\" + 0.003*\"'take',\" + 0.003*\"'fire',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'springfield',\" + 0.006*\"'get',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'back',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.366014, rho=0.500000\n",
      "INFO:gensim.models.ldamodel:-7.557 per-word bound, 188.3 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.011*\"'get',\" + 0.009*\"'famili',\" + 0.008*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'take',\" + 0.004*\"'make',\" + 0.004*\"'tri',\" + 0.003*\"'find',\" + 0.003*\"'say',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.006*\"'school',\" + 0.005*\"'make',\" + 0.005*\"'comic',\" + 0.004*\"'tell',\" + 0.004*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'show',\" + 0.004*\"'springfield',\" + 0.004*\"'martin',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.007*\"'say',\" + 0.007*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.005*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'howev',\" + 0.003*\"'see',\" + 0.003*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.008*\"'get',\" + 0.006*\"'tell',\" + 0.005*\"'springfield',\" + 0.005*\"'make',\" + 0.005*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.003*\"'abe',\" + 0.003*\"'one',\" + 0.003*\"'tri',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'back',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.243433, rho=0.447214\n",
      "INFO:gensim.models.ldamodel:-7.544 per-word bound, 186.6 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 4, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.008*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'make',\" + 0.004*\"'say',\" + 0.004*\"'hous',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.007*\"'school',\" + 0.005*\"'comic',\" + 0.005*\"'make',\" + 0.004*\"'tell',\" + 0.004*\"'back',\" + 0.004*\"'martin',\" + 0.004*\"'famili',\" + 0.004*\"'apu',\" + 0.004*\"'springfield',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.007*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.005*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'howev',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'tell',\" + 0.006*\"'springfield',\" + 0.005*\"'make',\" + 0.005*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'abe',\" + 0.004*\"'one',\" + 0.003*\"'find',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.165356, rho=0.408248\n",
      "INFO:gensim.models.ldamodel:-7.537 per-word bound, 185.7 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 5, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.008*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'take',\" + 0.004*\"'tri',\" + 0.004*\"'say',\" + 0.004*\"'make',\" + 0.004*\"'hous',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.007*\"'school',\" + 0.005*\"'comic',\" + 0.005*\"'make',\" + 0.004*\"'tell',\" + 0.004*\"'back',\" + 0.004*\"'martin',\" + 0.004*\"'book',\" + 0.004*\"'apu',\" + 0.004*\"'krabappel',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.005*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'tell',\" + 0.006*\"'springfield',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'abe',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.003*\"'find',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.115092, rho=0.377964\n",
      "INFO:gensim.models.ldamodel:-7.533 per-word bound, 185.2 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 6, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.008*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'take',\" + 0.004*\"'hous',\" + 0.004*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.007*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.004*\"'tell',\" + 0.004*\"'back',\" + 0.004*\"'martin',\" + 0.004*\"'book',\" + 0.004*\"'krabappel',\" + 0.004*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.005*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'tell',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'abe',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.003*\"'find',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'school',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.082221, rho=0.353553\n",
      "INFO:gensim.models.ldamodel:-7.530 per-word bound, 184.9 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 7, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'take',\" + 0.004*\"'hous',\" + 0.004*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.007*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.004*\"'tell',\" + 0.004*\"'martin',\" + 0.004*\"'back',\" + 0.004*\"'book',\" + 0.004*\"'krabappel',\" + 0.004*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'tell',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'abe',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.003*\"'find',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.060082, rho=0.333333\n",
      "INFO:gensim.models.ldamodel:-7.529 per-word bound, 184.6 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 8, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.004*\"'take',\" + 0.004*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'martin',\" + 0.004*\"'tell',\" + 0.004*\"'krabappel',\" + 0.004*\"'book',\" + 0.004*\"'back',\" + 0.004*\"'toni',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'tell',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'abe',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.003*\"'find',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.045055, rho=0.316228\n",
      "INFO:gensim.models.ldamodel:-7.527 per-word bound, 184.5 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 9, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.004*\"'take',\" + 0.004*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'martin',\" + 0.004*\"'krabappel',\" + 0.004*\"'tell',\" + 0.004*\"'toni',\" + 0.004*\"'book',\" + 0.004*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'tell',\" + 0.005*\"'make',\" + 0.004*\"'abe',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.003*\"'snake',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'school',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.034723, rho=0.301511\n",
      "INFO:gensim.models.ldamodel:-7.526 per-word bound, 184.3 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 10, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.004*\"'take',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'martin',\" + 0.005*\"'toni',\" + 0.005*\"'krabappel',\" + 0.004*\"'book',\" + 0.004*\"'tell',\" + 0.004*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'make',\" + 0.003*\"'one',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'tell',\" + 0.005*\"'make',\" + 0.005*\"'abe',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.003*\"'snake',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'school',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.027540, rho=0.288675\n",
      "INFO:gensim.models.ldamodel:-7.525 per-word bound, 184.2 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 11, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.004*\"'take',\" + 0.003*\"'make',\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'toni',\" + 0.005*\"'martin',\" + 0.005*\"'krabappel',\" + 0.005*\"'book',\" + 0.004*\"'tell',\" + 0.004*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'one',\" + 0.003*\"'make',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'tell',\" + 0.005*\"'abe',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.004*\"'snake',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'school',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.022479, rho=0.277350\n",
      "INFO:gensim.models.ldamodel:-7.525 per-word bound, 184.1 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 12, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.004*\"'take',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'toni',\" + 0.005*\"'martin',\" + 0.005*\"'krabappel',\" + 0.005*\"'book',\" + 0.004*\"'tell',\" + 0.004*\"'apu',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'one',\" + 0.003*\"'make',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'tell',\" + 0.005*\"'abe',\" + 0.005*\"'make',\" + 0.004*\"'famili',\" + 0.004*\"'smither',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.004*\"'snake',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'take',\" + 0.004*\"'school',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.018889, rho=0.267261\n",
      "INFO:gensim.models.ldamodel:-7.524 per-word bound, 184.1 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 13, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.003*\"'take',\" + 0.003*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'toni',\" + 0.005*\"'martin',\" + 0.005*\"'krabappel',\" + 0.005*\"'book',\" + 0.005*\"'apu',\" + 0.005*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.003*\"'one',\" + 0.003*\"'make',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'tell',\" + 0.005*\"'abe',\" + 0.005*\"'smither',\" + 0.005*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'stori',\" + 0.004*\"'one',\" + 0.004*\"'snake',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'tell',\" + 0.006*\"'get',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'school',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.016255, rho=0.258199\n",
      "INFO:gensim.models.ldamodel:-7.523 per-word bound, 184.0 perplexity estimate based on a held-out corpus of 600 documents with 108774 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 14, at document #600/600\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\" + 0.004*\"'show',\" + 0.004*\"'say',\" + 0.004*\"'tri',\" + 0.004*\"'hous',\" + 0.003*\"'make',\" + 0.003*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\" + 0.005*\"'toni',\" + 0.005*\"'martin',\" + 0.005*\"'krabappel',\" + 0.005*\"'book',\" + 0.005*\"'apu',\" + 0.005*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\" + 0.005*\"'back',\" + 0.004*\"'famili',\" + 0.004*\"'springfield',\" + 0.004*\"'one',\" + 0.003*\"'make',\" + 0.003*\"'see',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'tell',\" + 0.005*\"'abe',\" + 0.005*\"'smither',\" + 0.005*\"'famili',\" + 0.004*\"'make',\" + 0.004*\"'stori',\" + 0.004*\"'snake',\" + 0.004*\"'one',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'get',\" + 0.006*\"'tell',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\" + 0.005*\"'make',\" + 0.004*\"'school',\" + 0.004*\"'take',\" + 0.004*\"'back',\" + 0.004*\"'tri',\" + 0.004*\"'home',\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.014317, rho=0.250000\n",
      "INFO:gensim.utils:saving LdaState object under model5.gensim.state, separately None\n",
      "INFO:gensim.utils:saved model5.gensim.state\n",
      "INFO:gensim.utils:saving LdaModel object under model5.gensim, separately ['expElogbeta', 'sstats']\n",
      "INFO:gensim.utils:storing np array 'expElogbeta' to model5.gensim.expElogbeta.npy\n",
      "INFO:gensim.utils:not storing attribute id2word\n",
      "INFO:gensim.utils:not storing attribute dispatcher\n",
      "INFO:gensim.utils:not storing attribute state\n",
      "INFO:gensim.utils:saved model5.gensim\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.200): 0.010*\"'get',\" + 0.009*\"'famili',\" + 0.009*\"'bob',\" + 0.006*\"'tell',\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.200): 0.009*\"'get',\" + 0.008*\"'school',\" + 0.006*\"'comic',\" + 0.005*\"'make',\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.200): 0.008*\"'get',\" + 0.007*\"'say',\" + 0.006*\"'tell',\" + 0.005*\"'take',\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.200): 0.007*\"'get',\" + 0.006*\"'springfield',\" + 0.005*\"'tell',\" + 0.005*\"'abe',\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.200): 0.006*\"'get',\" + 0.006*\"'tell',\" + 0.006*\"'springfield',\" + 0.006*\"'famili',\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.010*\"\\'get\\',\" + 0.009*\"\\'famili\\',\" + 0.009*\"\\'bob\\',\" + 0.006*\"\\'tell\\',\"')\n",
      "(1, '0.009*\"\\'get\\',\" + 0.008*\"\\'school\\',\" + 0.006*\"\\'comic\\',\" + 0.005*\"\\'make\\',\"')\n",
      "(2, '0.008*\"\\'get\\',\" + 0.007*\"\\'say\\',\" + 0.006*\"\\'tell\\',\" + 0.005*\"\\'take\\',\"')\n",
      "(3, '0.007*\"\\'get\\',\" + 0.006*\"\\'springfield\\',\" + 0.005*\"\\'tell\\',\" + 0.005*\"\\'abe\\',\"')\n",
      "(4, '0.006*\"\\'get\\',\" + 0.006*\"\\'tell\\',\" + 0.006*\"\\'springfield\\',\" + 0.006*\"\\'famili\\',\"')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'LdaModel' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-df5cbe1dfd66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/general_venv/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteger_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m                 \u001b[0;31m# make sure the term IDs are ints, otherwise np will get upset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'LdaModel' has no len()"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "print(ldamodel.get_document_topics(ldamodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* supervised LDA\n",
    "* model over time (sja nýjasta pgm'ið)\n",
    "* research paper topic modelling \n",
    "        \"The model can be applied to any kinds of labels on documents, such as tags on posts on the website.\"\n",
    "        gætum við notað short description sem tagg þá ?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
